 #' Creates a list of unique color values used for plotting
#'
#' @return A named vector of unique hexedecimal color values, either generated from a preselected
#'         vector of 20 unique colors, or from a sequence of colors in hsv colorspace.
#'
#' @param object A vector, factor, data.frame used to allocate color for each unique element.
#' @param palette the customized color schmea name:
#' seurat:31, blindless:69, col50:50, ditto:24, paired:12, colx22:22, jet:9, tableau20:20,
#' tableau10medium:10, colorblind10:10, trafficlight:9, purplegray12:12, bluered12:12,
#' greenorange12:12, cyclic:20, alphabet:26, alphabet2:26, glasbey:32,
#' polychrome:36, stepped:24
#' @param value The Seurat metadata slot to generate colors for. Defaults to "celltype".
#' @param n the number of colors to use
#' @examples
#'
#' @export

readRDSMC= function (file, cores)
{
    tictoc::tic()
    con <- pipe(paste0("cat ", file, " | pigz -dcp ", cores),
        "rb")
    object <- tryCatch({
        readRDS(file = con)
    }, error = function(err) {
        stop("could not read file\n", file, ":\n", err)
    }, finally = {
        if (exists("con"))
            close(con)
    })
    tictoc::toc()
    return(object)
}

ReadX = function (input = NULL, informat = NULL, assays = NULL, data.use = c("counts", 
    "data"), ...) 
{
    input <- normalizePath(sub("\\/$", "", input, perl = T))
    object <- switch(tolower(informat), rds = {
        objectx <- readRDSMC(input,10)
        if (class(objectx) == "Seurat" & objectx@version < 4) {
            objectx <- SeuratObject::UpdateSeuratObject(objectx)
        }
        objectx
    }, loom = {
        SCopeLoomR::open_loom(input, mode = "r+")
    }, h5ad = {
        anndata::read_h5ad(input, ...)
    }, h5seurat = {
        assay_data <- list()
        if (is.null(assays)) {
            assay_data <- NULL
        } else {
            for (assayx in assays) {
                assay_data[[assayx]] = data.use
            }
        }
        SeuratDisk::LoadH5Seurat(input, assays = assay_data, 
            ...)
    }, {
        stop("NO specifed format of your data object supported!")
    })
    return(object)
}

RunDiffexp <-function(object, test = "wilcox", contrast = NULL, fdr = NULL, 
    fc.thres = 2, pval.thres = 0.05, outputdir = NULL, ...)
{
    contrasts = unlist(strsplit(contrast, ":", perl = T))
    numerator_subset = unlist(strsplit(contrasts[2], ",", perl = T))
    denominator_subset = unlist(strsplit(contrasts[3], ",", perl = T))
    cellmeta = Seurat::FetchData(object, vars = contrasts[1]) %>% tibble::rownames_to_column(var = "barcode")
    numerator = cellmeta %>% dplyr::filter(!!rlang::sym(contrasts[1]) %in%
        numerator_subset) %>% dplyr::pull(barcode)
    denominator = cellmeta %>% dplyr::filter(!!rlang::sym(contrasts[1]) %in%
        denominator_subset) %>% dplyr::pull(barcode)
    res = Seurat::FindMarkers(object, ident.1 = numerator_subset,
        ident.2 = denominator_subset, group.by = contrasts[1],
        min.pct = 0, test.use = test, only.pos = F, ...)
    if ("auc" %in% names(res))
        res = res %>% dplyr::select(-auc)
    res = res %>% tibble::rownames_to_column(var = "gene") %>%
        dplyr::rename(pvalue = p_val, padj = p_val_adj)
    if (nrow(res) == 0) {
        warning(paste0("NO Differential Genes Identified for ",
            contrast, sep = ""))
        return(0)
    }
    numerator_means = Matrix::rowMeans(SeuratObject::GetAssayData(object,
        slot = "data")[res$gene, numerator])
    denominator_means = Matrix::rowMeans(SeuratObject::GetAssayData(object,
        slot = "data")[res$gene, denominator])
    res = res %>% dplyr::mutate(FoldChange = 2^avg_log2FC, baseMean = 1/2 *
        (log2(numerator_means) + log2(denominator_means))) %>%
        dplyr::rename(log2FoldChange = avg_log2FC) %>% dplyr::select(gene,
        everything()) %>% dplyr::select(-baseMean)
        base_prefix = paste0(contrasts[1], "_", contrasts[2],
            "-vs-", contrasts[3])
	colnames(res) =c("gene","p-value","log2FoldChange","pct.1","pct.2","q-value","FoldChange")
        write.table(res, file.path(outputdir, paste0(base_prefix,
            "-all_diffexp_genes", ".xls")), sep = "\t", col.names = TRUE,
            row.names = FALSE, quote = FALSE, na = "")
    if (!is.null(pval.thres)) {
        res_Significant = dplyr::filter(res, `p-value` < pval.thres,
            abs(log2FoldChange) > log2(fc.thres))
    }
    if (!is.null(fdr)) {
        res_Significant = dplyr::filter(res, padj < fdr, abs(log2FoldChange) >
            log2(fc.thres))
    }
    if (nrow(res_Significant) == 0) {
        warning(paste0("NO Significant Differential Genes Identified for ",
            contrast, sep = ""))
        return(0)
    }
    res_Significant[which(res_Significant$log2FoldChange > 0),
        "Regulation"] <- "Up"
    res_Significant[which(res_Significant$log2FoldChange < 0),
        "Regulation"] <- "Down"
    if (!is.null(outputdir)) {
        base_prefix = paste0(contrasts[1], "_", contrasts[2],
            "-vs-", contrasts[3])
        if (!is.null(pval.thres)) {
		colnames(res_Significant) =c("gene","p-value","log2FoldChange","pct.1","pct.2","q-value","FoldChange","Regulation")
            write.table(res_Significant, file.path(outputdir,
                paste0(base_prefix, "-diff-", "pval-", pval.thres,
                  "-FC-", fc.thres, ".xls")), sep = "\t", col.names = TRUE,
                row.names = FALSE, quote = FALSE, na = "")
            stat <- matrix(c("Case", "Control", "Up_diff", "Down_diff",
                paste("Total_diff(", "pvalue<", pval.thres, "&FoldChange>",
                  fc.thres, ")", sep = "")), ncol = 5)
        }
        if (!is.null(fdr)) {
		colnames(res_Significant) =c("gene","p-value","log2FoldChange","pct.1","pct.2","q-value","FoldChange","Regulation")
            write.table(res_Significant, file.path(outputdir,
                paste0(base_prefix, "-diff-", "padj-", fdr, "-FC-",
                  fc.thres, ".xls")), sep = "\t", col.names = TRUE,
                row.names = FALSE, quote = FALSE, na = "")
            stat <- matrix(c("Case", "Control", "Up_diff", "Down_diff",
                paste("Total_diff(", "padj<", fdr, "&FoldChange>",
                  fc.thres, ")", sep = "")), ncol = 5)
        }
        up_num <- length(which(res_Significant$Regulation == "Up"))
        down_num <- length(which(res_Significant$Regulation == "Down"))
        total <- sum(up_num, down_num)
        stat1 <- c(paste(contrasts[2], "(", contrasts[1], ")",
            sep = ""), paste(contrasts[3], "(", contrasts[1],
            ")", sep = ""), up_num, down_num, total)
        if (file.exists(file.path(outputdir, "diffexp_results_stat.xls"))) {
            stat <- rbind(stat1)
        }
        else {
            stat <- rbind(stat, stat1)
        }
        write.table(stat, file.path(outputdir, "diffexp_results_stat.xls"),
            append = file.exists(file.path(outputdir, "diffexp_results_stat.xls")),     
            quote = F, row.names = F, col.names = F, sep = "\t",
            na = "")
    }
    else {
        return(res_Significant)
    }
}
RunDimReduc <- function (object, feature.use = NULL, reduct1.use = "pca", reduct2.use = "umap", 
    perplexity = 30, batch.use = NULL, npcs.use = NULL, assay.use = NULL,
    ...)
{
    if (!is.object(object)) {
        assay_data = list()
        assay_data[[assay]] = data.use
        object <- ReadX(object, informat, assay = assay.use,
            data.use, ...)
    }
    assay.use <- assay.use %||% Seurat::DefaultAssay(object)
    feature.use <- feature.use %||% Seurat::VariableFeatures(object)
    npcs.use <- npcs.use %||% 30
    if (tolower(reduct2.use) %in% c("cca", "mnn", "harmony")) {
        if (is.null(batch.use)) {
            warning("NO batch information specified!The batchid will be used as default!")
            batch.use = "batchid"
        }
        if (!batch.use %in% colnames(colData(object))) {
            stop("NO specified batch column found in the meta.data slot of seurat object!")
        }
    }
    if (is.null(reduct1.use)) {
        print("NO primary reduction method specified, PCA will be used as default!")
        reduct1.use = "pca"
    }
    if (is.null(reduct2.use)) {
        reduct2.use = reduct1.use
    }
    object = switch(tolower(reduct2.use), ica = Seurat::RunICA(object,
        nics = npcs.use, features = feature.use, verbose = F,
        ...), cca = do.call("RunCCA", c(SplitObject(object, split.by = batch.use),
        list(features = feature.use, renormalize = F, rescale = F))),
        pca = Seurat::RunPCA(object, npcs = npcs.use, features = feature.use,
            do.print = F, verbose = F, ...), lsi = Signac::RunSVD(object,
            n = npcs.use, features = feature.use, reduction.key = "LSI_",
            reduction.name = "lsi", verbose = F, ...), lda = Seurat::RunLDA(object,
            slot = "counts", topics = 30, method = "Z-score"),
        tsne = Seurat::RunTSNE(object, reduction = reduct1.use,
            perplexity = perplexity, dims = 1:npcs.use, num_threads = future::nbrOfWorkers(),
            check_duplicates = F, ...), `flt-sne` = Seurat::RunTSNE(object,
            reduction = reduct1.use, dim.embed = 3, tsne.method = "FIt-SNE",
            dims = 1:npcs.use, fasttsne_path = system("which fast_tsne"),
            check_duplicates = F, ...), mnn = RunFastMNN(object,
            batch = batch.use, assay = assay.use, features = feature.use,...), svd = Signac::RunSVD(object,
            n = npcs.use, features = feature.use, verbose = F,
            ...), harmony = harmony::RunHarmony(object, group.by.var = batch.use,
            reduction = reduct1.use, assay = assay.use, dims.use = 1:npcs.use,
            project.dim = FALSE, plot_convergence = F, ...),
        umap = Seurat::RunUMAP(object, dims = 1:npcs.use, verbose = F,
            reduction = reduct1.use, n.components = 2, ...))
    return(object)
}
#!/usr/bin/env Rscript
# the command line api of data analysis of biological experiments
if (!requireNamespace('argparse', quietly = TRUE)) {
  stop("Please install argparse to parse the command line paramters!")
}
suppressPackageStartupMessages( library("Seurat") )
suppressPackageStartupMessages( library("OESingleCell"))
suppressPackageStartupMessages( library("argparse") )
suppressPackageStartupMessages( library("magrittr") )
suppressPackageStartupMessages( library("rlang") )
# suppressPackageStartupMessages( library("grid") )
suppressPackageStartupMessages( library("ggplot2") )
suppressPackageStartupMessages(library("harmony",lib.loc="/public/dev_scRNA/software/miniconda3/envs/OESingleCell/lib/R/library/"))
source("/public/scRNA_works/pipeline/scRNA-seq_further_analysis/Get_colors.R")
# suppressPackageStartupMessages( library("ggsignif") )
# ======================= COMMAND LINE PARAMETERS SETTING =======================
# ======================= GLOBAL command line parameters setting=================
parser = ArgumentParser(description = "single cell sequencing data manipulating toolsets.",
                        usage = "%(prog)s [global options]" )
parser$add_argument("-i", "--input", type = "character",
             help = "The input exprssion matrix in several possible format.")
parser$add_argument("-f", "--informat", type = "character", default = NULL,
             help = "The format of data object, the possible choices can be:h5seurat,(seurat)rds,(sce)rds, loom.[default: %(default)s]")
parser$add_argument("-o", "--output", type = "character", default = "./",
             help = "the output directory of results."  )
parser$add_argument("-d", "--outformat", type = "character", default = "h5seurat",
             help = "the output format of data object, possible choices:h5seurat,seurat,anndata,sce,CellDataSet(monocle2)[default: %(default)s]")
parser$add_argument("-j", "--ncores", type="integer", default = 10,
             help="the number of CPUs used to improve the performace.[default: %(default)s]")
parser$add_argument("--prefix", type = "character", default = "seurat",
             help = "the prefix of output file without file extension.[default %(default)s]")
parser$add_argument("--assay", type = "character", default = NULL,
             help = "the main assay in data object to use. When it comes to multimodal assay, this is the assay used to initialize the object, all the other assays will merged into it.")
parser$add_argument("--subassay", type = "character", default = NULL,
             help = "[OPTIONAL]the comma separated assays list except the main assay specified by --assay, when it comes to multimodal assay. For monomodal assay, it's NULL as default.")
parser$add_argument("--dataslot", type="character", default="data",
             help="the data slot in the specified assay used for this run, one of 'counts','data' must be provided.[default: %(default)s]")
parser$add_argument("--predicate", type = "character", default = NULL,
             help = "The conditional expression to subset cells used for subtyping.[default: %(default)s]")
parser$add_argument("--update", default= "TRUE", type="character",
             help="whether update the data in the object on disk using the newly produced results. Set this to FALSE when you use this script for subclustering! Only availiable for h5seurat input.[default TRUE]")
subparsers = parser$add_subparsers(help = "subcommands:")
# sce: singlecellexperiement object supported by R packages:scater,scran etc.
# h5: hdf5 formatted molecular quantification from cellranger etc.
# loom: loom format, a specialized hdf5 format.
# h5seurat: the hdf5 formated seurat object.
# h5ad: the format support by scanpy from anndata in python.
# aggr: the result from cellranger aggr
# tenx:the directory of cellranger count/aggr output with sampleid named subdirectory.
# xsv: the raw gene count matrix file, it can be very large. Please make sure the data path is Your_Project/sampleid/sampleid.(tsv|csv).
# cellDataSet: the format for monocle.
# Seurat: the  binary seurat object .rds from the clustering results.
# visium: the output from spaceranger ananlysis of 10X Visium spatial transcriptomics data.", '"""'))
# se: summarizedExperient object in rds format
# htseq: the results from htseq-count
# vdj: the results from cellranger vdj
# smart-seq2:
#
# star: the results from STAR alignment result TO DO

# create the parsers for subcommand create
sub_create = subparsers$add_parser("create",
     help = "make the specified format data object out of the supported input data sources.")
sub_create$add_argument("-s", "--source", type = "character", default = "mtx",
     help = "The source of data, possible choices:h5, mtx, xsv(including BD,tsv and csv), Visium, slideseq.[default: %(default)s]")
sub_create$add_argument("-m", "--metadata", type = "character",
     help = "the sample metadata which must include sample id in this assay design.")
sub_create$add_argument("-x", "--metrics", type = "character", default = "percent.mito",
     help = "the additional QC metrics list to calculate in advance.[default %(default)s]")
sub_create$add_argument("--gcolumn", type = "integer", default = 2,
     help = "Specify which column of genes.tsv or features.tsv to use for feature names.[default %(default)s]")
sub_create$add_argument("--aggr", type = "character", default = "FALSE",
     help = "[OPTIONAL] wether the results derived from cellranger aggr.[default %(default)s]")
sub_create$add_argument("--feature.meta", type = "character", default = NULL,
     help = "[OPTIONAL]the reference genome annotaion file from 10X.")
sub_create$add_argument("--chrom.size", type = "character", default = NULL,
     help = "[OPTIONAL]length of each chromosome of the genome file from 10X.")
sub_create$add_argument("--cell.meta", type = "character", default = "FALSE",
     help = "[OPTIONAL] logical indication wether there is cell annotation file for, 'singlecell.csv' for in ATAC-seq for example.[default: FALSE]")
sub_create$add_argument("--fragment", type = "character", default = "FALSE",
     help = "[OPTIONAL] use the fragment annotion file 'fragments.tsv.gz' in outs directory from cellranger-atac count results for each sample, Only valid for scATAC-seq assay.[default FALSE]")
sub_create$add_argument("--transpose", type = "character", default = "FALSE",
     help = "[OPTIONAL]wether to transpose the count matrix when comes to the cell-feature matrix.[default %(default)s]")
sub_create$add_argument("--gset", type = "character", default = NULL,
     help = "[OPTIONAL]the gmt formated customized genes set file for QC metrics' calculation.")
sub_create$add_argument("--mixSpecies", type = "character", default = "no",
     help = "[OPTIONAL]wether the data is from mixed species, 'no', 'mm10', 'GRCh38', 'Rat' or other Species prefix in gem_classification.csv.[default %(default)s]")

# create the parsers for subcommand multimodal
sub_multimodal = subparsers$add_parser("multimodal",
     help = "make the specified format data object out of cellranger multimodal assay, currently only scRNA+scATAC.")
sub_multimodal$add_argument("-s", "--source", type = "character", default = "h5",
     help = "The source of multimodal assay data, currently only hdf5 formated files are supported.[default %(default)s]")
sub_multimodal$add_argument("-m", "--metadata", type = "character",
     help = "the sample metadata which must include sample id in this assay design.")
sub_multimodal$add_argument("-x", "--metrics", type = "character", default = "percent.mito",
     help = "the additional QC metrics list to calculate in advance.[default %(default)s]")
sub_multimodal$add_argument("--gcolumn", type = "integer", default = 2,
     help = "Specify which column of genes.tsv or features.tsv to use for feature names.[default %(default)s]")
sub_multimodal$add_argument("--feature.meta", type = "character", default = NULL,
     help = "[OPTIONAL]the reference genome annotaion file from 10X.")
sub_multimodal$add_argument("--cell.meta", type = "character", default = "FALSE",
     help = "[OPTIONAL] logical indication wether there is cell annotation file for, 'singlecell.csv' for in ATAC-seq for example.[default: FALSE]")
sub_multimodal$add_argument("--fragment", type = "character", default = "FALSE",
     help = "[OPTIONAL] use the fragment annotion file 'fragments.tsv.gz' in outs directory from cellranger-atac count results for each sample, Only valid for scATAC-seq assay.[default FALSE]")
sub_multimodal$add_argument("--gset", type = "character", default = NULL,
     help = "[OPTIONAL]the gmt formated customized genes set file for QC metrics' calculation.")

sub_convert = subparsers$add_parser("convert",
     help = "convert the data object from input format to the target format.")
sub_convert$add_argument("--from", type = "character", default = "h5seurat",
     help = "the format of the input data object, choices can be: monocle2(CellDataSet), monocle3(cell_data_set), Seurat, sce(SingleCellExperiment), anndata.")
sub_convert$add_argument("--to", type = "character", default = "",
     help = "the destination output format of the data object, choices can be: monocle2(CellDataSet), monocle3(cell_data_set), Seurat, sce(SingleCellExperiment), anndata..")
# sub_convert$add_argument("--seperateby", type = "character", default = NULL,
#      help = "[OPTIONAL]save the expression matrix in  mtx format like cellranger output for each sample." )

# create the parsers for subcommand subset
sub_subset = subparsers$add_parser("subset",
                    help = "filter the cells using the specified conditions." )
sub_subset$add_argument( "--geneset", type = "character",
                   help = "features/variables to keep in TAB format.")
sub_subset$add_argument("--feature4subset", type = "character",
                  help = "Logical expression on features in matrix indicating cells to keep.Example: 'MSA4>1'.")
sub_subset$add_argument( "--levels", type = "character",
                         help = "The subset of variable levels in variable specified by --group2use.")
sub_subset$add_argument( "--group2use", type = "character",
                         help = "the cell names or annotation column names set for the cell annotation table.")
sub_subset$add_argument( "--low", type = "double", default = NULL,
                         help = "the lower bound of the continious variable specified by --group2use.[default: %(default)s]")
sub_subset$add_argument( "--high", type = "double", default = NULL,
                         help = "the higher bound of the continious variable specified by --group2use.[default: %(default)s]")
sub_subset$add_argument( "--invert", type = "character", default = "FALSE",
                         help = "reverse the selection conditions specified by all other conditions.[default: %(default)s]")
# on stop of running data quanlity control of
sub_qc = subparsers$add_parser("qc", help = "one stop of data control.")
sub_qc$add_argument( "-r", "--vars2regress", type = "character", default = "nCount_RNA,percent.mito",
                help = "comma separated list of sources of variation to regress out from the data. The other options can be percent.ribo, CC.Difference etc.[default: %(default)s]")
sub_qc$add_argument( "-c", "--filters", type = "character", default = "nFeature_RNA,nCount_RNA,percent.mito",
                help = "the variables used to remove the outliers of cells. The other options can be percent.ribo etc.[default: %(default)s]")
sub_qc$add_argument("--gset", type = "character", default = NULL,
                help = "获取线粒体基因列表")
sub_qc$add_argument("-f", "--mito_four", type = "character", default = "FALSE",
                help = "线粒体按照超过细胞间线粒体UMIs中位数的四倍进行剔除")
sub_qc$add_argument( "--genes2filter", type = "character", default = NULL,
                help = "the genelist to filter.")
sub_qc$add_argument( "--QC", type = "character", default = "TRUE",
                help = "running data quanlity control.[default: %(default)s]")
sub_qc$add_argument( "-x", "--mincell4gene", type="double", default = 0.01,
                help="the minimium cell number one gene detected.If the value is less than 1, it is a proportion, otherwise a integerial cell number.[default: 10]")
sub_qc$add_argument( "-u", "--rlm.xy", type = "character", default = NULL,
                help = "[OPTIONAL]using the robust linear model of variables, for example nCount_RNA:nFeature_RNA, to remove the outliers of cells.[default: NULL]")
sub_qc$add_argument( "--cut.1", type = "character", default = "median",
                help = "the method to determine the center of an array, here refering to the median or mean of the QC metric.[default: %(default)s]")
sub_qc$add_argument( "--cut.2", type = "character", default = "mad",
                help = "the method to find the difference unit to the data center, here refering to median, sd or mad.[default: %(default)s]")
sub_qc$add_argument( "-n", "--nfold", type="double", default = 2.0,
                help="the fold of intervals(sd for mean, mad for median, median for median) for parameters specified by --filters determine the outlier threshold by +/- n*cut.2.[default:2.0]")
sub_qc$add_argument( "-l", "--lower", type="character", default = "200,2000,0",
                help="the lower bounds list for the parameters specified by --filters.[default: %(default)s]" )
sub_qc$add_argument( "-L", "--upper", type="character", default = NULL,
                help="the upper bounds list for the parameters specified by --filters.If not specified, it will be determined by the parameter --cut.1, --cut.2 and -n automatically." )
sub_qc$add_argument("-m", "--normmeth", type="character", default = "LogNormalize",
                help="the method to normalize the raw counts. Choices can be: sctransform, LogNormalize, scran, CR, CLR,logTF-IDF, TF-logIDF, logTF-logIDF, IDF etc. For feature-barcoding/cite-seq, CLR is recommended. For scRNA-seq, sctransform is recommended. Notice that if sctransform used, the default assay should be changed to SCT automatically in the later analysis. For ATAC assay, logTF-IDF id recommended.")
sub_qc$add_argument("-z", "--features2filter", type = "character", default = NULL,
                help = "[OPTIONAL]the file of specified feature list with 'gene' as header to remove from the features-cell matrix.[default: NULL]")
sub_qc$add_argument("-v", "--pointsize", type = "double", default = 0.1,
             help = "the size for each point in QC metrics vlnplot plot. Set 0 for point-freee vlnplot.")
sub_qc$add_argument("--nvfeatures", type = "double", default = 2000,
                help = "[OPTIONAL]the number of top variable features to keep for RNA-seq or the minimum percentile(0~1), for example 0.95, for ATAC-seq .")
sub_qc$add_argument("--rmdoublets", type = "character", default = "FALSE",
                            help = "remove the doublet cells.[default: %(default)s]")
sub_qc$add_argument("--method", type = "character", default = "scrublet",
                            help = "the method used to detect doublets, choices: scrublet, doubletfinder.[default: %(default)s]")
sub_qc$add_argument("--ident", type = "character", default = "clusters",
                            help = "[OPTIONAL]ONLY AVAILABLE for doubletfinder,the name of cell group annotation.")

## on stop of running data quanlity control of
#sub_qc = subparsers$add_parser("qc", help = "one stop of data control.")
#sub_qc$add_argument( "-x", "--mincell4gene", type="double", default = 0.01,
#                help="the minimium cell number one gene detected.If the value is less than 1, it is a proportion, otherwise a integerial cell number.[default: 10]")
#sub_qc$add_argument( "-u", "--rlm.xy", type = "character", default = NULL,
#                help = "[OPTIONAL]using the robust linear model of variables, for example nCount_RNA:nFeature_RNA, to remove the outliers of cells.[default: NULL]")
#sub_qc$add_argument( "--cut.1", type = "character", default = "median",
#                help = "the method to determine the center of an array, here refering to the median or mean of the QC metric.[default: %(default)s]")
#sub_qc$add_argument( "--cut.2", type = "character", default = "mad",
#                help = "the method to find the difference unit to the data center, here refering to median, sd or mad.[default: %(default)s]")
#sub_qc$add_argument( "-n", "--nfold", type="double", default = 2.0,
#                help="the fold of intervals(sd for mean, mad for median, median for median) for parameters specified by --filters determine the outlier threshold by +/- n*cut.2.[default:2.0]")
#sub_qc$add_argument( "-c", "--filters", type = "character", default = "nFeature_RNA,nCount_RNA,percent.mito",
#                help = "the variables used to remove the outliers of cells. The other options can be percent.ribo etc.[default: %(default)s]")
#sub_qc$add_argument( "-l", "--lower", type="character", default = "200,2000,0",
#                help="the lower bounds list for the parameters specified by --filters.[default: %(default)s]" )
#sub_qc$add_argument( "-L", "--upper", type="character", default = NULL,
#                help="the upper bounds list for the parameters specified by --filters.If not specified, it will be determined by the parameter --cut.1, --cut.2 and -n automatically." )
#sub_qc$add_argument("-m", "--normmeth", type="character", default = "LogNormalize",
#                help="the method to normalize the raw counts. Choices can be: sctransform, LogNormalize, scran, CR, CLR,logTF-IDF, TF-logIDF, logTF-logIDF, IDF etc. For feature-barcoding/cite-seq, CLR is recommended. For scRNA-seq, sctransform is recommended. Notice that if sctransform used, the default assay should be changed to SCT automatically in the later analysis. For ATAC assay, logTF-IDF id recommended.")
#sub_qc$add_argument("-r", "--vars2regress", type = "character", default = "nCount_RNA,percent.mito",
#                help = "comma separated list of sources of variation to regress out from the data. The other options can be percent.ribo, CC.Difference etc.[default: %(default)s]")
#sub_qc$add_argument("-z", "--features2filter", type = "character", default = NULL,
#                help = "[OPTIONAL]the file of specified feature list with 'gene' as header to remove from the features-cell matrix.[default: NULL]")
#sub_qc$add_argument("-v", "--pointsize", type = "double", default = 1,
#             help = "the size for each point in QC metrics vlnplot plot. Set 0 for point-freee vlnplot.")
#sub_qc$add_argument("--nvfeatures", type = "double", default = 2000,
#                help = "[OPTIONAL]the number of top variable features to keep for RNA-seq or the minimum percentile(0~1), for example 0.95, for ATAC-seq .")
#sub_qc$add_argument("--subset", type = "character", default = "TRUE",
#                help = "[OPTIONAL]logical indication wether to subset the data object according to threshold specified by user.[default: TRUE]")

# normalize the raw data before downstream data analysis
sub_normalize = subparsers$add_parser("normalize", help = "normalize the raw data.")
sub_normalize$add_argument("-m", "--nmethod", type = "character", default = "sct",
              help = "the normalization method to choose from: sct, LogNormalize, scran, cr,clr for single cell data.")
sub_normalize$add_argument("-r", "--vars2regress", type = "character", default = "nCount_RNA,percent.mito",
                help = "comma separated list of sources of variation to regress out from the data. The other options can be percent.ribo, CC.Difference etc.[default: %(default)s]")
sub_normalize$add_argument( "-s", "--scale-factor", default = 10000, type = 'integer',
                help = "Sets the scale factor for cell-level normalization.[default: %(default)s]" )
sub_normalize$add_argument("--sct-method", default = "glmGamPoi", type = 'character',
                help = "the distribution type used to fit generalized linear models of each gene count against the sequencing depths, choices:poisson, glmGamPoi(faster).[default: %(default)s]")
sub_normalize$add_argument( "--margin", default = NULL, type = 'integer',
                help = "If performing CLR normalization, normalize across features (1) or cells (2)." )
sub_normalize$add_argument("--model", type = "character", default = "linear",
          help = "Use a linear model or generalized linear model (poisson, negative binomial) for the regression. Options are 'linear' (default), 'poisson', and 'negbinom'")
sub_normalize$add_argument("--use-umi", type = "character", default = "FALSE",
          help = "Regress on UMI count data. Default is FALSE for linear modeling, but automatically set to TRUE if model.use is 'negbinom' or 'poisson'")
sub_normalize$add_argument("--block-size", type = "integer", default = 1000,
          help = "Default size for number of features to scale at in a single computation. Increasing block.size may speed up calculations but at an additional memory cost.")

# cluster the data
sub_cluster = subparsers$add_parser("bclust", help = "one stop run of data dimension reduction and clustering.")
sub_cluster$add_argument("-t", "--components", type="integer", default=NULL,
             help="the appropriate number of dimensions for primary reduction. Recommendations:pca:30,mnn:10[default: %(default)s]")
sub_cluster$add_argument("-e", "--integrated", default= "FALSE", type="character",
             help="integrated 样本整合方法！")
sub_cluster$add_argument("-y", "--component_pca", type="integer", default=NULL,
             help="the appropriate number of statistically significant dimension to use for clustering.")
sub_cluster$add_argument("-p", "--perplexity", type="integer", default=30,
             help="The value of the perplexity only availiable for tSNE.[default: %(default)s]")
sub_cluster$add_argument("-m", "--metadata", type="character", default = NULL,
             help="[OPTIONAL]the additional sample metadata which must include sample id in this assay design.")
sub_cluster$add_argument("-c", "--clusteringuse", type="character", default = "snn",
             help="the only supported clustering algorithms currently:snn,louvain,leiden. For other methods, use subcommand 'clusterx'." )
sub_cluster$add_argument("-r", "--resolution", type = "double", default = 0.4,
             help = "vaule used to set the resolution of cluster distiguish, use a value above(below)1.0 if you want to obtain a larger(smaller) number of communities.[default: %(default)s]")
sub_cluster$add_argument("-s", "--pointsize", type = "double", default = NULL,
             help = "[OPTIONAL]the point size in the plot.")
sub_cluster$add_argument("-w", "--kweight", type = "integer", default = 100,
             help = "[OPTIONAL]Number of neighbors to consider when weighting anchors.")
sub_cluster$add_argument("-b", "--batchid", type = "character", default = NULL,
             help = "[OPTIONAL]the batch information column name of sample in the metadata.")
sub_cluster$add_argument("--reduct1", type = "character",default="pca",
             help="the primary dimension reduction results used for clustering. Now ica,cca,pca,lsi,mnn,tsne,harmony,Flt-SNE,UMAP,swne,diffusion,phate,fa2 are supported.[default: %(default)s]")
sub_cluster$add_argument("--reduct2", type = "character",default=NULL,
             help="the secondary reduction method usually used to embed community. Now tsne,Flt-SNE,UMAP,swne,diffusion,phate,fa2 are supported. If NULL supplied, NO secondary reduction will be carried out.[default: NULL]")
sub_cluster$add_argument("--palette",type = "character",default= "customecol2",
             help="the discrete color schema for each cell cluster, customecol2 as default. Choices: customecol2:50;blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,colx22_custom:22,cyclic:20,tableau20:20, paired:12, purplegray12:12, cellchat:26, cellchat_custom:26, cellpaper:30, cellpaper_custom:59")
# sub_cluster$add_argument("--no-update", dest = "update", action="store_false",
#              help="produce new data object on disk. Only availiable for h5seurat input.")
sub_cluster$add_argument("--rerun", default="FALSE", type = "character",
             help="Rerun the primary reduction in case of parameter changes.[default FALSE]")
sub_cluster$add_argument("--ref", default=NULL, type = "character",
             help="the path of reference genome")
# sub_cluster$add_argument("--no-rerun", dest = "rerun", action="store_false",
#              help="NO rerun the primary reduction.")

# create the parser for subcommand celltyping
# the dataslot here is used to specifiy which data slot to use when celltyping
sub_celltype = subparsers$add_parser("celltyping", help = "find the celltype for each cell in data object.")
sub_celltype$add_argument("-c","--builtinref", type = "character",
             help = "one or more builtin reference data object name in SummarizedExperiment/SingleCellExperiment object.")
sub_celltype$add_argument("-r","--customref", type = "character",
             help = "One or more SummarizedExperiment/SingleCellExperiment data object containing log-transformed matrix used as non-built-in reference.")
sub_celltype$add_argument("--annolevel", type = "character", default=NULL,
             help = "cell identities annotation column in reference data for each cell in test data. If set, annotation is performed on the cluster level, otherwise it defaults to per-cell annotation.")
sub_celltype$add_argument("--usecluster", type = "character", default = "FALSE",
             help = "wether to predict identitiy for each cluster of test data rather than single cell.")
sub_celltype$add_argument("--demethod", type = "character", default = "classic",
             help = "String specifying how DE genes should be detected between pairs of labels in ref data. Choices can be:classic,wilcox and t.[default: %(default)s].")
sub_celltype$add_argument("-v", "--pointsize", type = "double", default = NULL,
             help = "the size for each point in scatter plot.")
sub_celltype$add_argument("-n", "--topn", type = "integer", default = 25,
             help = "the top number of reference cell type score for each test cell to visulize on heatmap.")
sub_celltype$add_argument("--colorschema", type = "character", default = NULL,
             help = "the default color schema mapping for valus in each heatmap cell. The format:low, middle, high.")
sub_celltype$add_argument("--palette",type = "character",default= "customecol2",
             help="the discrete color schema for each cell types, customecol2 as default. Choices: customecol2:50;blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,colx22_custom:22,cyclic:20,tableau20:20, paired:12, purplegray12:12, cellchat:26, cellchat_custom:26, cellpaper:30, cellpaper_custom:59")
sub_celltype$add_argument("--reduct", type = "character", default = "umap",
             help = "[OPTIONAL]the reduction results used to embedding the celltypeing results.[default: %(default)s]")
sub_celltype$add_argument("--species", type = "character", default = "human",
             help = "[OPTIONAL]the organism both test and reference data derived.[default: %(default)s]")


# create the parsers for subcommand merge
sub_merge = subparsers$add_parser("merge",  help = "merge data object")
sub_merge$add_argument( "--toadd", type = "character",
             help = "one or more of object list to merge into the target object.")
sub_merge$add_argument( "--adformat", type = "character",
             help = "The format of input expression matrix to add")
sub_merge$add_argument( "--mergedata", type = "character",
             help = "logical string T/F to indicate wether to merge the data slot")

# create the parsers for subcommand summarize
sub_summ = subparsers$add_parser("summarize", help = "summarized statistics for clustering results")
sub_summ$add_argument( "-c", "--groupby", type = "character", default = "clusters",
             help = "[OPTIONAL]visualize cell metadata by coloring cells in different color according to cell clustering metadata.[default: %(default)s].")
sub_summ$add_argument( "-b", "--facetby", type = "character", default = NULL,
             help = "[OPTIONAL]visualize cells in seperate plot split by this groupping variable, only 2D supported.")
sub_summ$add_argument( "-s", "--pointsize", type = "double", default = NULL,
             help = "[OPTIONAL]the point size in the plot.[default: %(default)s]")
sub_summ$add_argument( "-k", "--dims", type = "integer", default = 2,
             help = "[OPTIONAL]the 2D/3D of the plot.Currently 3D plot is only support in plotly style.[default: %(default)s]")
sub_summ$add_argument( "--reduct", type = "character", default = "umap",
             help = "[OPTIONAL]the previous calculated reduction result used in the scatter plot.[default: %(default)s]")
sub_summ$add_argument("--palette",type = "character",default= "customecol2",
             help="the discrete color schema for each cell groups, customecol2 as default. Choices:customecol2:50;blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,colx22_custom:22,cyclic:20,tableau20:20, paired:12, purplegray12:12, cellchat:26, cellchat_custom:26, cellpaper:30, cellpaper_custom:59")
sub_summ$add_argument( "--dosummary", type = "character", default = "TRUE",
             help = "wether to plot the summary statistics of cells clustering.[default: TRUE]")
sub_summ$add_argument( c("--use_color_anno" ), type = "character",  default = TRUE,
                help = "[Optional]是否采用rds中注释的颜色信息，默认采用，若无则自动重新注释颜色。")
sub_summ$add_argument( c("--color_file" ), type = "character",  default = NULL,
                help = "[Optional]选填，输入以tab分隔的文件，第一列的列名为metadata列名，第一列为该列元素，第二列为对应的颜色.")
sub_summ$add_argument( c("--area_plot" ), type = "character",  default = FALSE,
                help = "[Optional]选填，是否要出折线占比图（area_plot），默认不出.")

# create the parsers for subcommand split
sub_split = subparsers$add_parser("split", help = "split the object according to the cell metadata.")
sub_split$add_argument("--splitby", type = "character", default = "ident",
                       help = "the cell annotation column name.If NOT supplied, %(default)s will be used as default!")


sub_findneighbor = subparsers$add_parser("findneighbor", help = "only find the clusters in the input data")
sub_findneighbor$add_argument( "-k", "--k_param", default = 20, type = 'integer',
    help = "Defines k for the k-nearest neighbor algorithm" )
sub_findneighbor$add_argument( "--nn_method", default = 'rann', type = 'character',
    help = "Method for nearest neighbor finding. Options include: rann (default), annoy(faster)" )
sub_findneighbor$add_argument( "-a", "--dist_metric", type = 'character', default = "euclidean",
    help = "Distance metric. Options include: euclidean (default), cosine, manhattan, and hamming" )
sub_findneighbor$add_argument( "--graph_name", type = 'character', default = NULL,
    help = "Name of graph to use for the clustering algorithm." )
sub_findneighbor$add_argument( "--force_recalc", type = "character", default = "FALSE",
    help = "Force recalculation of SNN" )
sub_findneighbor$add_argument( "--reduction", type = 'character', default = "pca",
    help = "one or more reductions to use as input for building the (S)NN for mono-modal or multi-modual assays." )
# sub_findneighbor$add_argument( "-f", "--features", default = NULL, type = 'character',
#     help = "Comma-separated list of genes to use for building SNN. Alternatively, text file with one gene per line." )
# sub_findneighbor$add_argument( "--reduction", default = NULL, type = 'character',
#     help = "one or more Reduction  to use as input for building the SNN" )
sub_findneighbor$add_argument( "--dims", default = "1:15", type = 'character',
    help = "Dimensions of reduction to use as input. A comma-separated list of the dimensions to use in construction of the SNN graph." )

# create the parsers for subcommand removeEmptyDrops
sub_removeEmpty = subparsers$add_parser("rmambients", help = "remove the empty droplet using DropletUitls")
sub_removeEmpty$add_argument("--fdr", type = "double", default = 0.25,
             help = "the significance level for a cell to be identified as an empty droplet.")
sub_removeEmpty$add_argument("--iters", type = "integer", default = 1000,
             help = "the iteration to be used in calculation.")

# calculate the score of gene modules
sub_score = subparsers$add_parser("score", help = "calculate the gene module score")
sub_score$add_argument("--name", type = "character", default = NULL,
        help = "the  name of internal gene set. Choices can be:Macosko_mouse, Macosko_human, Jeny2020")
sub_score$add_argument("--gmt", type = "character", default = NULL,
        help = "the gene sets in gmt format for calculation.")
sub_score$add_argument("--min.size", type = "integer", default = 5,
        help = "the minimal number of genes in each gene set.[default: %(default)s]")
sub_score$add_argument("--plot", type = "character", default = NULL,
        help = "methods used to visualize the gene module score of each cell. Choices:NULL,vlnplot, featureplot. [default: NULL] no plot")
sub_score$add_argument("-g", "--groupby", type = "character", default = "clusters",
        help = "[OPTIONAL]The grouppinig variable in the metadata for separate the cells to visulize marker genes.")
sub_score$add_argument("--dodge", type = "character", default = "FALSE",
        help = "[OPTIONAL]visualize the feature between the contrast groups separately for each level in variable specified by --groupby.")
sub_score$add_argument("-y", "--splitby", type = "character", default = NULL,
        help = "[OPTIONAL]the variable in the metadata used to split the graph by the variable levels to comparing the module difference in different levels.")
sub_score$add_argument("--ccolors", type = "character", default = "spectral",
        help = "[OPTIONAL]the name of customized continious color palatte, recommandations:spectral, solar_extra,flame_light or color scale used to map the continious expression value for feature plot or dotplot,format:low_color,high_color.[default: %(default)s]")

# create the parsers for subcommand fetech
sub_fetch = subparsers$add_parser("fetch", help = "Retreives data (feature expression, PCA scores, metrics, etc.)")
# for a set of cells.A table with cells as rows and cellular data as columns returns.
sub_fetch$add_argument("--vars",
            help = "comma seperated List of all variables to fetch, use keyword ident to pull identity classes.")
sub_fetch$add_argument("--header",
            help = "[OPTIONAL]change the header of the output table if specified. Notice that the first column is always the cell barcode.")

# create the parsers for subcommand downsample
sub_downsample = subparsers$add_parser("downsample", help = "downsample the exppression matrix in case of too many cell and scarcely disequal cell numbers in each sample")
sub_downsample$add_argument("--targetN", type = "integer",
              help = "the number of cell to keep after downsample.")
sub_downsample$add_argument("--usePCA", type = "character", default = "TRUE",
              help = "logical parameter indicating wether to use fbpca during before downsample.[default: TRUE]")
sub_downsample$add_argument("--subsampleby", type = "character",
             help = "radom subsample by the specified group using the specified ratio,example:'clusters:0.5'.")


sub_vis = subparsers$add_parser("visualize", help = "visualize the specified features.")
sub_vis$add_argument("-l", "--markers",type ="character",
        help="the file of marker genes table to be visulized.")
sub_vis$add_argument("-n", "--topn", type="integer", default = 10,
        help = "the number of top markers for each cluster to visualizse.")
sub_vis$add_argument("-z", "--flip", type = "character", default = "FALSE",
        help = "气泡图横纵坐标调整，默认横坐标为基因，纵坐标为clusters")
sub_vis$add_argument("-d", "--dotsplit", type = "character", default = "FALSE",
        help = "气泡图是否按照基因列表分列，中间添加gap并进行标题简写")
sub_vis$add_argument("-c", "--topby", type = "character", default = "gene_diff",
        help="the column used to pick top n marker genes.The option can be one of the column in the input marker genes table.")
sub_vis$add_argument("-x", "--extraGene", type = "character", default = NULL,
        help = "[OPTIONAL]The extra gene list of interest to visualize specified by the user.[default: NULL]")
sub_vis$add_argument("-m", "--vismethod",type= "character",default="vlnplot,featureplot",
        help = "the visulization methods for the marker genes. Choices can be: ridgeplot,vlnplot,splitby_featureplot,dotplot,featureplot,boxplot.")
sub_vis$add_argument("--pvalue",type= "character",default = NULL,
        help = "[OPTIONAL]use like GROUP1:GROUP2+GROUP2:GROUP3 to add pvalue on vlnplot or boxplot.")
sub_vis$add_argument("-g", "--groupby", type = "character", default = "clusters",
        help = "[OPTIONAL]The grouppinig variable in the metadata for separate the cells to visulize marker genes.")
sub_vis$add_argument("--dodge", type = "character", default = "FALSE",
        help = "[OPTIONAL]visualize the feature between the contrast groups separately for each level in variable specified by --groupby.Only valid for violin plot!")
sub_vis$add_argument("-y", "--splitby", type = "character", default = NULL,
        help = "[OPTIONAL]the variable in the metadata used to split the graph by the variable levels to comparing the gene expression difference in different levels.[default: NULL]")
sub_vis$add_argument("--ccolors", type = "character", default = "spectral",
        help = "[OPTIONAL]the name of customized continious color palatte, recommandations:spectral, solar_extra,flame_light or color scale used to map the continious expression value for feature plot or dotplot,format:low_color,high_color.[default: %(default)s]")
sub_vis$add_argument("--vcolors", type = "character", default = "customecol2",
        help = "[OPTIONAL]the name of customized discrete color used to map to the cell groupping variable.[default: %(default)s]Choices:blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,cyclic:20,tableau20:20,Buen:17,UKBB:18,TF1:17,paired:12")
sub_vis$add_argument("-s", "--pointsize", type = "double", default = 0.1,
        help = "[OPTIONAL]the point size in the plot.")
# sub_vis$add_argument("--sample_ratio", type = "double", default = 0.6,
#         help = "[OPTIONAL]the ratio of random subsample for each group when drawing heatmap.")
sub_vis$add_argument("--reduct", type = "character", default = "umap",
        help = "[OPTIONAL]the previous calculated reduction result used in the featureplot,.")
sub_vis$add_argument("-a", "--alpha2use", type = "double", default = 0,
        help = "[OPTIONAL]the opacity of the pooints on the violin plot.")
sub_vis$add_argument("--xlab", type = "character", default = "TRUE",
        help = "[OPTIONAL]show xlab or not")
sub_vis$add_argument( c("--use_color_anno" ), type = "character",  default = TRUE,
                help = "[Optional]是否采用rds中注释的颜色信息，默认采用，若无则自动重新注释颜色。")
sub_vis$add_argument( c("--color_file" ), type = "character",  default = NULL,
                help = "[Optional]选填，输入以tab分隔的文件，第一列的列名为metadata列名，第一列为该列元素，第二列为对应的颜色.")

sub_markers = subparsers$add_parser("findallmarkers", help = "find markers between all groups.")
sub_markers$add_argument( "--min_pct1", "-t", type = "double", default = 0.5,
       help ="the minimium ratio of cells expressing one specific gene in a cluster.[default: %(default)s]")
sub_markers$add_argument( "--max_pct2", "-T", type = "double", default = 0.5,
       help ="the maximiium ratio of cells expressing one specific gene in all other clusters.[default: %(default)s]")
sub_markers$add_argument( "--pct_fold", "-c", type = "double", default = 2,
       help ="the minimiu fold of pct1 for gene in a specific cluster against pct2 for all other cluster.[default: %(default)s]")
sub_markers$add_argument( "--topn_marker","-N", type = "integer",default = 10,
       help = "the maximium number of ranked marker genes on the top for each cluster.[default: %(default)s]")
sub_markers$add_argument( "--avg_log2FC","-k", type = "double", default = 1,
       help = "The average log2FC of the gene UMI count in its cluster against the all other clusters.[default: %(default)s]")
sub_markers$add_argument( "--pvalue","-p", type = "double", default = 0.05,
       help = "the P-value of the gene differential expression.[default: %(default)s]")
sub_markers$add_argument( "--cluster_name", "-n", type = "character", default = NULL,
       help = "the name of groupping column from clustering result metadata used to find markers. The example can be tsne.2D.res.1.")
sub_markers$add_argument( "--FDR","-q", type = "double", default = 0.1,
       help = "the FDR of the gene differential expression.")
sub_markers$add_argument( "--strict","-s", type = "character", default = "FALSE",
       help = "whether to use strict mode, using all the filtering options, to find markers. Notice that, this may result in no markers remain for some clusters.")
sub_markers$add_argument( "--test","-e", type = "character", default = "wilcox",
       help = "test methods used to cell markers.[default: %(default)s] Options are: wilcox,presto,venice, t, bimod,poisson, negbinom, MAST, DESeq2, DESeq2LRT,limma, edgeR.")
# 'wilcox' : Wilcoxon rank sum test (default).
# 'presto' : performace improved Wilcoxon rank sum test for big data.
# 'venice' : package from bioTuning with function VeniceAllMarkers imtating the FindAllMarkers in Seurat but much faster.")
# 't' : Student\'s t-test.
# 'bimod' : Likelihood-ratio test for single cell gene expression, (McDavid et al., Bioinformatics, 2013).
# 'poisson' : Likelihood ratio test assuming an underlying poisson distribution. Use only for UMI-based datasets.
# 'negbinom' : Likelihood ratio test assuming an underlying negative binomial distribution. Use only for UMI-based datasets.
# 'MAST' : GLM-framework that treates cellular detection rate as a covariate (Finak et al, Genome Biology, 2015).
# 'DESeq2' : DE based on a model using the negative binomial distribution (Love et al, Genome Biology, 2014).


# create the parsers for subcommand update
sub_update = subparsers$add_parser("update",
          help = "update the main data object using annotation from other data object or external info.")
sub_update$add_argument("--admeta", type = "character",
          help = "the additional metadata which includes any groupping design in this assay.")
sub_update$add_argument("--annlevel", type = "character", default = "sample",
          help = "the annotation level,sample or cell is supported.")
sub_update$add_argument("--recode", type = "character", default = NULL,
          help = "rename the level id in specified groups in the file with each column corresponding to header in the object metadata and column element format as from:to.")
# sub_update$add_argument("--adfeatures", type = "character",
#           help = "the additional metadata of genes in the object.")


sub_write10x = subparsers$add_parser("write10x", help = "save the data object into the format from 10X Genomics.")
sub_write10x$add_argument("--split.by", "-x", type = "character", default = NULL,
          help = "the groupping variable of cells used to split the data object.[default: %(default)s]")
sub_write10x$add_argument("--overwrite", type = "character", default = "TRUE",
          help = "wether to overwrite the existed data object.[default: %(default)s]")
sub_write10x$add_argument("--version", "-v", type = "character", default = "3",
          help = "the version of cellranger to format the output to.[default: %(default)s]")
sub_write10x$add_argument("--h5", type = "character", default = "FALSE",
          help = "Wether to save the count matrix in hdf5 format defined by 10X Genomics.[default: %(default)s]")

sub_findhvg = subparsers$add_parser("findhvg", help = "features extraction of highly variable features.")
sub_findhvg$add_argument("--select-method", type = "character", default = "vst",
          help = "methods to choose top variable features. Choices:vst, mean.var.plot, dispersion and markvariogram, moransi sepecifi for spatial data.[default: %(default)s]")
sub_findhvg$add_argument("--loess-span", type = "double", default = 0.3,
          help = "(vst only)Loess span parameter used when fitting the variance-mean relationship.[default: %(default)s] Only used when selection method is set to 'dispersion' or 'vst'.")
sub_findhvg$add_argument("--nfeature", type = "integer", default = 2000,
          help = "Number of features to select as top variable features.[default: %(default)s]")

sub_dimreduce = subparsers$add_parser("dimreduce", help = "dimension reduction.")
sub_dimreduce$add_argument("-t", "--components", type="integer", default=NULL,
             help="the appropriate number of dimensions for primary reduction. Recommendations:pca:30,mnn:10[default: %(default)s]")
sub_dimreduce$add_argument( "--perplexity", "-p", type="integer", default=30,
           help="The value of the perplexity used for tSNE")
sub_dimreduce$add_argument( "--rerun", type="character", default = "FALSE",
           help="[OPTIONAL]wether to rerun the reduction to overwrite the previous results.[default: FALSE]")
sub_dimreduce$add_argument( "--reduct1", type = "character",default=NULL,
           help="[OPTIONAL]the primary reduction methods whose results can be used as input for secondary reduction. The supported methods can be one of the followings: ica, cca, pca, rpca, lsi, svd, mnn, harmony, tsne, flt-tsne, umap, diffusion.")
sub_dimreduce$add_argument( "--reduct2",type = "character",default="tsne",
           help="one or more of the scondary dimension reduction methods used for this run. the options can be tsne, flt-sne, umap, duffusion, swne. That is to say not all the primary redcution method can used as scondary one.")
sub_dimreduce$add_argument( "--batchid", type = "character", default = NULL,
             help = "[OPTIONAL]the batch information column name of sample in the metadata.")


sub_clusterx = subparsers$add_parser("clusterx", help = "universal interface of clustering methods")
sub_clusterx$add_argument("--algorithm", type="character", default = "snn",
             help="the only supported clustering algorithm currently:snn,louvain,leiden. For other methods, use subcommand 'clusterx'." )
sub_clusterx$add_argument("-r", "--resolution", type = "double", default = 0.4,
             help = "vaule used to set the resolution of cluster distiguish, use a value above(below)1.0 if you want to obtain a larger(smaller) number of communities.[default: %(default)s]")
sub_clusterx$add_argument( "--graphid", type = "character", default = NULL,
             help = "the graph name used to find communities.[default: NULL]")
sub_clusterx$add_argument("--palette",type = "character",default= "customecol2",
             help="the discrete color schema for each cell cluster, customecol2 as default. Choices:customecol2:50;blindless:69,cold:32,glasbey:32,ditto:24,alphabet:26,alphabet2:26,colx22:22,colx22_custom:22,cyclic:20,tableau20:20, paired:12, purplegray12:12, cellchat:26, cellchat_custom:26, cellpaper:30, cellpaper_custom:59")
sub_clusterx$add_argument("-s", "--pointsize", type = "double", default = 0.5,
             help = "[OPTIONAL]the point size in the plot.")

sub_diffexp = subparsers$add_parser("diffexp", help = "differential test between specified groups.")
sub_diffexp$add_argument("-x", "--design", type = "character", default = NULL,
          help = "The group design for cell clusters or samples to make differential expression analysis.")
sub_diffexp$add_argument("-M", "--addition_metadata", type="character", default = NULL,
          help="[Optional]additional metadata for each sample which includes sample id and additional sample groupping info.")
sub_diffexp$add_argument("-c","--contrast", type = "character",default = NULL,
          help = "[Optional]levels of a factor used to compare with for final differenetial results. The format is Factor:interesting_levle:reference_level.")
sub_diffexp$add_argument("-k", "--FC", type = "double", default = 1,
          help = "The average FC of the gene UMI count in its cluster against the all other clusters.")
sub_diffexp$add_argument("-p", "--pvalue", type = "double", default = 0.05,
          help = "the P-value of the gene differential expression.",metavar = "P-value")
sub_diffexp$add_argument("--fdr","-q", type = "double", default = NULL,
          help = "the FDR of the gene differential expression.",metavar = "FDR")
sub_diffexp$add_argument("--test","-e", type = "character", default = "wilcox",
          help = "the test methods used to find differential expressed genes between specified group levels.[default: %(default)s] Options are:wilcox,presto,venice,limma,roc,t,bimod,poission negbinom,scde,MAST,DESeq2,DESeq2LRT,edgeR.")

# add_annotation
sub_annotation = subparsers$add_parser("annotation", help = "add annotation for genelist.")
sub_annotation$add_argument("-g","--genelist", type = "character", default = NULL,
       help = "The gene list file ")
sub_annotation$add_argument("-a","--anno", type = "character", default = NULL,
       help = "The gene annotation file: gene_annotation.xls")
# changecelltype
sub_changecelltype = subparsers$add_parser("changecelltype", help = "add annotation for genelist.")
sub_changecelltype$add_argument("-c","--celltype", type = "character", default = NULL,
       help = "The celltype file ")
sub_changecelltype$add_argument("-b","--barcode", type = "character", default = FALSE,
       help = "[OPTIONAL]The celltype file base on barcode or not")
sub_changecelltype$add_argument("--palette", type = "character", default = "customecol2",
       help = "The color scheme")
sub_changecelltype$add_argument("-r","--reduct", type = "character", default = "umap",
       help = "The reduction to visualize")
sub_changecelltype$add_argument("-C","--cluster", type = "character", default = "clusters",
       help = "The Columns used to modify cell types")
sub_changecelltype$add_argument("-B","--extrabarcode", type = "character", default = NULL,
       help = "The Columns used to modify cell types")
sub_changecelltype$add_argument("--order", type = "character", default = FALSE,
       help = "[Optional]是否按照tsv顺序注释细胞类型")
sub_changecelltype$add_argument( c("--use_color_anno" ), type = "character",  default = FALSE,
                help = "[Optional]是否采用rds中注释的颜色信息，默认采用，若无则自动重新注释颜色。")
sub_changecelltype$add_argument( c("--color_file" ), type = "character",  default = NULL,
                help = "[Optional]选填，输入以tab分隔的文件，第一列的列名为metadata列名，第一列为该列元素，第二列为对应的颜色.")


sub_removedbls = subparsers$add_parser("rmdoublets", help = "remove doublets.")
sub_removedbls$add_argument("--dbl_rates", type = "double", default = 0.06,
                            help = "the expected doublets rate in each sample.")
sub_removedbls$add_argument("--method", type = "character", default = "scrublet",
                            help = "the method used to detect doublets, choices: scrublet, doubletfinder.[default: %(default)s]")
sub_removedbls$add_argument("--subset", type = "character", default = "TRUE",
                            help = "logical indication of wether to subset the data object for only singlets.[default: TRUE]")
sub_removedbls$add_argument("--ident", type = "character", default = "clusters",
                            help = "[OPTIONAL]ONLY AVAILABLE for doubletfinder,the name of cell group annotation.")

sub_refd = subparsers$add_parser("preparerefd", help = "prepare the single cell reference data appropriate for SingleR.")

sub_rmbatch = subparsers$add_parser("rmbatch", help = "remove batches among data sets.")

# create the parsers for subcommand metacell
sub_metacell = subparsers$add_parser("metacell", help = "produce cell count matrix of metacell")

sub_callpeak = subparsers$add_parser("callpeak", help = "call peak for each group of cell for scATAC-seq")
sub_callpeak$add_argument("--groupby", type = "character", default = "clusters",
                          help = "Grouping variable to use. If set, peaks will be called independently on each group of cells and then combined. Note that to call peaks using subsets of cells we first split the fragment file/s used, so using a grouping variable will require extra time to split the files and perform multiple MACS peak calls, and will store additional files on-disk that may be large. Note that we store split fragment files in the temp directory, and if the program is interrupted before completing these temporary files will not be removed. If NULL, peaks are called using all cells together (pseudobulk).")
sub_callpeak$add_argument("--mac2", type = "character", default = NULL,
                          help = "Path to MACS program. If NULL, try to find MACS automatically.")
sub_callpeak$add_argument("--broad", type = "character", default = "FALSE",
                          help = "whether to Call broad peaks (--broad parameter for MACS).")
sub_callpeak$add_argument("--ident", type = "character", default = NULL,
                          help = "List of identities to include if grouping cells (only valid if also setting the group.by parameter). If NULL, peaks will be called for all cell identities.")
sub_callpeak$add_argument("--combine", type = "character", default = NULL,
                          help = "Controls whether peak calls from different groups of cells are combined using GenomicRanges::reduce when calling peaks for different groups of cells (group.by parameter). If FALSE, a list of GRanges object will be returned. Note that metadata fields such as the p-value, q-value, and fold-change information for each peak will be lost if combining peaks.")
sub_callpeak$add_argument("--chunk", type = "integer", default = 2000,
                          help = "Number of regions to load into memory at a time, per thread. Processing more regions at once can be faster but uses more memory.")

# create the parsers for subcommand integrate
sub_transfer = subparsers$add_parser("transfer", help = "integrate multiple data objects.")
sub_transfer$add_argument("--algrithms", type = "character", default = "seurat",
          help = "the algrithms used integrate the different data objects, choices: seurat, harmony, liger, conos.")


# create the parsers for subcommand impute
sub_impute = subparsers$add_parser("impute", help = "impute the missing values in count matrix.")
sub_impute$add_argument("--method", type = "character", default = "magic",
          help = "the method used to impute the sparse matrix.[default: %(default)s]")
sub_impute$add_argument("--slot", type = "character", default = "counts",
          help = "the name of the matrix to impute of the specified assay")


# create the parsers for subcommand summary
sub_summary = subparsers$add_parser("summary", help = "print the summary statitics of data object")

# run copy number variation inference useing infercnv
sub_infercnv = subparsers$add_parser("infercnv", help = "infer copy number variation from single cell expression raw counts.")
sub_infercnv$add_argument("-g", "--gene_order", type = "character",
             help = "[OPTIONAL]The tab-delimited gene_order_file of the positions for each gene along each chromosome without header, with columns: chromosome, start, and stop position")
sub_infercnv$add_argument("-t", "--malignant", type = "character",
             help = "the cell type name to be assumed as cancer cells")
sub_infercnv$add_argument("-l", "--celltype", type = "character",
             help = "the cell type annotation column name to use in seurat metadata.")
sub_infercnv$add_argument("-u", "--mode", type = "character", default = "subclusters",
             help = "Grouping level for image filtering or HMM predictions. Options can be:samples: fastest, but subclusters is ideal. subclusters: detect the subclusters  of tumor")
sub_infercnv$add_argument("-m", "--clusting2use", type = "character", default = "ward.D2",
             help = "the hierarchical clustering methods of cells to use. Valid choices are: 'ward.D', 'ward.D2', 'single', 'complete', 'average', 'mcquitty', 'median', 'centroid'.")
sub_infercnv$add_argument("-r", "--refgroup", type = "character",
             help = "a comma seperated list containing the classifications of the reference (normal) cells to use for infering cnv. If the normal reference cell is supplied from customized source, all the reference cell type will be named as 'normal'.")
sub_infercnv$add_argument("--refexp", type = "character",
             help = "[OPTIONAL]the reference (normal) cells expression count matrix for inferring cnv.")
sub_infercnv$add_argument( "--gtf", "-z", type = "character",
             help = "the exact gtf file for the alignment for this project.")
# make_option( c("--chr2exclude", "-x"), type = "character", default = "chrM",
#     help = "list of chromosomes in the reference genome annotations that should be excluded from analysis."),
sub_infercnv$add_argument( "--cutoff", "-c", type = "double", default = 0.1,
            help = "min average read counts per gene among reference cells. cutoff=1 works well for Smart-seq2, and cutoff=0.1 works well for 10x Genomics.")
sub_infercnv$add_argument( "--doHMM",type="character", default = "FALSE",
            help="wether to using HMM when predicting the CNV for each cell. If no CNV gene prediction needed, Set it False to save time." )
sub_infercnv$add_argument("--do-cnvlevel", type = "character", default = "FALSE",
            help = "wether to calculate the cnv level for each cell.")
sub_infercnv$add_argument( "--pval","-p",type="double", default = 0.05,
            help="max p-value for defining a significant tumor subcluster." )

sub_vdj = subparsers$add_parser("vdj", help = "parse the output of cellranger vdj to integrate.")
sub_vdj$add_argument("--vdj", type = "character", default = "./",
       help = "the directory of 10X cellranger vdj results directory with each sample as subdirectory or the directory with file filtered_contig_annotations.csv,clonotypes.csv, all_contig_annotations.json,all_contig.fasta.")
sub_vdj$add_argument("--metadata", "-m", type="character", default = NULL,
       help="the sample metadata which must include sample id in this assay design.")
sub_vdj$add_argument("--type", "-t", type="character", default = NULL,
       help="the type of immunological cell receptor: TCR or BCR.")
sub_vdj$add_argument("--seurat", "-s", type="character", default = NULL,
       help="add the clonotype annotation to the seurat as an assay.")
sub_vdj$add_argument("--quant.use", "-q", type = "character", default = "umi",
       help = "count number for each clonotype in each sample, choices can be: cells: the number of cell for each clonotype in each sample; umi: the UMI number for each clonotype in each sample; reads：the reads for each clonotype in each sample. [default: umi]")
sub_vdj$add_argument("--maketse", "-e", type = "character", default = "FALSE",
       help = "whether to construct the TreeSummarizedExperiment object to store data for later diversity analysis.[default: FALSE]")
sub_vdj$add_argument("--bcprefix", "-x", type = "character", default = "sampleid",
       help = "prefix the cell barcode with sample id or row index in metadata.tsv. Options can be sampleid or index.[default: %(default)s]")
sub_vdj$add_argument("--vdjformat", "-v", type = "character", default = "vdjtools",
       help = "the output format of the V(D)J clonotypes table. Options can be vdjtools or immunarch.[default:vdjtools]")


sub_runcicero = subparsers$add_parser("runcicero", help = "run Cicero for predicting gene activity, CCANS and Links.")
sub_runcicero$add_argument("--window","-w", type = "integer", default = 500000,
                            help = "the genome sliding window to determine the distance threshold for calculating coaccess peaks. [default: 500000].")
sub_runcicero$add_argument("--run-ccan", type = "character", default = "FALSE",
                           help = "[OPTIONAL]wether to find cis-Co-accessibility Networks (CCANS).[default: FALSE]")
sub_runcicero$add_argument("--do-norm", type = "character", default = "TRUE",
                           help = "[OPTIONAL]wether to normalize the count matrix from cicero.[default: TRUE]")

sub_monocl3 = subparsers$add_parser("monocle3", help = "run monocle3 on the input data object")
sub_monocl3$add_argument("--reduct", type = "character", default = "umap",
                         help = "the reduction method used for trajectory.")

sub_st_deconv = subparsers$add_parser("st_deconv", help = "deconvolute the compositions of cell types for spatial transcriptomics or bulk transcriptomics data using scRNA-seq data.")

# create the parsers for subcommand multimodal
sub_monocle = subparsers$add_parser("monocle", help = "run monocle2 on the input data object.")
sub_monocle$add_argument("--components", "-t", type = "integer", default = 20,
     help = "the appropriate number of statistically significant components to use for clustering, which derived from the JackStraw result.")
sub_monocle$add_argument("--min.cell", "-x", type = "double", default = 0,
     help = "the minimium proportion of cell number one gene detected", metavar = "minimium proportion")
sub_monocle$add_argument("--batch", "-b", type = "logical", default = F,
     help = "Wether to remove batch effect using combat from sva package.")    
sub_monocle$add_argument("--perplexity", "-p", type = "integer", default = 30,
     help = "The value of the perplexity used for tSNE")     
sub_monocle$add_argument("--metadata", "-m", type = "character", default = NULL,
     help = "the sample metadata which must include sample id in this assay design.")   
sub_monocle$add_argument("--from", type = "character", default = NULL,
     help = "the original cluster id used in calibrate the clustering results.")         
sub_monocle$add_argument("--to", type = "character", default = NULL,
     help = "the adjusted cluster id used in calibrate the clustering results.")  
sub_monocle$add_argument("--resolution", "-r",type = "double", default = 1,
     help = "vaule used to set the resolution of cluster distiguish, use a value above(below)1.0 if you want to obtain a larger(smaller) number of communities.")  
sub_monocle$add_argument("--colorby", "-C", type = "character", default = "clusters,sampleid,group,State",
     help = "[Otional]visualize cells' metadata by coloring cells in different color according to cell grouping list.")  
sub_monocle$add_argument("--pointsize", "-s", type = "double", default = 1,
     help = "[Otional]the point size in the plot.")                          
sub_monocle$add_argument("--design", "-d", type = "character", default = "clusters",
     help = "[Otional]The group design to find ordering genes.")       
sub_monocle$add_argument("--downsample", "-e", type = "character", default = "30000",
     help = "the downsample number of cells.")          
sub_monocle$add_argument("--topn", "-n", type = "integer", default = NULL,
     help = "the subset of ordering gene.")  
sub_monocle$add_argument("--rds", type = "character", default = NULL,
     help = "[Otional]The pseudotime_result.rds input to replot.") 
sub_monocle$add_argument( c("--use_color_anno" ), type = "character",  default = TRUE,
                help = "[Optional]是否采用rds中注释的颜色信息，默认采用，若无则自动重新注释颜色。")
sub_monocle$add_argument( c("--color_file" ), type = "character",  default = NULL,
                help = "[Optional]选填，输入以tab分隔的文件，第一列的列名为metadata列名，第一列为该列元素，第二列为对应的颜色.")
sub_monocle$add_argument( c("--palette" ), type = "character",  default = NULL,
                help = "[Optional]选填，根据需求指定离散型色板名.")

opt = parser$parse_args()
`%!in%` <- Negate(`%in%`) # 方便predicate反向筛选

#================== GLOBAL PARAMETERS PARSING ===================================
# setting the output directory
if ( is.null(opt$output) ){
    print("NO output directory specified,the current directory will be used!")
    output_dir = getwd()
}else{
    if ( file.exists(opt$output) ){
        output_dir = opt$output
    }else{
        output_dir = opt$output
        dir.create(output_dir,recursive = T)
    }
}
output_dir = normalizePath(output_dir )

# check the input data object
if ( is.null(opt$dataslot) ){
  dataslots = NULL
}else{
  dataslots = unlist( strsplit(opt$dataslot, ",") )
}

if ( !is.null(opt$subassay) ){
  assays =  union(opt$assay, unlist(strsplit(opt$subassay,",")))
}else{
  assays = opt$assay
}


invisible(gc(full = T, verbose = F))
options(future.globals.maxSize= Inf ) # setting the maxumium mermory usage much bigger in case of big data
future::plan("multicore", workers = min(future::availableCores(), opt$ncores)) # parallization using specified CPUs start from here

# print(dataslots)
# stop("XXXXXA")

#================== SUBCOMMAND INVOKE ==========================================
# ================ Subcmd: create data object from specified source ========
args<-commandArgs(TRUE)

if ( "create" %in% args ){ # create data object from raw data source
  # collect the additional parameters

  data_ob <- switch (tolower(opt$source),
    "mtx" = { # data come from cellranger count results in mtx format
      seux = OESingleCell::CreateX(data.dir = opt$input,
                                   assay.meta = opt$metadata,
                                   source = opt$source, assay = opt$assay,
                                   aggr = as.logical(opt$aggr),
                                   add.meta = as.logical(opt$cell.meta),
                                   use.fragment = as.logical(opt$fragment),
                                   gene.column = opt$gcolumn,
                                   gtf = opt$feature.meta,
                                   chrom.size = opt$chrom.size)
    },
    "h5" = { # read raw data from cellranger count results in hdf5 format
      seux = OESingleCell::CreateX(data.dir = opt$input,
                                   assay.meta = opt$metadata,
                                   add.meta = as.logical(opt$cell.meta),
                                   use.fragment = as.logical(opt$fragment),
                                   source = opt$source, assay = opt$assay,
                                   aggr = as.logical(opt$aggr),
                                   gtf = opt$feature.meta,
                                   chrom.size = opt$chrom.size)
    },
    "xsv" = { # data from text file
      seux = OESinleCell::CreateX(data.dir = opt$input, assay.meta = opt$metadata,
                     add.meta = as.logical(opt$cell.meta),
                     source = opt$source, assay = opt$assay, aggr = as.logical(opt$aggr),
                     gene.column = opt$gcolumn, transpose = as.logical(opt$transpose), random.barcode = TRUE )
    }
  )
  if (opt$mixSpecies != "no"){
    source("/gpfs/oe-scrna/pipeline/scRNA-seq_further_analysis/function/seuratFc.r")
    data_ob = mix_Species_Split(input_dir = opt$input, data_ob = data_ob, mixSpecies = opt$mixSpecies)
  }
  if ( !is.null(opt$gset) ){
    # gmt = GSEABase::getGmt(con=opt$gset)
    gmt_list = unlist(strsplit(opt$gset,",",perl = T))
    #gset_list = GSEABase::geneIds(GSEABase::getGmt(con=opt$gset))
    gset_list <- lapply(gmt_list, function(gmtfile){
                        gset_list <- GSEABase::geneIds(GSEABase::getGmt(con=gmtfile))  
                        return(gset_list)
    })
    for (i in c(1:length(gset_list))){
        data_ob = OESingleCell::CalculateMetrics(data_ob, metrics = NULL, gset = gset_list[[i]])
    }
  } else if (!is.null(opt$metrics)) {
    # metrics = c("percent.mito", "CC.difference"),
    metrics = unlist( strsplit(opt$metrics, ","))
    data_ob = OESingleCell::CalculateMetrics(data_ob, metrics = metrics)
  }

  if ( !is.null(opt$feature.meta) ){
    data_ob = OESingleCell::addFeatureAnno( data_ob,
                                            assay = opt$assay,
                                            gtf = opt$feature.meta)
  }
  # 添加group和sampleid颜色信息
  for ( samplename in c("sampleid","group")){
      if ( samplename %in% colnames(data_ob@meta.data) ) {
            data_ob@meta.data[[samplename]]=factor(data_ob@meta.data[[samplename]],levels=unique(data_ob@meta.data[[samplename]]))
            # nfacet <- length(unique(data_ob@meta.data$sampleid))
            #color_schema = OESingleCell::SelectColors(palette ="customecol2")
            # colors2use = color_schema[11:(10+nfacet)]
            color_schema = get_colors(data_ob@meta.data, groupby = samplename, palette ="customecol2")
            print("写入sampleid_col作为颜色信息")
            data_ob = Seurat::AddMetaData(data_ob, metadata = color_schema[["object_meta"]])
            print(table(data_ob@meta.data[,paste0(samplename,"_col")]))
        }
    }

  # Now the h5seurat format is used as the standard data object in disk or better interpre
  if ( tolower(opt$outformat) == "h5seurat" ){
    prefix = file.path(output_dir, opt$prefix)
    SeuratDisk::SaveH5Seurat(data_ob, filename = glue::glue("{prefix}.h5seurat") ,
                             overwrite = TRUE, verbose = FALSE)
  }else{
    OESingleCell::SaveX(data_ob, output = output_dir,
                        outformat = opt$outformat, prefix = opt$prefix, update = FALSE )
  }
  quit()
}


# ================ Subcmd: multimodal, create data object from multimodal assay ========
if ( "multimodal" %in% args ){ # create data object from raw data source
  # collect the additional parameters
  data_ob <- switch (tolower(opt$source),
    "h5" = { # read raw data from cellranger count results in hdf5 format
      seux = OESingleCell::CreateMultiModal(data.dir = opt$input,
                                   assay.meta = opt$metadata,
                                   add.meta = as.logical(opt$cell.meta),
                                   use.fragment = as.logical(opt$fragment),
                                   source = opt$source, assay = assays[1],
                                   gtf = opt$feature.meta,
                                   chrom.size = opt$chrom.size)
    },
    stop("Only hdf5 file SUPPORTED for multimodal assay!")
  )

  if ( !is.null(opt$gset) ){
    # gmt = GSEABase::getGmt(con=opt$gset)
    gset_list = GSEABase::geneIds(GSEABase::getGmt(con=opt$gset))
    data_ob = OESingleCell::CalculateMetrics(data_ob, metrics = NULL, gset = gset_list)
  }

  # metrics = c("percent.mito", "CC.difference"),
  if ( !is.null(opt$metrics) ){
    metrics = unlist( strsplit(opt$metrics, ","))
    data_ob = OESingleCell::CalculateMetrics(data_ob, metrics = metrics)
  }

  if ( !is.null(opt$feature.meta) ){
      data_ob = OESingleCell::addFeatureAnno( data_ob,
                                              assay = opt$assay,
                                              gtf = opt$feature.meta  )
  }

  # Now the h5seurat format is used as the standard data object in disk or better interpre
  if ( tolower(opt$outformat) == "h5seurat" ){
    prefix = file.path(output_dir, opt$prefix)
    SeuratDisk::SaveH5Seurat(data_ob, filename = glue::glue("{prefix}.h5seurat") ,
                             overwrite = TRUE, verbose = FALSE)
  }else{
    OESingleCell::SaveX(data_ob, output = output_dir,
                      outformat = opt$outformat, prefix = opt$prefix, update = FALSE )
  }
  quit()
}

# ======================== Subcmd: one stop of qc workflow ==================================
if ( "qc" %in% args ){
  # read the specified assay and data slot in data object into memory
  data_ob = ReadX(input = opt$input,
                                informat = opt$informat,
                                reductions = "pca",
                                assays = assays, # only RNA assay is valid
                                data.use = "counts",
                                verbose = F)
  # -c参数，获取要过滤的列
  filter_params = unlist(strsplit(opt$filters, ",", perl =T))
  # -r参数，获取数据回归列
  vars2regress = unlist(strsplit(opt$vars2regress, ",", perl =T))
  # 标准化
  data_ob@meta.data$log10GenesPerUMI <- log10(data_ob@meta.data$nFeature_RNA)/log10(data_ob@meta.data$nCount_RNA)

  if ( "CC.Difference" %in% vars2regress ){
      s.genes = Seurat::CaseMatch(search = Seurat::cc.genes$s.genes, match = rownames(data_ob) )
      g2m.genes = Seurat::CaseMatch(search = Seurat::cc.genes$g2m.genes, match = rownames(data_ob) )
      data_ob = Seurat::CellCycleScoring(data_ob, s.features = s.genes, g2m.features = g2m.genes,set.ident = F)
      cycleS = Seurat::FetchData(data_ob, vars = c("S.Score", "G2M.Score") )
      data_ob = OESingleCell::AddMetaData(data_ob, col.name = "CC.Difference",
                           metadata = cycleS[["S.Score"]] - cycleS[["G2M.Score"]])
  }

  # 质控分析
  # 获取样本数量，为后续排列图形做准备
  nsamples = length(unique(Seurat::FetchData(data_ob, vars = "sampleid" )[["sampleid"]]))
  if (nsamples <= 4){
    nsamples = nsamples
    ncol = 3
    height = 5
  }else{
    nsamples = nsamples/2
    ncol = 3
    height = 8
  }
  # 绘制小提琴图
  ggvln_before_QC = Seurat::VlnPlot(data_ob, features = filter_params,
                                   group.by = "sampleid", alpha = 0.5,
                                   pt.size = opt$pointsize, ncol = ncol)
  OESingleCell::save_ggplots( filename = file.path(output_dir,"QC_metrics_beforeQC"),
                             plot = ggvln_before_QC,
                             height = height,
                             limitsize = F,
                             width = nsamples*length(filter_params) + 3, bg="white" )
  # 去重
  summx_params = unique(c(filter_params, vars2regress))
  # 获取每个样本原始细胞数
  statistics_beforeQC_sim = Seurat::FetchData(data_ob, vars = c("sampleid") ) %>%
    dplyr::group_by(sampleid) %>%
    dplyr::summarise(
            Total_cells_beforeQC = dplyr::n()) %>%
    tibble::column_to_rownames(var = "sampleid")
  # 获取 summx_params（输入列） 的均值、中位值
  statistics_beforeQC =  Seurat::FetchData(data_ob, vars = c( summx_params,"sampleid") ) %>%
    dplyr::group_by(sampleid) %>%
    dplyr::summarise(
            dplyr::across(where(is.numeric),
                          list( ~ round(mean(.x, na.rm = TRUE), 3), ~ median(.x, na.rm = TRUE))) ,
            total_cells = dplyr::n()) %>%
    tibble::column_to_rownames(var = "sampleid")
  # 获取线粒体百分比的q90
  q90_mito =  Seurat::FetchData(data_ob, vars = c( "percent.mito","sampleid") ) %>%
    dplyr::group_by(sampleid) %>%
    dplyr::summarise(
            dplyr::across(where(is.numeric),
                          list( q90 = ~ quantile(.x, probs = 0.9, na.rm = TRUE))) ) %>%
    tibble::column_to_rownames(var = "sampleid")
  max_mito = max(q90_mito[,1])

  # 修改列名
  before_grid = expand.grid(c("mean", "median"), summx_params, "beforeQC")
  colx_before = c( paste( before_grid[[1]], before_grid[[2]], before_grid[[3]], sep = "_"),
                  "Total_cells_beforeQC")
  colnames(statistics_beforeQC)  = colx_before
  # QC
  if ( toupper(opt$QC) == "TRUE" ){
      # 线粒体按照超过细胞间线粒体UMIs中位数的四倍进行剔除过滤方式
      if (toupper(opt$mito_four) == "TRUE" ){
        # 解析最小过滤参数
        lower_threshold = sapply( unlist(strsplit(opt$lower, ",") ),
          function(x) ifelse(x == "NULL", NA, as.numeric(x)) )
        # 判断 过滤参数与输入列是否一致
        if ( length(lower_threshold) != length(filter_params) ){
          stop("The lower threshold setting is not consistant with the parameters in --filters!")}
        names(lower_threshold) = filter_params
        # 解析最大过滤参数
        upper_threshold = sapply( unlist(strsplit(opt$upper, ",") ),
          function(x) ifelse(x == "NULL", NA, as.numeric(x)) )
        if ( length(upper_threshold) != length(filter_params) ){
              stop("The upper threshold setting is not consistant with the parameters in --filters!")}
        names(upper_threshold) = filter_params
        # 创建输入列参数的边界列表
        bounds_list = list()
        for ( x in filter_params)  bounds_list[[x]] = c(min = unname(lower_threshold[x]), max = unname(upper_threshold[x]) )
        for ( assayx in assays ){
          # 如果 assays 存在以下几种，则直接跳过下方代码
          if ( assayx %in% c("ADT", "CRISPR") ) next
          # 如果：cut.1，cut.2不为空，则进行UMI/Gene按照平均值±2倍标准差，反之根据指定-c参数的最小过滤值,最大过滤值
          # 是否进行红细胞过滤
          if ( "percent.HB" %in% filter_params) {
            filter_params1 = filter_params[-length(filter_params)]
            bounds_list1 = bounds_list[-length(bounds_list)]
            outliers = OESingleCell::FindOutliers(data_ob, vars = filter_params1,
                                                  var.limit = bounds_list1, batch = "sampleid",
                                                  type = "both", cut.1 = opt$cut.1, cut.2 = opt$cut.2,
                                                  n = opt$nfold, log = FALSE )
            # 每个矩阵作为列进行排列
            outliercells = do.call(cbind, outliers)
            # 检查有任何值等于TRUE
            metric_outlier = apply(outliercells, 1, function(x) any(x == T))
            # 添加到rds,列名为is_metric_outlier:包含TURE、FALSE(FALSE是我们所需)
            data_ob = OESingleCell::AddMetaData(data_ob, metadata = metric_outlier,
                                                col.name = "is_metric_outlier")
            outlier_variables = "is_metric_outlier"
            # find outlier cells using roboust linear model between the specified corresponding variable
            # and the dependent variable
            if ( !is.null( opt$rlm.xy) ){
              rlm.xy = unlist(strsplit(opt$rlm.xy, ":"))
              rlmoutlier = OESingleCell::FindRlmOutlier(data_ob, y = rlm.xy[2], x = rlm.xy[1])
              data_ob = OESingleCell::AddMetaData(data_ob, metadata = rlmoutlier,
                                                  col.name = "is_rlmoutliers")
              outlier_variables = c( outlier_variables, "is_rlmoutliers")
            }
            # is_valid :包含TURE、FALSE(TURE是我们所需，其实就是is_metric_outlier中的FALSE)
            is_valid_cell = !apply(OESingleCell::FetchData(data_ob, vars = outlier_variables), 1, function(x) any(x == T))
            data_ob = OESingleCell::AddMetaData(data_ob, metadata = is_valid_cell, col.name = "is_valid")
            data_ob = subset(data_ob, subset = is_valid == TRUE )
            print("Hello，ngene_numi_fold2sdg过滤完成")
            print("Hello，我们开始进行：线粒体按照超过细胞间线粒体UMIs中位数的四倍进行剔除")
            counts<-GetAssayData(data_ob,'counts')
            #线粒体基因列表
            gmt_list = unlist(strsplit(opt$gset,",",perl = T))
            gset_list <- lapply(gmt_list, function(gmtfile){
                                gset_list <- GSEABase::geneIds(GSEABase::getGmt(con=gmtfile))  
                                return(gset_list)
            })
            #获取线粒体基因名
            char_vector <- unlist(gset_list[[1]])
            print(paste0("线粒体基因名",char_vector))
            #线粒体基因UMI数
            mt <- counts[char_vector,]
            #去除线粒体基因UMI中位数四倍以上的细胞
            mt_umi = colSums(mt)
            #print(head(mt_umi))
            median_value <- summary(mt_umi)["Median"]
            cat("线粒体UMIs中位数:", median_value, "\n")
            fust = as.data.frame(mt_umi)
            fust$bak = fust$mt_umi
            # 这里写死了，是四倍，后期可以修改！！
            filter_cell = rownames(fust[(fust$mt_umi < median_value*4),])
            data_ob = data_ob[,filter_cell]
            # 重新计算log10GenesPerUMI
            data_ob@meta.data$log10GenesPerUMI <- log10(data_ob@meta.data$nFeature_RNA)/log10(data_ob@meta.data$nCount_RNA)
            # 过滤红细胞
            HB_max = bounds_list$percent.HB["max"]
            HB_min = bounds_list$percent.HB["min"]
            if (HB_min!="-Inf") {
                data_ob = subset(data_ob, subset = HB_min< percent.HB & percent.HB < HB_max)
            }else {
                data_ob = subset(data_ob, subset = percent.HB < HB_max)
            }
            # 统计过滤标准（最大值、最小值）
            thresholds = do.call(cbind,
                                lapply(names(outliers), function(x) {
                                  cut = t(attr(outliers[[x]], "threshold"))
                                  colnames(cut) = paste( x, colnames(cut), sep = "_")
                                  cut}))
            # 将红细胞信息添加
            thresholds <- as.data.frame(thresholds)
            thresholds$percent.HB_lower <- HB_min
            thresholds$percent.HB_higher <- HB_max
            # is_valid :TURE是我们所需,只保留TRUE
            # 获取样本中各列最大值、最小值
            value_range  = subset(data_ob@meta.data, subset = is_valid == TRUE ) %>% dplyr::group_by(sampleid) %>% 
                            dplyr::summarise( dplyr::across(names(outliers), 
                            list( min = min,  max = max))) %>% tibble::column_to_rownames(var = "sampleid")
            # 将红细胞信息添加
            result_percent_HB <- data_ob@meta.data %>% dplyr::group_by(sampleid) %>% dplyr::summarise(percent.HB_min = min(percent.HB),percent.HB_max = max(percent.HB))
            value_range$percent.HB_min <- result_percent_HB$percent.HB_min
            value_range$percent.HB_max <- result_percent_HB$percent.HB_max
            }else{
              # 仅进行线粒体过滤
              outliers = OESingleCell::FindOutliers(data_ob, vars = filter_params,
                                              var.limit = bounds_list, batch = "sampleid",
                                              type = "both", cut.1 = opt$cut.1, cut.2 = opt$cut.2,
                                              n = opt$nfold, log = FALSE )
              # 每个矩阵作为列进行排列
              outliercells = do.call(cbind, outliers)
              # 检查有任何值等于TRUE
              metric_outlier = apply(outliercells, 1, function(x) any(x == T))
              # 添加到rds,列名为is_metric_outlier:包含TURE、FALSE(FALSE是我们所需)
              data_ob = OESingleCell::AddMetaData(data_ob, metadata = metric_outlier,
                                                          col.name = "is_metric_outlier")
              outlier_variables = "is_metric_outlier"
              # find outlier cells using roboust linear model between the specified corresponding variable
              # and the dependent variable
              if ( !is.null( opt$rlm.xy) ){
                        rlm.xy = unlist(strsplit(opt$rlm.xy, ":"))
                        rlmoutlier = OESingleCell::FindRlmOutlier(data_ob, y = rlm.xy[2], x = rlm.xy[1])
                        data_ob = OESingleCell::AddMetaData(data_ob, metadata = rlmoutlier,
                                                            col.name = "is_rlmoutliers")
                        outlier_variables = c( outlier_variables, "is_rlmoutliers")
                      }
              # is_valid :包含TURE、FALSE(TURE是我们所需，其实就是is_metric_outlier中的FALSE)
              is_valid_cell = !apply(OESingleCell::FetchData(data_ob, vars = outlier_variables), 1, function(x) any(x == T))
              data_ob = OESingleCell::AddMetaData(data_ob, metadata = is_valid_cell, col.name = "is_valid")
              data_ob = subset(data_ob, subset = is_valid == TRUE )
              print("Hello，ngene_numi_fold2sdg过滤完成")
              print("Hello，我们开始进行：线粒体按照超过细胞间线粒体UMIs中位数的四倍进行剔除")
              counts<-GetAssayData(data_ob,'counts')
              #线粒体基因列表
              gmt_list = unlist(strsplit(opt$gset,",",perl = T))
              gset_list <- lapply(gmt_list, function(gmtfile){
                                          gset_list <- GSEABase::geneIds(GSEABase::getGmt(con=gmtfile))  
                                          return(gset_list)
                      })
              #获取线粒体基因名
              char_vector <- unlist(gset_list[[1]])
              print(paste0("线粒体基因名",char_vector))
              #线粒体基因UMI数
              mt <- counts[char_vector,]
              #print(head(char_vector))
              #去除线粒体基因UMI中位数四倍以上的细胞
              mt_umi = colSums(mt)
              #print(head(mt_umi))
              median_value <- summary(mt_umi)["Median"]
              cat("线粒体UMIs中位数:", median_value, "\n")
              fust = as.data.frame(mt_umi)
              fust$bak = fust$mt_umi
              # 这里写死了，是四倍，后期可以修改！！
              filter_cell = rownames(fust[(fust$mt_umi < median_value*4),])
              data_ob = data_ob[,filter_cell]
              # 重新计算log10GenesPerUMI
              data_ob@meta.data$log10GenesPerUMI <- log10(data_ob@meta.data$nFeature_RNA)/log10(data_ob@meta.data$nCount_RNA)
              #统计过滤标准（最大值、最小值）
              thresholds = do.call(cbind,
                              lapply(names(outliers), function(x) {
                                cut = t(attr(outliers[[x]], "threshold"))
                                colnames(cut) = paste( x, colnames(cut), sep = "_")
                                cut}))
              # is_valid :TURE是我们所需,只保留TRUE
              # 获取样本中各列最大值、最小值
              value_range  = subset(data_ob@meta.data, subset = is_valid == TRUE ) %>% dplyr::group_by(sampleid) %>% 
                              dplyr::summarise( dplyr::across(names(outliers), 
                              list( min = min,  max = max))) %>% tibble::column_to_rownames(var = "sampleid")
              }

            # 绘图
            ggvln_after_QC = Seurat::VlnPlot(data_ob,
                                          features = filter_params, alpha = 0.5,
                                          group.by = "sampleid", pt.size = 0.1, ncol = ncol)
            OESingleCell::save_ggplots( filename = file.path(output_dir,"QC_metrics_afterQC"),
                                    plot = ggvln_after_QC,
                                    height = height,
                                    limitsize = F,
                                    width = nsamples*length(filter_params)+3, bg="white")
            # 过滤后：获取每个样本原始细胞数
            statistics_afterQC_sim = Seurat::FetchData(data_ob, vars = c("sampleid","is_valid") ) %>%
            dplyr::filter(is_valid == TRUE) %>% 
            dplyr::group_by(sampleid) %>% dplyr::summarise(Total_cells_afterQC = dplyr::n()) %>% tibble::column_to_rownames(var = "sampleid")
            # 过滤后：获取输入列的均值、中位值
            statistics_afterQC = Seurat::FetchData(data_ob, vars = unique(c(filter_params, vars2regress,"sampleid","is_valid")) ) %>% dplyr::filter(is_valid == TRUE) %>% dplyr::group_by(sampleid) %>% dplyr::summarise( dplyr::across(where(is.numeric),list( ~ round(mean(.x, na.rm = TRUE), 3), ~ median(.x, na.rm = TRUE))) , total_cells = dplyr::n()) %>% tibble::column_to_rownames(var = "sampleid")
            after_grid = expand.grid(c("mean", "median"), summx_params, "afterQC")
            colx_after = c( paste( after_grid[[1]], after_grid[[2]], after_grid[[3]], sep = "_"),"Total_cells_afterQC")
            colnames(statistics_afterQC)  = colx_after
            #合并数据,并新增一列sample内容是行名（样本名）
            cell_statitics = cbind(statistics_beforeQC, statistics_afterQC, thresholds)
            cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                            dplyr::select(sample, dplyr::everything())
            # 保存表格
            write.table(cell_statitics,file.path(output_dir,"cell_statitics_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)
            #合并数据,并新增一列sample内容是行名（样本名）
            cell_statitics = cbind(statistics_beforeQC_sim, statistics_afterQC_sim, value_range)
            cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                            dplyr::select(sample, dplyr::everything())
            write.table(cell_statitics,file.path(output_dir,"cell_count_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)
      }}else{
          # 指定阈值进行过滤
          # 解析最小过滤参数
          lower_threshold = sapply( unlist(strsplit(opt$lower, ",") ),
                                    function(x) ifelse(x == "NULL", NA, as.numeric(x)) )
          # 判断 过滤参数与输入列是否一致
          if ( length(lower_threshold) != length(filter_params) ){
            stop("The lower threshold setting is not consistant with the parameters in --filters!")
          }
          names(lower_threshold) = filter_params
          # 解析最大过滤参数
          upper_threshold = sapply( unlist(strsplit(opt$upper, ",") ),
                                    function(x) ifelse(x == "NULL", NA, as.numeric(x)) )
          # 判断 过滤参数与输入列是否一致
          if ( length(upper_threshold) != length(filter_params) ){
            stop("The upper threshold setting is not consistant with the parameters in --filters!")
          }
          names(upper_threshold) = filter_params
          # 创建输入列参数的边界列表
          bounds_list = list()
          for ( x in filter_params)  bounds_list[[x]] = c(min = unname(lower_threshold[x]), max = unname(upper_threshold[x]) )
          # 如果线粒体比例（percent.mito）最大过滤值没有输入，则进行自动判断并赋值
          if ( "percent.mito" %in% filter_params) {
            if ( (!is.null(bounds_list$percent.mito)) & is.na(bounds_list$percent.mito["max"])) {
              print("Auto calculating percent.mito cut-off…")
              # Q90 = ceiling(quantile(data_ob$percent.mito,0.9)/0.05)*0.05
              # if (Q90 > 0.2) {
              #     warning("The 90th percentile of percent.mito exceed 20% !!!"); 
              #     Q90 = 0.2
              # }
              Q90 = ceiling(max_mito/0.05)*0.05
              print(paste0("各样本线粒体比例q90最大值为:", max_mito))
              if (Q90 > 0.3) {
                  warning("The 90th percentile of percent.mito exceed 30% !!!"); 
                  Q90 = 0.3
              }
              print(paste0("The percent.mito cut-off is set as ",Q90,"."))
              bounds_list$percent.mito["min"] <- 0
              bounds_list$percent.mito["max"] <- Q90
            }
          }
          # Calculate the QC metrics for each cell
          # The number of genes and UMIs are automatically calculated for every object by Seurat.
          # For non-UMI data, nUMI represents the sum of the non-normalized values within a cell.
          # We calculate the percentage of mitochondrial genes here and store it in percent.mito using AddMetaData.
          # AddMetaData adds columns to cell annotation table, and is a great place to stash QC stats
          # ,since this represents non-transformed and non-log-normalized counts.
          # The % of UMI mapping to MT-genes is a common scRNA-seq QC metric.
          #calculate the mitochondrial gene derived transcript proportion and add to the metadata
          # assays = ifelse( !is.null(opt$subassay), opt$assay, c(opt$assay, unlist(strsplit(opt$subassay,","))))
          for ( assayx in assays ){
            # 如果 assays 存在以下几种，则直接跳过下方代码
            if ( assayx %in% c("ADT", "CRISPR") ) next
            # Filter unquanlified cells using different methods
            # We filter out cells that have unique gene counts over 2,500 or less than
            # 200. Note that low.thresholds and high.thresholds are used to define a
            # 'gate'. -Inf and Inf should be used if you don't want a lower or upper
            # threshold.
            # if each filter's lower or upper threshold is specified from the command line
            # the user defined value will be used. Otherwise,the default threshold will
            # be calculated using the distribution significant level specified automatically
            # All the thresholds are specific for each sample, so when the threshold and the
            # standard variance fold are both
            # available from the command line, we will compare the value with the one derived
            # from the distribution lower outliner

            # 如果：cut.1，cut.2不为空，则进行UMI/Gene按照平均值±2倍标准差，反之根据指定-c参数的最小过滤值,最大过滤值
            outliers = OESingleCell::FindOutliers(data_ob, vars = filter_params,
                                                  var.limit = bounds_list, batch = "sampleid",
                                                  type = "both", cut.1 = opt$cut.1, cut.2 = opt$cut.2,
                                                  n = opt$nfold, log = FALSE )
            # 每个矩阵作为列进行排列
            outliercells = do.call(cbind, outliers)
            # 检查有任何值等于TRUE
            metric_outlier = apply(outliercells, 1, function(x) any(x == T))
            # 添加到rds,列名为is_metric_outlier:包含TURE、FALSE(FALSE是我们所需)
            data_ob = OESingleCell::AddMetaData(data_ob, metadata = metric_outlier,
                                                col.name = "is_metric_outlier")
            outlier_variables = "is_metric_outlier"
            # find outlier cells using roboust linear model between the specified corresponding variable
            # and the dependent variable
            if ( !is.null( opt$rlm.xy) ){
              rlm.xy = unlist(strsplit(opt$rlm.xy, ":"))
              rlmoutlier = OESingleCell::FindRlmOutlier(data_ob, y = rlm.xy[2], x = rlm.xy[1])
              data_ob = OESingleCell::AddMetaData(data_ob, metadata = rlmoutlier,
                                                  col.name = "is_rlmoutliers")
              outlier_variables = c( outlier_variables, "is_rlmoutliers")
            }
            # is_valid :包含TURE、FALSE(TURE是我们所需，其实就是is_metric_outlier中的FALSE)
            is_valid_cell = !apply(OESingleCell::FetchData(data_ob, vars = outlier_variables), 1, function(x) any(x == T))
            data_ob = OESingleCell::AddMetaData(data_ob, metadata = is_valid_cell, col.name = "is_valid")

            #统计过滤标准（最大值、最小值）
            thresholds = do.call(cbind,
                              lapply(names(outliers), function(x) {
                                cut = t(attr(outliers[[x]], "threshold"))
                                colnames(cut) = paste( x, colnames(cut), sep = "_")
                                cut}) )
            # is_valid :TURE是我们所需,只保留TRUE
            # 获取样本中各列最大值、最小值
            value_range  = subset(data_ob@meta.data, subset = is_valid == TRUE ) %>% dplyr::group_by(sampleid) %>% 
                            dplyr::summarise( dplyr::across(names(outliers), 
                            list( min = min,  max = max))) %>% tibble::column_to_rownames(var = "sampleid")
            # 绘图
            ggvln_after_QC = Seurat::VlnPlot(subset(data_ob, subset = is_valid == TRUE ),
                                            features = filter_params, alpha = 0.5,
                                            group.by = "sampleid", pt.size = 0.1, ncol = ncol)
            OESingleCell::save_ggplots( filename = file.path(output_dir,"QC_metrics_afterQC"),
                                      plot = ggvln_after_QC,
                                      height = height,
                                      limitsize = F,
                                      width = nsamples*length(filter_params)+3, bg="white")
            # 过滤后：获取每个样本原始细胞数
            statistics_afterQC_sim = Seurat::FetchData(data_ob, vars = c("sampleid","is_valid") ) %>%
              dplyr::filter(is_valid == TRUE) %>% 
              dplyr::group_by(sampleid) %>%
              dplyr::summarise(
                      Total_cells_afterQC = dplyr::n()) %>%
              tibble::column_to_rownames(var = "sampleid")
            # 过滤后：获取输入列的均值、中位值
            statistics_afterQC = Seurat::FetchData(data_ob, vars = unique(c(filter_params, vars2regress,"sampleid","is_valid")) ) %>%
                dplyr::filter(is_valid == TRUE) %>%
                dplyr::group_by(sampleid) %>%
                dplyr::summarise(
                      dplyr::across(where(is.numeric),
                                    list( ~ round(mean(.x, na.rm = TRUE), 3), ~ median(.x, na.rm = TRUE))) ,
                      total_cells = dplyr::n()) %>% tibble::column_to_rownames(var = "sampleid")

            after_grid = expand.grid(c("mean", "median"), summx_params, "afterQC")
            colx_after = c( paste( after_grid[[1]], after_grid[[2]], after_grid[[3]], sep = "_"),
                            "Total_cells_afterQC")
            colnames(statistics_afterQC)  = colx_after

            #合并数据,并新增一列sample内容是行名（样本名）
            cell_statitics = cbind(statistics_beforeQC, statistics_afterQC, thresholds)
            cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                            dplyr::select(sample, dplyr::everything())
            # 保存表格
            write.table(cell_statitics,file.path(output_dir,"cell_statitics_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)

            #合并数据,并新增一列sample内容是行名（样本名）
            cell_statitics = cbind(statistics_beforeQC_sim, statistics_afterQC_sim, value_range)
            cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                            dplyr::select(sample, dplyr::everything())
            write.table(cell_statitics,file.path(output_dir,"cell_count_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)
        }}
            # filter genes by using the minimium cell number one gene is detected
            # this step shoud be run after cell filtering, because there may be
            # satisfied cell number for one gene before filtering
            # but fails after cell filtering
            if ( !is.null(opt$genes2filter) ){
                if ( file.exists( opt$genes2filter) ){
                    genes2filter = read.csv(opt$genes2filter,sep=",",header =T )
                }
                genes2filter = as.vector(genes2filter$gene)
            }else{
              genes2filter = NULL
            }
            if ( opt$mincell4gene < 1 ){ #the parameter is a percentage
                min.cell_N = round(opt$mincell4gene * ncol(data_ob))
            }else{ #the parameter is a integer
                min.cell_N = opt$mincell4gene
            }
            data_ob = OESingleCell::FilterGenes(data_ob, min.cells = min.cell_N, filter.genes = genes2filter )
            # now actually filter outlier cells
            data_ob = subset(data_ob, subset = is_valid == TRUE )
  }

  if (toupper(opt$rmdoublets) == "TRUE"){
    RunDoubletFinder <- function(
      object,
      PCs = 1:30,
      doublet.rate = 0.06,
      db.ratio = 0.25,
      nb.size = 0.09,
      sct = FALSE,
      GT = FALSE,
      GT.calls = NULL,
      identity = NULL,
      ...
    ){
      #Set pN-pK param sweep ranges
      pK <- c(0.0005, 0.001, 0.005, seq(0.01,0.3,by=0.01)) # 34
      pN <- seq(0.05,0.3,by=0.05)

      # Remove pK values with too few cells
      min.cells <- round(ncol(object)/(1-0.05) - ncol(object) )
      pK.test <- round(pK*min.cells)
      pK <- pK[which(pK.test >= 1)]

      # Down-sample cells to 10000 (when applicable) for computational effiency
      data <- SeuratObject::GetAssayData(object, slot = "counts")
      if ( ncol(object) > 10000 ) {
        real.cells <- colnames(object)[sample(1:ncol(object), 10000, replace=FALSE)]
        data <- data[ , real.cells]
      }else{
        real.cells <- colnames(object)
      }

      # Iterate through pN, computing pANN vectors at varying pK
      n.real.cells <- length(real.cells)
      output2 <- future.apply::future_lapply(pN, function(x){
        # Make merged real-artifical data
        print(paste("Creating artificial doublets for pN = ", x*100,"%",sep=""))
        n_doublets <- round(n.real.cells/(1 - x) - n.real.cells)
        real.cells1 <- sample(real.cells, n_doublets, replace = TRUE)
        real.cells2 <- sample(real.cells, n_doublets, replace = TRUE)
        doublets <- (data[, real.cells1] + data[, real.cells2])/2
        colnames(doublets) <- paste("X", 1:n_doublets, sep = "")
       data_wdoublets <- cbind(data, doublets)

        ## Pre-process Seurat object
        seu_wdoublets <- SeuratObject::CreateSeuratObject(counts = data_wdoublets)
        if (sct == FALSE){
          seu_wdoublets <- Seurat::NormalizeData(seu_wdoublets)
          seu_wdoublets <- Seurat::FindVariableFeatures(seu_wdoublets)
          seu_wdoublets <- Seurat::ScaleData(seu_wdoublets)
        }else{
          seu_wdoublets <- Seurat::SCTransform(seu_wdoublets)
        }

        seu_wdoublets <- Seurat::RunPCA(seu_wdoublets, verbose=FALSE)
        ## Compute PC distance matrix
        nCells <- ncol(seu_wdoublets)
        pca.coord <- SeuratObject::Embeddings(seu_wdoublets, reduction = "pca")[,PCs]
        # pca.coord <- object_wdoublets@reductions$pca@cell.embeddings[ , PCs]
        rm(seu_wdoublets);gc()
        dist.mat <- fields::rdist(pca.coord)[,1:n.real.cells]

        # Pre-order PC distance matrix prior to iterating across pK for pANN computations
        for (i in 1:n.real.cells) {
          dist.mat[,i] <- order(dist.mat[,i])
        }

        # Trim PC distance matrix for faster manipulations
        ind <- round(nCells * max(pK))+5
        dist.mat <- dist.mat[1:ind, ]

        ## Compute pANN across pK sweep
        print("Computing pANN across all pK...")
        sweep.res.list = list()
        list.ind = 0
        for (k in 1:length(pK)) {
          print(paste("pK = ", pK[k], "...", sep = ""))
          pk.temp <- round(nCells * pK[k])
          pANN <- as.data.frame(matrix(0L, nrow = n.real.cells, ncol = 1))
          colnames(pANN) <- "pANN"
          rownames(pANN) <- real.cells
          list.ind <- list.ind + 1

          for (i in 1:n.real.cells) {
            neighbors <- dist.mat[2:(pk.temp + 1),i]
            pANN$pANN[i] <- length(which(neighbors > n.real.cells))/pk.temp
          }

          sweep.res.list[[list.ind]] <- pANN
        }
        sweep.res.list
     }, future.seed = 2020)

      ## Write parallelized output into list
      sweep.list <- list()
      list.ind <- 0

      for(i in 1:length(output2)){
        for(j in 1:length(output2[[i]])){
          list.ind <- list.ind + 1
          sweep.list[[list.ind]] <- output2[[i]][[j]]
        }
      }

      ## Assign names to list of results
      name.vec <- NULL
      for (j in 1:length(pN)) {
        name.vec <- c(name.vec, paste("pN", pN[j], "pK", pK, sep = "_" ))
      }
      names(sweep.list) <- name.vec

      ## Set pN-pK param sweep ranges
      # require(KernSmooth); require(ROCR)
      # name.vec <- names(sweep.list)
      name.vec <- unlist(strsplit(name.vec, split="pN_"))
      name.vec <- name.vec[seq(2, length(name.vec), by=2)]
      name.vec <- unlist(strsplit(name.vec, split="_pK_"))
      pN <- as.numeric(unique(name.vec[seq(1, length(name.vec), by=2)]))
      pK <- as.numeric(unique(name.vec[seq(2, length(name.vec), by=2)]))
      print(paste("PK ==+ ", pK, "..."))
      print(paste("PN ==+ ", pN, "..."))
      ## Initialize data structure w/ or w/o AUC column, depending on whether ground-truth doublet classifications are available
      if ( GT == TRUE ) {
        sweep.stats <- as.data.frame(matrix(0L, nrow=length(sweep.list), ncol=4))
        colnames(sweep.stats) <- c("pN","pK","AUC","BCreal")
        sweep.stats$pN <- factor(rep(pN, each=length(pK), levels = pN))
        sweep.stats$pK <- factor(rep(pK, length(pN),levels = pK))
      }else{
        sweep.stats <- as.data.frame(matrix(0L, nrow=length(sweep.list), ncol=3))
        colnames(sweep.stats) <- c("pN","pK","BCreal")
        sweep.stats$pN <- factor(rep(pN, each=length(pK), levels = pN))
        sweep.stats$pK <- factor(rep(pK, length(pN),levels = pK))
      }

      ## Perform pN-pK parameter sweep summary
      for (i in 1:length(sweep.list)) {
        res.temp <- sweep.list[[i]]

        ## Use gaussian kernel density estimation of pANN vector to compute bimodality coefficient
        gkde <- approxfun(KernSmooth::bkde(res.temp$pANN, kernel="normal"))
        x <- seq(from=min(res.temp$pANN), to=max(res.temp$pANN), length.out=nrow(res.temp))
       gkdx = gkde(x)
        sweep.stats$BCreal[i] <- bimodality_coefficient(gkdx)

        if (GT == FALSE) { next }

        ## If ground-truth doublet classifications are available, perform ROC analysis on logistic
        ## regression model trained using pANN vector
        meta <- as.data.frame(matrix(0L, nrow=nrow(res.temp), ncol=2))
        meta[,1] <- GT.calls
        meta[,2] <- res.temp$pANN
        train.ind <- sample(1:nrow(meta), round(nrow(meta)/2), replace=FALSE)
        test.ind <- (1:nrow(meta))[-train.ind]
        colnames(meta) <- c("SinDub","pANN")
        meta$SinDub <- factor(meta$SinDub, levels = c("Doublet","Singlet"))
        model.lm <- glm(SinDub ~ pANN, family="binomial"(link='logit'), data=meta, subset=train.ind)
        prob <- predict(model.lm, newdata=meta[test.ind, ], type="response")
        ROCpred <- ROCR::prediction(predictions=prob, labels=meta$SinDub[test.ind])
        perf.auc <- ROCR::performance(ROCpred, measure="auc")
        sweep.stats$AUC[i] <- perf.auc@y.values[[1]]
      }

      ## Implementation for data without ground-truth doublet classifications
      if ( !"AUC" %in% colnames(sweep.stats) ) {
        ## Initialize data structure for results storage
        bc.mvn <- as.data.frame(matrix(0L, nrow=length(unique(sweep.stats$pK)), ncol=5))
        colnames(bc.mvn) <- c("ParamID","pK","MeanBC","VarBC","BCmetric")
        bc.mvn$pK <- unique(sweep.stats$pK)
        bc.mvn$ParamID <- 1:nrow(bc.mvn)

        ## Compute bimodality coefficient mean, variance, and BCmvn across pN-pK sweep results
        x <- 0
        for (i in unique(bc.mvn$pK)) {
          x <- x + 1
          ind <- which(sweep.stats$pK == i)
          bc.mvn$MeanBC[x] <- mean(sweep.stats[ind, "BCreal"])
          bc.mvn$VarBC[x] <- sd(sweep.stats[ind, "BCreal"])^2
          bc.mvn$BCmetric[x] <- mean(sweep.stats[ind, "BCreal"])/(sd(sweep.stats[ind, "BCreal"])^2)
        }
      }else{
        # Implementation for data with ground-truth doublet classifications (e.g., MULTI-seq, CellHashing, Demuxlet, etc.)
        # Initialize data structure for results storage
        bc.mvn <- as.data.frame(matrix(0L, nrow=length(unique(sweep.stats$pK)), ncol=6))
        colnames(bc.mvn) <- c("ParamID","pK","MeanAUC","MeanBC","VarBC","BCmetric")
        bc.mvn$pK <- unique(sweep.stats$pK)
        bc.mvn$ParamID <- 1:nrow(bc.mvn)

        ## Compute bimodality coefficient mean, variance, and BCmvn across pN-pK sweep results
        x <- 0
       for (i in unique(bc.mvn$pK)) {
          x <- x + 1
          ind <- which(sweep.stats$pK == i)
          bc.mvn$MeanAUC[x] <- mean(sweep.stats[ind, "AUC"])
          bc.mvn$MeanBC[x] <- mean(sweep.stats[ind, "BCreal"])
          bc.mvn$VarBC[x] <- sd(sweep.stats[ind, "BCreal"])^2
          bc.mvn$BCmetric[x] <- mean(sweep.stats[ind, "BCreal"])/(sd(sweep.stats[ind, "BCreal"])^2)
        }
      }

      # choose parameters
      maxBCmetric    <- max(bc.mvn$BCmetric, na.rm = TRUE)
      pK <- as.numeric(as.character(bc.mvn[bc.mvn$BCmetric==maxBCmetric, ]$pK))

      # compute doublet scores
      annotations    <- OESingleCell::colData(object)[[identity]]  ## ex: annotations <- object_kidney@meta.data$ClusteringResults
      # homotypic.prop <- modelHomotypic(annotations)
      anno.freq <- table(annotations)/length(annotations)
      homotypic.prop <- sum(anno.freq^2)
      nExp_poi       <- round(doublet.rate*ncol(object))  ## Assuming 7.5% doublet formation rate - tailor for your dataset
      nExp   <- round(nExp_poi*(1-homotypic.prop))
      # object.scored     <- doubletFinder_v3(object, PCs =PCs, pN = pN, pK = pK, nExp = nExp_poi.adj, reuse.pANN = FALSE, sct = use.SCT)
      print(paste( "pN =", pN, "pK=", pK, "nExp=", nExp))
      ## Generate new list of doublet classificatons from existing pANN vector to save time
      ## Make merged real-artifical data
      real.cells <- colnames(object)
      data <- SeuratObject::GetAssayData(object, slot = "counts")[, real.cells]
      n_real.cells <- length(real.cells)
      n_doublets <- round(n_real.cells/(1 - db.ratio) - n_real.cells)
      print(paste("Creating",n_doublets,"artificial doublets...",sep=" "))
      real.cells1 <- sample(real.cells, n_doublets, replace = TRUE)
      real.cells2 <- sample(real.cells, n_doublets, replace = TRUE)
      doublets <- (data[, real.cells1] + data[, real.cells2])/2
      colnames(doublets) <- paste("X", 1:n_doublets, sep = "")
      data_wdoublets <- cbind(data, doublets)

      ## Pre-process Seurat object
      print("Creating Seurat object...")
      seu_wdoublets <- SeuratObject::CreateSeuratObject(counts = data_wdoublets)
      if (sct == FALSE){
        print("Normalizing Seurat object...")
        seu_wdoublets <- Seurat::NormalizeData(seu_wdoublets)
        print("Finding variable genes...")
        seu_wdoublets <- Seurat::FindVariableFeatures(seu_wdoublets)
        print("Scaling data...")
        seu_wdoublets <- Seurat::ScaleData(seu_wdoublets)
      }else{
        print("Running SCTransform...")
        seu_wdoublets <- Seurat::SCTransform(seu_wdoublets)
      }
      print("Running PCA...")
      seu_wdoublets <- Seurat::RunPCA(seu_wdoublets, verbose=FALSE)
      ## Compute PC distance matrix
      print("Calculating PC distance matrix...")
      nCells <- ncol(seu_wdoublets)
      pca.coord <- SeuratObject::Embeddings(seu_wdoublets, reduction = "pca")[,PCs]
      k <- round(ncol(seu_wdoublets) * nb.size)
      rm(seu_wdoublets);gc()

      ## Compute PC distance matrix
      print("Calculating PC distance matrix...")
      dist.mat <- fields::rdist(pca.coord)

      ## Compute pANN
      print("Computing pANN...")
      pANN <- as.data.frame(matrix(0L, nrow = n_real.cells, ncol = 1))
      rownames(pANN) <- real.cells
      colnames(pANN) <- "pANN"
      for (i in 1:n_real.cells) {
        neighbors <- order(dist.mat[, i])
        neighbors <- neighbors[2:(k + 1)]
        neighbor.names <- rownames(dist.mat)[neighbors]
        pANN$pANN[i] <- length(which(neighbors > n_real.cells))/k
      }

      print("Classifying doublets..")
      classifications <- rep("FALSE",n_real.cells)
      classifications[order(pANN$pANN[1:n_real.cells], decreasing=TRUE)[1:nExp]] <- "TRUE"
      object <- SeuratObject::AddMetaData(object, metadata = pANN[colnames(object), 1], col.name = paste("pANN", db.ratio, nb.size, nExp, sep="_"))
      object <- SeuratObject::AddMetaData(object, metadata = classifications, col.name = "predicted_doublets")
      return(object)
    }

    bimodality_coefficient <- function(x) {
      n <- length(x)
      S <- (1/n)*sum((x-mean(x))^3)/(((1/n)*sum((x-mean(x))^2))^1.5)
      G <- S*(sqrt(n*(n-1)))/(n-2)
      K <- (1/n)*sum((x-mean(x))^4)/(((1/n)*sum((x-mean(x))^2))^2)-3
      K <- ((n - 1)*((n+1)*K-3*(n-1))/((n-2)*(n-3)))+3
      B <- ((G^2)+1)/(K+((3*((n-1)^2))/((n-2)*(n-3))))
      return(B)
    }
    # data_list = OESingleCell::SplitObject(data_ob, split.by = "sampleid")
    is_doublets <- switch(opt$method,
    # data_list = OESingleCell::SplitObject(data_ob, split.by = "sampleid"),
      "scrublet" = {
                      data_list = OESingleCell::SplitObject(data_ob, split.by = "sampleid")
          dbl_all <- future.apply::future_lapply(data_list, function(x){
           if ( length(Seurat::Cells(x)) <= 1000 ){
                dbl_rates = 0.008
            }else if ( length(Seurat::Cells(x)) %in% 1001:2000 ) {
                dbl_rates = 0.015
            }else if ( length(Seurat::Cells(x)) %in% 2001:3000 ) {
                dbl_rates = 0.023
            }else if ( length(Seurat::Cells(x)) %in% 3001:4000 ) {
                dbl_rates = 0.030
            }else if ( length(Seurat::Cells(x)) %in% 4001:5000 ) {
                dbl_rates = 0.038
            }else if ( length(Seurat::Cells(x)) %in% 5001:6000 ) {
                dbl_rates = 0.046
            }else if ( length(Seurat::Cells(x)) %in% 6001:7000 ) {
                dbl_rates = 0.053
            }else if ( length(Seurat::Cells(x)) %in% 7001:8000 ) {
                dbl_rates = 0.061
            }else if ( length(Seurat::Cells(x)) %in% 8001:9000 ) {
                dbl_rates = 0.068
            }else if ( length(Seurat::Cells(x)) %in% 9001:10000 ) {
                dbl_rates = 0.080
            }else if ( length(Seurat::Cells(x)) > 10000 ) {
                dbl_rates = 0.1
            }
            x <- OESingleCell::RunScrublet(x, doublet.rate= dbl_rates )
            dbl_res <- OESingleCell::FetchData(x, var = "predicted_doublets")
          }, future.seed = 123)
        },
      "DoubletFinder" = {
        cellmeta = OESingleCell::colData(data_ob)
        if ( ! opt$ident %in% colnames(cellmeta) ) {
          print("NO specfied cell identity column FOUND in cell annotation!")
                      data_ob = Seurat::FindVariableFeatures(data_ob, loess.span = 0.3,
                            clip.max = "auto", mean.function = "FastExpMean",
                            dispersion.function = "FastLogVMR", num.bin = 20,
                            nfeature = "2000", binning.method = "equal_width" )
                      data_ob = Seurat::ScaleData(data_ob, 
                                                  #features = rownames(data_ob), 
                                                  verbose = T )
          data_ob = Seurat::RunPCA(data_ob, npcs = 30, features = OESingleCell::VariableFeatures(data_ob), do.print = F, verbose = F)
        }
        dbl_all = list()
                data_list = OESingleCell::SplitObject(data_ob, split.by = "sampleid")
        for ( x in 1:length(data_list) ){
          if ( length(Seurat::Cells(data_list[[x]])) <= 1000 ){
                dbl_rates = 0.008
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 1001:2000 ) {
                dbl_rates = 0.015
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 2001:3000 ) {
                dbl_rates = 0.023
         }else if ( length(Seurat::Cells(data_list[[x]])) %in% 3001:4000 ) {
                dbl_rates = 0.030
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 4001:5000 ) {
                dbl_rates = 0.038
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 5001:6000 ) {
                dbl_rates = 0.046
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 6001:7000 ) {
                dbl_rates = 0.053
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 7001:8000 ) {
                dbl_rates = 0.061
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 8001:9000 ) {
                dbl_rates = 0.068
          }else if ( length(Seurat::Cells(data_list[[x]])) %in% 9001:10000 ) {
                dbl_rates = 0.080
          }else if ( length(Seurat::Cells(data_list[[x]])) > 10000 ) {
                dbl_rates = 0.1
          }
          # parallization using specified CPUs start from here
          future::plan("multicore", workers = min(future::availableCores(), 2))
          data_list[[x]] <- RunDoubletFinder(data_list[[x]], doublet.rate= dbl_rates, identity = opt$ident )
          dbl_all[[x]] <- OESingleCell::FetchData(data_list[[x]], var = "predicted_doublets")
        }
        dbl_all
          # dbl_all <- future.apply::future_lapply(data_list, function(x){
          #   x <- RunDoubletFinder(x, doublet.rate= opt$dbl_rates, identity = opt$ident )
          #   dbl_res <- OESingleCell::FetchData(x, var = "predicted_doublets")
          # }, future.seed = 123)
      }
    )
    data_ob = OESingleCell::AddMetaData(data_ob, metadata = do.call(rbind, is_doublets)[[1]], col.name = "is_doublets")
    # append all other data not loaded before subsetting for h5seurat formated file.
    # if ( opt$informat == "h5seurat" ) data_ob = SeuratDisk::AppendData(opt$input, data_ob)

    # TO DO
    # add support of median calculation
    # 3 valid digits

    # statistics of metadat after QC
    ggvln_after_rmdoublets = Seurat::VlnPlot(subset(data_ob, subset = is_doublets == FALSE ),
                                     features = filter_params, alpha = 0.5,
                                     group.by = "sampleid", pt.size = opt$pointsize, ncol = ncol)
    OESingleCell::save_ggplots( filename = file.path(output_dir,"QC_metrics_afterQC"),
                                plot = ggvln_after_rmdoublets,
                                height = height,
                                limitsize = F,
                                width = nsamples*length(filter_params)+3, bg="white")
    statistics_after_rmdoublets_sim = Seurat::FetchData(data_ob, vars = c("sampleid","is_doublets") ) %>%
          dplyr::filter(is_doublets == FALSE) %>% 
          dplyr::group_by(sampleid) %>%
          dplyr::summarise(
                  Total_cells_after_rmdoublets = dplyr::n()) %>%
          tibble::column_to_rownames(var = "sampleid")
    statistics_after_rmdoublets = Seurat::FetchData(data_ob, vars = unique(c(filter_params, vars2regress,"sampleid","is_doublets")) ) %>%
         dplyr::filter(is_doublets == FALSE) %>%
         dplyr::group_by(sampleid) %>%
         dplyr::summarise(
               dplyr::across(where(is.numeric),
                             list( ~ round(mean(.x, na.rm = TRUE), 3), ~ median(.x, na.rm = TRUE))) ,
               total_cells = dplyr::n()) %>% tibble::column_to_rownames(var = "sampleid")
    after_grid = expand.grid(c("mean", "median"), summx_params, "after_rmdoublets")
    colx_after = c( paste( after_grid[[1]], after_grid[[2]], after_grid[[3]], sep = "_"),
                     "Total_cells_after_rmdoublets")
    colnames(statistics_after_rmdoublets)  = colx_after
    ##   #merge the statitics by columns
    if ( opt$QC != "TRUE" ) { ## rmdoublet only 
        cell_statitics = cbind(statistics_beforeQC, statistics_after_rmdoublets)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_statitics_before_after_rmdoublets.xls"),sep="\t",col.names=T,row.names=F)
    } else { ## merge final stats
        cell_statitics = cbind(statistics_beforeQC, statistics_afterQC,statistics_after_rmdoublets, thresholds)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_statitics_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)
    }
    if ( opt$QC != "TRUE" ) { ## rmdoublet only 
        cell_statitics = cbind(statistics_beforeQC_sim, statistics_after_rmdoublets_sim)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_count_before_after_rmdoublets.xls"),sep="\t",col.names=T,row.names=F)
    } else { ## merge final stats
        cell_statitics = cbind(statistics_beforeQC_sim, statistics_afterQC_sim,statistics_after_rmdoublets_sim, value_range)
        cell_statitics = cell_statitics %>% tibble::rownames_to_column(var = "sample") %>%
                         dplyr::select(sample, dplyr::everything())
        write.table(cell_statitics,file.path(output_dir,"cell_count_before_after_QC.xls"),sep="\t",col.names=T,row.names=F)
    }
    data_ob = subset(data_ob, subset = is_doublets == FALSE)
  }

  #Normalize the raw counts
  if ( tolower(opt$normmeth ) == "sctransform" ){
    # Results are saved in a new assay (named SCT by default) with counts being (corrected)
    # counts, data being log1p(counts), scale.data being pearson residuals;
    # sctransform::vst intermediate results are saved in misc slot of new assay.
    # normalize data with SCTransform()
    data_ob = Seurat::SCTransform(data_ob, method = "glmGamPoi",
                                  vars.to.regress = vars2regress,
                                  verbose = FALSE,return.only.var.genes = FALSE)
    if ( "CC.Difference" %in% vars2regress ){
      # s.genes = Seurat::CaseMatch(search = cc.genes$s.genes, match = rownames(object) )
      # g2m.genes = Seurat::CaseMatch(search = cc.genes$g2m.genes, match = rownames(object) )
      # data_ob = Seurat::CellCycleScoring(data_ob, s.features = s.genes, g2m.features = g2m.genes,set.ident = F)
    # cycleS = OESingleCell::FetchData(data_ob, vars = c("S.Score", "G2M.Score") )
    # data_ob = OESingleCell::AddMetaData(data_ob, col.name = "CC.Difference",
                             # metadata = cycleS[["S.Score"]] - cycleS[["G2M.Score"]])
    # normalise again but this time including also the cell cycle scores
    data_ob = Seurat::SCTransform(data_ob, assay = "RNA", method = "glmGamPoi",
                                  vars.to.regress = vars2regress,
                                  verbose = FALSE,return.only.var.genes = FALSE)
    }
  }else{
      # When you initialise your Seurat object, both counts and data contain
      # your raw transcripts counts (assuming that's your raw data). While the
      # matrix stored in counts generally remains the raw data, the data in the
      # data slot will be normalised when you run NormalizeData().
      data_ob = OESingleCell::NormalizeData(data_ob, normalization.method = opt$normmeth,scale.factor = 10000)
  }

  OESingleCell::SaveX(data_ob, output = output_dir,
                      outformat = opt$outformat, prefix = opt$prefix, update = FALSE )
  quit()
}


# ========= Subcmd: clustering for dimension reduction and clustering ==========
if ( "bclust" %in% args ){
  if ( tolower(opt$reduct2) %in% c("pca","cca","harmony","ica", "mnn") ){ #if the prevous reduction is primary reduction
       print( "the scondary reduction should not be one of pca, cca, ica, mnn or harmony if specified!")
       print("Change to UMAP method as default!")
       opt$reduct2 = "umap"
  }else{
      opt$reduct2 = tolower(opt$reduct2)
  }

 # read the specified assay and data slot in data object into memory
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots, verbose = F)
  message("Loading Data object Finished!")

  #get sample and group levels
  sampleid_levels=levels(data_ob@meta.data$sampleid)
  group_levels=levels(data_ob@meta.data$group)

  #update the metedata in the data_ob@meta.data with new additional sample metadata
  if ( !is.null(opt$metadata) ){
      additional_metadata = read.csv(opt$metadata,sep=",",header =T )
      rownames(additional_metadata) = additional_metadata$sampleid
      data_ob = UpdataCellMeta(data_ob, metadata = additional_metadata, cell.delm = "-")
  }

  if ( is.null(OESingleCell::colData(data_ob)[["clusters"]]) ){
      # data_ob = StashIdent(data_ob, save.name = "clusters")
      data_ob[["clusters"]] = Seurat::Idents(data_ob)
  }else{
      # if it is the first time to run this script on the data object, the
      # clusters here is actually the sample index.
      # After running this script, the cluster id will be overwrite with
      # the actual cell cluster id.
      data_ob = Seurat::SetIdent( data_ob, value = "sampleid")
  }

  #get the subset of cells used for visualization if necessay
  # subset cells on the expression matrix using logical exprssion on features

  if ( is.null(opt$component_pca )){
    component_pca = 30
    print(paste0("PCA_npcs:", component_pca, "!"))
  }else{
    component_pca = opt$component_pca
    print(paste0("PCA_npcs:", component_pca, "!"))
  }
  
  if ( !is.null(opt$predicate) ){
      df = OESingleCell::colData(data_ob)
      desired_cells= subset(df, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }
##################提取高变基因中需要去除的基因###################################
  gene_anno=read.delim(paste0(opt$ref,"/annotation/gene_annotation.xls"))
  lncRNA=gene_anno[which(gene_anno$gene_type=="lncRNA"),"id"]

  if (file.exists(paste0(opt$ref,"/MT_genelist.gmt"))){
    MT=GSEABase::geneIds(GSEABase::getGmt(con=paste0(opt$ref,"/MT_genelist.gmt")))$percent.mito
  } else {
    MT=NULL
  }

  if (file.exists(paste0(opt$ref,"/HB_genelist.gmt"))){
    HB=GSEABase::geneIds(GSEABase::getGmt(con=paste0(opt$ref,"/HB_genelist.gmt")))$percent.HB
  } else {
    HB=NULL
  }

  if (grepl("GRCh38", opt$ref)==TRUE){
    Heat_shock_protein=c("HSP90AA1","HSP90AA2P","HSP90AA4P","HSP90AA5P","HSP90AA6P","HSP90AB1","HSP90AB2P","HSP90AB3P","HSP90AB4P",
    "HSP90AB6P","HSP90AB7P","HSP90B1","HSP90B2P","HSP90B3P","HSPA12A","HSPA12B","HSPA13","HSPA14","HSPA14","HSPA1A","HSPA1B","HSPA1L",
    "HSPA2","HSPA4","HSPA4L","HSPA5","HSPA6","HSPA7","HSPA8","HSPA8P1","HSPA8P11","HSPA8P13","HSPA8P14","HSPA8P15","HSPA8P16","HSPA8P17",
    "HSPA8P18","HSPA8P19","HSPA8P20","HSPA8P3","HSPA8P4","HSPA8P5","HSPA8P6","HSPA8P7","HSPA8P8","HSPA8P9","HSPA9","HSPA9P1","HSPB1","HSPB11",
    "HSPB1P1","HSPB1P2","HSPB2","HSPB2-C11orf52","HSPB3","HSPB6","HSPB7","HSPB8","HSPB9","HSPBAP1","HSPBP1","HSPD1","HSPD1P1","HSPD1P10",
    "HSPD1P11","HSPD1P12","HSPD1P14","HSPD1P15","HSPD1P16","HSPD1P18","HSPD1P2","HSPD1P21","HSPD1P3","HSPD1P4","HSPD1P5","HSPD1P6","HSPD1P7",
    "HSPD1P8","HSPD1P9","HSPE1","HSPE1-MOB4","HSPE1P1","HSPE1P10","HSPE1P11","HSPE1P12","HSPE1P13","HSPE1P14","HSPE1P16","HSPE1P18","HSPE1P19",
    "HSPE1P2","HSPE1P20","HSPE1P21","HSPE1P22","HSPE1P23","HSPE1P24","HSPE1P25","HSPE1P26","HSPE1P27","HSPE1P28","HSPE1P3","HSPE1P4","HSPE1P5",
    "HSPE1P6","HSPE1P7","HSPE1P8","HSPE1P9","HSPG2","HSPH1","DNAJA1","DNAJA1P1","DNAJA1P2","DNAJA1P3","DNAJA1P4","DNAJA1P5","DNAJA1P6","DNAJA2",
    "DNAJA3","DNAJA4","DNAJB1","DNAJB11","DNAJB12","DNAJB13","DNAJB14","DNAJB1P1","DNAJB2","DNAJB3","DNAJB4","DNAJB5","DNAJB5-DT","DNAJB5P1",
    "DNAJB6","DNAJB7","DNAJB8","DNAJB8-AS1","DNAJB9","DNAJC1","DNAJC10","DNAJC11","DNAJC12","DNAJC13","DNAJC14","DNAJC15","DNAJC16","DNAJC17",
    "DNAJC18","DNAJC19","DNAJC19P1","DNAJC19P2","DNAJC19P3","DNAJC19P4","DNAJC19P5","DNAJC19P6","DNAJC19P7","DNAJC19P8","DNAJC19P9","DNAJC2",
    "DNAJC21","DNAJC22","DNAJC24","DNAJC25","DNAJC25-GNG10","DNAJC27","DNAJC27-AS1","DNAJC28","DNAJC3","DNAJC30","DNAJC3-DT","DNAJC4","DNAJC5",
    "DNAJC5B","DNAJC5G","DNAJC6","DNAJC7","DNAJC8","DNAJC8P1","DNAJC9","DNAJC9-AS1")
    Dissociation=c("ATF3","BTG2","CEBPB","CEBPB-AS1","CEBPD","CXCL1","EGR1","FOS","FOSB","FOSL1","FOSL1P1","FOSL2","ID3","IER2","JUN","JUNB","JUND",
    "MT1A","MT1B","MT1E","MT1F","MT1G","MT1H","MT1L","MT1M","MT1X","MT2A","NFKBIA","NR4A1","PPP1R15A","SOCS3","UBC","ZFP36")
    TR_V_gene=gene_anno[which(gene_anno$gene_type=="TR_V_gene"),"id"]
    Ribosome=grep(pattern = "^Rp[sl][[:digit:]]|^[mM]Rp[sl][[:digit:]]", rownames(data_ob), value = TRUE,ignore.case = T)
  } else if (grepl("GRCm39|mm10", opt$ref )==TRUE){
    Heat_shock_protein=c("Hsp90aa1","Hsp90ab1","Hsp90b1","Hspa12a","Hspa12b","Hspa13","Hspa14","Hspa1a","Hspa1a","Hspa1l","Hspa2","Hspa4","Hspa4l",
    "Hspa5","Hspa8","Hspa9","Hspb1","Hspb11","Hspb2","Hspb3","Hspb6","Hspb7","Hspb8","Hspb9","Hspbap1","Hspbp1","Hspd1","Hspe1","Hspg2","Hsph1",
    "Dnaja1","Dnaja2","Dnaja3","Dnaja4","Dnajb1","Dnajb11","Dnajb12","Dnajb13","Dnajb14","Dnajb2","Dnajb4","Dnajb5","Dnajb6","Dnajb7","Dnajb8",
    "Dnajb9","Dnajc1","Dnajc10","Dnajc11","Dnajc12","Dnajc13","Dnajc14","Dnajc15","Dnajc16","Dnajc17","Dnajc18","Dnajc19","Dnajc19-ps","Dnajc2",
    "Dnajc21","Dnajc22","Dnajc24","Dnajc25","Dnajc27","Dnajc28","Dnajc3","Dnajc30","Dnajc4","Dnajc5","Dnajc5b","Dnajc5g","Dnajc6","Dnajc7","Dnajc8","Dnajc9")
    Dissociation=c("Atf3","Btg2","Cebpb","Cebpd","Egr1","Fos","Fosb","Fosl1","Fosl2","Id3","Ier2","Jun","Junb","Jund","Nfkbia","Nr4a1","Ppp1r15a","Socs3",
    "Ubc","Zfp36")
    TR_V_gene=gene_anno[which(gene_anno$gene_type=="TR_V_gene"),"id"]
    Ribosome=grep(pattern = "^Rp[sl][[:digit:]]|^[mM]Rp[sl][[:digit:]]", rownames(data_ob), value = TRUE,ignore.case = T)
  } else {
    Heat_shock_protein=NULL
    Dissociation=NULL
    TR_V_gene=NULL
    Ribosome=NULL
  }
remove_gene=c(lncRNA,TR_V_gene,Ribosome,MT,HB,Heat_shock_protein,Dissociation)
#################################################################################
  #rerun时重新计算高变基因,以保证亚群分析时可以重新计算高变基因
  if (as.logical(opt$rerun) == T){
    print('重新计算高变基因，并针对"nCount_RNA","percent.mito"进行ScaleData(确保含有这两列)')
    data_ob = Seurat::FindVariableFeatures(data_ob, loess.span = 0.3,
                              clip.max = "auto", mean.function = "FastExpMean",
                              dispersion.function = "FastLogVMR", num.bin = 20,
                              nfeature = 2000, binning.method = "equal_width" )
    data_ob@assays$RNA@var.features=setdiff(data_ob@assays$RNA@var.features,remove_gene)
    data_ob <- Seurat::ScaleData(data_ob, verbose = T )
  }
  variablefs = Seurat::VariableFeatures(data_ob)
  print(length(variablefs))
  if ( is.null(opt$pointsize) ){
      if (dim(data_ob)[2] < 500){
          pointsize = 1.5
      } else pointsize = 0.5
  } else {
      pointsize = opt$pointsize
  }

  if ( as.logical(opt$integrated) ){
    print(paste0("开始 integrated 合并数据!"))
    # 按batchid进行拆分，后续可以改
    #data_ob = Seurat::SetIdent( data_ob, value = "sampleid")
    meta_features = data_ob@assays$RNA@meta.features
    ifnb.list <- SplitObject(data_ob, split.by = opt$batchid)
    #独立地对每个数据集进行归一化和识别变量要素
    ifnb.list <- lapply(X = ifnb.list, FUN = function(x) {
        x <- NormalizeData(x)
        x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
    })
    #选择跨数据集重复可变的要素进行集成
    features <- SelectIntegrationFeatures(object.list = ifnb.list)
    #使用FindIntegrationAnchors()函数识别锚点，该函数将Seurat对象列表作为输入，并使用这些锚点将两个数据集与IntegrateData()集成在一起
    immune.anchors <- FindIntegrationAnchors(object.list = ifnb.list, anchor.features = features)
    #此命令创建“集成”数据分析
    if ( is.null(opt$kweight) ){
     kweight = 100
    } else {
     kweight = opt$kweight
    }
    data_ob <- IntegrateData(anchorset = immune.anchors,k.weight = opt$kweight)
    #指定我们将对校正后的数据执行下游分析注意原始未修饰数据仍驻留在“RNA”测定中
    Seurat::DefaultAssay(data_ob) <- "integrated"
    data_ob@assays$integrated@var.features=setdiff(data_ob@assays$integrated@var.features,remove_gene)
    data_ob <- ScaleData(data_ob, verbose = FALSE)
    data_ob@assays$RNA@var.features <- data_ob@assays$integrated@var.features
    data_ob@assays$RNA@scale.data <- data_ob@assays$integrated@scale.data
    data_ob@assays$RNA@meta.features <- meta_features
    #data_ob = immune.combined
    # 获取高变，用于pca等等
    variablefs = Seurat::VariableFeatures(data_ob)
    print(length(variablefs))
  }

# Determine statistically significant principal components for clustering
reduct1s <- as.character(unlist(stringr::str_split(opt$reduct1, ",")))
for (reduct1 in c(reduct1s)) {
if ( reduct1 %in% OESingleCell::Reductions(data_ob) & as.logical(opt$rerun) == F ){#if previous reduction has been calculated ,donot rerun
    if ( reduct1 %in% c("pca","cca","harmony","ica", "lsi") ){ #if the prevous reduction is primary reduction
        #check the components
        # find the optimal components for secondary reduction
        optimal_pc = tryCatch(
                  expr = Seurat::Command(data_ob, command = glue::glue("FindNeighbors.{opt$assay}.{reduct1}"), value = "dims"),
                  error = function(...){ return(NULL) }
                )
        optimal_pc = length(optimal_pc)
        if ( is.null(optimal_pc) ){ #if previous optimal components not available
            print( "NO previous optimal components is AVAILABLE, the optimal components number be detected automatically.")
            elb = Seurat::ElbowPlot(data_ob, reduction = reduct1)
            optimal_pc = OESingleCell::FindElbow(elb$data)
            # suppressWarnings({ Misc(data_ob, "optimal_pc") = optimal_pc})
        }
    }else{ # reduct1 is not primary reduction and previouly run without primary reduction
            # the exception is mnn, it's better to be specified from command line with relative low value
            optimal_pc = min(opt$components, ncol(OESingleCell::Embeddings(data_ob,reduction = reduct1)))
    }
    scale_data = Seurat::GetAssayData(data_ob, assay = Seurat::DefaultAssay(data_ob), slot = "scale.data")
}else{ # this can be primary reduction or secondary reduction
    print( "NO specified primary reduction found or forced to rerun! \n Reduction begins!")
    message(paste0("Running ", reduct1, " Dimension Reduction"))
    dim_outdir = file.path(output_dir,paste0(reduct1, "_Dimension_Reduction"))
    if ( !dir.exists(dim_outdir) ){
        dir.create(dim_outdir, recursive = T)
    }
    scale_data = Seurat::GetAssayData(data_ob, assay = Seurat::DefaultAssay(data_ob), slot = "scale.data")

    var_features <- data_ob@assays[[assays]]@var.features
    meta_features <- data_ob@assays[[assays]]@meta.features 

    data_ob = RunDimReduc(data_ob, reduct1.use = ifelse(
                        reduct1 == "harmony",
                        yes = "pca",
                        no = reduct1
                    ) ,
                        reduct2.use = reduct1,
                        feature.use = variablefs,
                        perplexity = opt$perplexity,
                        assay.use = Seurat::DefaultAssay(data_ob),
                        batch.use = opt$batchid, npcs.use = ifelse(
                        reduct1 == "pca",
                        yes = component_pca,
                        no = as.numeric(opt$components)
                    ) )
    message(paste0("Running ", reduct1, " Dimension Reduction finished! npcs.use: ",ifelse(
                        reduct1 == "pca",
                        yes = component_pca,
                        no = opt$components
                    )))
    data_ob@assays[[assays]]@var.features <- var_features
    data_ob@assays[[assays]]@meta.features <- meta_features

    reduct1_coord = OESingleCell::FetchData(data_ob, vars = c("rawbc", paste0( Seurat::Key(data_ob)[reduct1], 1:2))) %>%
                    dplyr::rename( "Barcode" = "rawbc")
    write.table( reduct1_coord, file.path(dim_outdir, paste0(reduct1, "_Dimension_Reduction_coordination.csv")),
                sep = ",", col.names = T, row.names = F, quote = F)

    optimal_pc = opt$components
    if ( reduct1 %in% c("pca","cca","harmony","ica", "lsi") ){ #if the prevous reduction is primary reduction
        if (is.null(optimal_pc)){
            optimal_pc = OESingleCell::FindElbow(data_ob, reduction = reduct1 )
        }
    }
}
}
# in case of dimension number out of the actual.
components2use = min( optimal_pc, ncol(OESingleCell::Embeddings(data_ob,reduction = reduct1)))
# after primary reduction, the scale.data will not be used, so as to delete it for saveing memory
# data_ob[[Seurat::DefaultAssay(data_ob)]] = Seurat::SetAssayData(data_ob[[Seurat::DefaultAssay(data_ob)]], slot = "scale.data", new.data=matrix() )
data_ob[[Seurat::DefaultAssay(data_ob)]] = Seurat::SetAssayData(data_ob[[Seurat::DefaultAssay(data_ob)]], slot = "scale.data", new.data=scale_data )
gc()

# print batchid result
  # 当非batchid作为批次时，将作为批次的列转为数字
if (!is.null(opt$batchid) && opt$batchid != 'batchid') {
  true_batchid <- as.numeric(as.factor(data_ob@meta.data[, opt$batchid]))
} else if (is.null(opt$batchid)) {
  # 没有指定batchid时，默认批次信息相同
  true_batchid <- rep(1, length(data_ob$batchid))
} else {
  true_batchid <- data_ob$batchid
}

cat("sampleid\tbatchid",unique(paste0(data_ob$sampleid,"\t",true_batchid)),sep="\n",file=file.path(output_dir,paste0("sampleid-batchid.xls")))

######### Clustering with the reduction results using different clustering methods
clustering.alg = c("snn" = 1, "louvain" = 2, "slm" = 3, "leidn" = 4)
message(glue::glue("Beginning to group the cells using algorithm {opt$clusteringuse} with top {components2use} {reduct1} components!" ) )
data_ob = Seurat::FindNeighbors( data_ob, reduction = reduct1, dims = 1:components2use,
                            features = variablefs,
                           nn.eps = 0, force.recalc = T, verbose = F)
data_ob = Seurat::FindClusters(object = data_ob, resolution = opt$resolution,
                               algorithm = clustering.alg[opt$clusteringuse], verbose = F)
message("Clustering Finished!")

######### secondary reduction
# secondary reduction used to detect the community in graph if graph-based clustering
# method used.
if ( !is.null( opt$reduct2) ){
    # message(paste0("Beginning ", opt$reduct2, " Dimension Reduction"))
    dim_outdir = file.path(output_dir,paste0(opt$reduct2, "_Dimension_Reduction"))
    if ( !dir.exists(dim_outdir) ){
        dir.create(dim_outdir, recursive = T)
    }
    data_ob = RunDimReduc(data_ob, reduct1.use = reduct1 , reduct2.use = opt$reduct2,
                            feature.use = variablefs,
                            assay.use = Seurat::DefaultAssay(data_ob),
                            batch.use = opt$batchid, npcs.use = components2use)
    reduct2_coord = OESingleCell::FetchData(data_ob,
                        vars = c("rawbc", paste0( Seurat::Key(data_ob)[opt$reduct2], 1:2))) %>%
                        dplyr::rename( "Barcode" = "rawbc")
    message(paste0("Running ", opt$reduct2, " Dimension Reduction finished! npcs.use: ", components2use ))
    
    write.table( reduct2_coord, file.path(dim_outdir, paste0(opt$reduct2, "_Dimension_Reduction_coordination.csv")),
    sep = ",", col.names = T, row.names = F, quote = F)
}else{
    opt$reduct2 = reduct1
}

######### save the clustering results
cell_id = Seurat::Idents(data_ob)
new_id = as.numeric(as.vector(cell_id)) + 1 # new cluster id start from 1
names(new_id) = names(cell_id)
new_id = as.factor(new_id)
cell_count_by_cluster = table( new_id )
Seurat::Idents(data_ob) = new_id
cluster_result_colname = paste(Seurat::DefaultAssay(data_ob), opt$reduct2,"res", opt$resolution, sep = ".")
#as default the seurat will store the clustering results in the data_object@ident
#to keep the clutering results using the specified resolution to data_object@metadata for reuse
# data_ob <- Seurat::StashIdent(object = data_ob, save.name = cluster_result_colname)
data_ob[[cluster_result_colname]] = Seurat::Idents(data_ob)
# data_ob <- Seurat::StashIdent(object = data_ob, save.name = "clusters")
data_ob[["clusters"]] = Seurat::Idents(data_ob)
reordered_cell_count_by_cluster = table(Seurat::Idents(data_ob))
cell_count_labels = paste(paste(names(reordered_cell_count_by_cluster),reordered_cell_count_by_cluster,sep="-")," cells")
ggdimplot = Seurat::DimPlot(object = data_ob,reduction = opt$reduct2, dims = c(1,2), order = levels(Seurat::Idents(data_ob)),
             label = T, group.by= cluster_result_colname,   pt.size = pointsize)
# custom_cols =  SelectColors(1:length(unique(Seurat::Idents(data_ob))), palette = opt$palette)
custom_cols =  get_colors(data_ob@meta.data, groupby = cluster_result_colname, palette = opt$palette)[["new_celltype_pal"]]

ggdimplot = ggdimplot + ggplot2::labs(title = "") + theme(aspect.ratio = 1/1)+
            ggplot2::scale_colour_manual( values = custom_cols,
                                 breaks=levels(Seurat::Idents(data_ob)),
                                 labels = cell_count_labels)
ggplot2::ggsave(file.path(dim_outdir,paste0(opt$reduct2, "_groupby_cluster","_resolution", opt$resolution,"_plot.pdf",collapse="")), 
                plot = ggdimplot, bg="white", width = ifelse(length(unique(Seurat::Idents(data_ob))) <= 20,7.5,9))
ggplot2::ggsave(file.path(dim_outdir,paste0(opt$reduct2, "_groupby_cluster","_resolution", opt$resolution,"_plot.png",collapse="")),dpi=1000, 
                plot = ggdimplot, bg="white", width = ifelse(length(unique(Seurat::Idents(data_ob))) <= 20,7.5,9))
## clustering result csv
clustering_df = OESingleCell::colData(data_ob) %>%
    dplyr::rename( "Barcode" = "rawbc") %>%
    dplyr::select( Barcode, sampleid, clusters, group)
write.table(clustering_df, quote = F,sep =",",row.names = F,
              file.path(output_dir,paste0("clustering_results.csv",collapse = "")))

if ( as.logical(opt$integrated) ){
  print("修改DefaultAssay")
  Seurat::DefaultAssay(data_ob) <- "RNA"
}

if (!is.null(sampleid_levels)){
data_ob@meta.data$sampleid=factor(data_ob@meta.data$sampleid,levels=sampleid_levels)
}
if (!is.null(group_levels)){
data_ob@meta.data$group=factor(data_ob@meta.data$group,levels=group_levels)
}

if ( as.logical(opt$update) ){
  # OESingleCell::SaveX(data_ob, output = opt$input,update = TRUE,
  #                     outformat = opt$outformat, graphs = Seurat::Graphs(data_ob),
  #                     reduction = c(reduct1, reduct2), commands = Seurat::Command(data_ob),
  #                     misc = NULL, tools = NULL )
  # SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob,
                               # reduction = unique(c(opt$reduct1, opt$reduct2)))
  inputdir = dirname(opt$input)
  file.remove(opt$input)
  OESingleCell::SaveX(data_ob, output = inputdir,update = FALSE,
                      outformat = opt$outformat, prefix = 'filtered')
}else{
  OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                      outformat = opt$outformat, prefix = opt$prefix)
}
quit()
}


# ================= Subcmd: Celltyping invoked=========
if ( "celltyping" %in% args ){
  LEVEL = opt$annolevel
  species = opt$species

 # read the specified assay and data slot in data object into memory
 data_ob = ReadX(
              input = opt$input, informat = opt$informat,
              assays = assays,
              data.use = dataslots, # "counts"
              reductions = opt$reduct, # only the used reduction results needed
              graphs = FALSE, # no graph object needed here
              images = FALSE, verbose = FALSE)

  # subset test data object
  if ( !is.null(opt$predicate) ){
      df = colData(data_ob)
      desired_cells= subset(df, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }

  raw_data_ob = data_ob
  source("/gpfs/oe-scrna/pipeline/scRNA-seq_further_analysis/function/seuratFc.r")
  if (tolower(species) %in% c("monkey","pig","chicken")){
    inTaxids = c(9544,9823,9031)
    inTaxid = inTaxids[grep(tolower(species), c("monkey","pig","chicken"))]
    outTaxid = 9606
    data_ob = homologene_transformed(data_ob, inTaxid, outTaxid,output_dir,opt$assay)
    }else if( tolower(species) %in% c("rat") ){
    inTaxids = c(10116)
    inTaxid = inTaxids[grep(tolower(species), c("rat"))]
    outTaxid = 10090
    data_ob = homologene_transformed(data_ob, inTaxid, outTaxid,output_dir,opt$assay)
    }

  # pointsize
  if ( is.null(opt$pointsize) ){
      if (dim(data_ob)[2] < 500){
          pointsize = 1.5
      } else pointsize = 0.5
  } else {
      pointsize = opt$pointsize
  }

  # Reference datasets are log2 transformed rather than natural log transformed
  # (Seurat).
  test.sce = Seurat::as.SingleCellExperiment(data_ob)
  test.sce = scuttle::logNormCounts(test.sce)

  if ( is.null(opt$builtinref) & is.null(opt$customref) ) stop("NO reference AVAILABE!")

  refd.list = list()
  if (!is.null(opt$customref)) {
    cref = unlist(strsplit(opt$customref, ",") )
    for( refx in cref ){
      refx = normalizePath(refx)
      refid = gsub("\\..[^\\.]*$","",make.names(basename(refx)))
      #判断refx是否为sce
      ref.test = readRDS(refx)
      if (class(ref.test) == 'SingleCellExperiment'){
          print('输入参考数据集为SingleCellExperiment，直接读取')
          ref.sce = ref.test
      } else if(class(ref.test) == 'Seurat'){
          print('输入参考数据集为Seurat，转换为SingleCellExperiment')
          ref.sce = Seurat::as.SingleCellExperiment(ref.test)
          ref.sce = scuttle::logNormCounts(ref.sce)
      } else stop("未知的输入格式")
      
      refd.list[[refid]] = ref.sce

      
    }
  }

  if ( !is.null(opt$builtinref) ){
    bref = unlist(strsplit(opt$builtinref, ",") )
    for( refx in bref ){
      refd.list[[refx]] = readRDS(system.file(package = "celldex", lib.loc = glue::glue("{orgnism}/{refx}.rds")))
    }
  }

  # prepare the reference data set
  if ( length(refd.list) > 1 ){
    print("using combined result from multiple datasets")
    ref.labels = lapply( refd.list, function(x) factor(x[[LEVEL]]) )
  }else{
    ref.labels = refd.list[[1]][[LEVEL]]
  }

#  if ( length(refd.list) == 1 ){
#    refd.list = refd.list[[1]]
#  }
  refdata = paste0(names(refd.list), collapse = "_")

  # Run prediction now
  if ( length(refd.list) == 1 ){
    pred = SingleR::SingleR(test.sce, ref = refd.list[[1]],
                   labels = ref.labels,
                   BPPARAM = BiocParallel::MulticoreParam(workers = future::nbrOfWorkers()))
  }else{
    pred = SingleR::SingleR(test.sce, ref = refd.list,
                   labels = ref.labels,
                   BPPARAM = BiocParallel::MulticoreParam(workers = future::nbrOfWorkers()))
  }
  data_ob = raw_data_ob
  rm(raw_data_ob)
  raw.metaname = paste0("raw_", LEVEL, "_celltype")
  data_ob = Seurat::AddMetaData(data_ob, metadata = pred[["labels"]], col.name = raw.metaname)
  if ( length(refd.list) > 1 ){
    celltyping_cols = data.frame(labels = pred$labels)
    for ( dx in names(refd.list) ){
      celltyping_cols[[glue::glue("{dx}_labels")]] = pred[["orig.results"]][[dx]][["labels"]]
    }
    data_ob = Seurat::AddMetaData(data_ob, metadata = celltyping_cols)
  }

  #count the cell number for each cell type
  if ( is.null(OESingleCell::colData(data_ob)[["clusters"]]) ){
      # data_ob = StashIdent(data_ob, save.name = "clusters")
      data_ob[["clusters"]] = Seurat::Idents(data_ob)
      warning("No clusters found in the object. use idents instead.")
  }
  celltyping_stat = OESingleCell::FetchData(data_ob, vars = c("clusters", raw.metaname) )%>%
                    dplyr::group_by(clusters,!!rlang::sym(raw.metaname) ) %>%
                    dplyr::summarize(cell_num=dplyr::n()) %>% dplyr::ungroup()
  write.table(celltyping_stat, quote = F,
              file.path(output_dir,
                        paste0(species, "ref_", refdata,"_", LEVEL, "_celltyping_statistics.xls",collapse="")),
              sep = "\t",row.names = F)


  ## heatmap
  print("2.Plot celltyping heatmap")
  meta.data = OESingleCell::FetchData(data_ob, vars = "clusters" ) %>%
              tibble::rownames_to_column(var = "cells")
  if ( ncol(data_ob) > 40000){
    print("Screening of 50,000 cells in proportion...")
    meta.data = meta.data %>% dplyr::group_by(clusters) %>%
                dplyr::sample_frac(40000/dim(data_ob)[2])
    pred=pred[meta.data$cells,]
  }
  if ( is.null(opt$colorschema) ){
    heatmap_color_schema = (grDevices::colorRampPalette(c("#D1147E", "white", "#00A44B")))(100)
  }else{
    colstrings = unlist(strsplit(opt$colorschema,","))
    heatmap_color_schema = (grDevices::colorRampPalette(colstrings))(100)
  }
  ncells = ifelse(  dim(meta.data)[1] > 70000, 70000, dim(meta.data)[1]  )
  plot_width = (1e5 - ncells)/1e4 * ceiling(ncells/30000)
  ## anno
  #annotation_colors <-  list(Clusters=CustomCol(as.numeric(levels(meta.data$clusters))))
  #names(annotation_colors$Clusters) <- as.numeric(levels(meta.data$clusters))
  # annotation_colors = list(Clusters=SelectColors(sort(data_ob[["clusters"]][[1]]), palette = opt$palette))
  annotation_colors = list(Clusters = get_colors(data_ob@meta.data, groupby = "clusters", palette = opt$palette)[["new_celltype_pal"]])
  annotation_colors
  if ( length(refd.list) == 1 ){
    ggheat = SingleR::plotScoreHeatmap(pred, cells.use = meta.data$cells,
                      clusters = meta.data$clusters,
                      max.labels = opt$topn, show.labels = F,
                      colors = heatmap_color_schema, order.by = "clusters",
                      annotation_colors=annotation_colors)
    width4legendlabs = max(nchar(names(head(sort(table(as.factor(pred$labels)),decreasing = T),opt$topn))))
    OESingleCell::save_ggplots(
      file.path(output_dir,paste0(species,"ref_",refdata,"_",LEVEL,"_celltyping_heatmap",collapse=".")),
      plot = ggheat, limitsize = F,width = plot_width + width4legendlabs/15, bg="white" )
  }else{
    refid = c("combine", names(refd.list))
    for ( inx in 0:length(refd.list) ){
      ggheat = SingleR::plotScoreHeatmap(pred,
                                         scores.use = inx,
                                         cells.use = meta.data$cells,
                                         clusters = meta.data$clusters,
                                         max.labels = opt$topn,
                                         show.labels = F,
                                         colors = heatmap_color_schema,
                                         order.by = "clusters")
      width4legendlabs = max(nchar(names(head(sort(table(as.factor(pred$labels)),decreasing = T),opt$topn))))
      OESingleCell::save_ggplots(
        file.path(output_dir,paste0(species,"ref_", refid[inx+1], "_",LEVEL,"_celltyping_heatmap",collapse=".")),
        plot = ggheat, width = plot_width + width4legendlabs/15, bg="white" )
    }
  }
  ## plot raw celltype
  print("3.Plot celltyping embeddings")
  print(length(unique(data_ob[[raw.metaname]][[1]])))
  
  nlevel = length(unique(data_ob[[raw.metaname]][[1]]))
  ncols = ifelse( nlevel > 30, as.integer(nlevel/30)+1, 1)
  if(length(unique(data_ob[[raw.metaname]][[1]])) >50){
      #custom_cols =  SelectColors(data_ob[[raw.metaname]][[1]], palette = opt$palette)
      ggdim = Seurat::DimPlot(data_ob, reduction = opt$reduct,pt.size = pointsize, group.by = raw.metaname ) +
                  ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5),
                                  legend.key.size = grid::unit(0.9,"lines"),
                                  legend.text = ggplot2::element_text(size = 10)) +
                  #ggplot2::scale_colour_manual( values = custom_cols ) +
                  ggplot2::guides(colour = guide_legend(ncol = ncols, override.aes = list(size=2)))+ theme(aspect.ratio = 1/1)
      OESingleCell::save_ggplots(filename = file.path(output_dir,paste0(species,"ref_",refdata,"_",LEVEL,"_celltyping", "_plot")),
                                 plot = ggdim, width = (8+ (width4legendlabs/13)* ncols), dpi = 300, bg="white")
  }else {
      # custom_cols =  SelectColors(data_ob[[raw.metaname]][[1]], palette = opt$palette)
      custom_cols =  get_colors(data_ob@meta.data, groupby = raw.metaname, palette = opt$palette)[["new_celltype_pal"]]
      ggdim = Seurat::DimPlot(data_ob, reduction = opt$reduct,pt.size = pointsize, group.by = raw.metaname ) +
                  ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5),
                                  legend.key.size = grid::unit(0.9,"lines"),
                                  legend.text = ggplot2::element_text(size = 10)) +
                  ggplot2::scale_colour_manual( values = custom_cols ) +
                  ggplot2::guides(colour = guide_legend(ncol = ncols, override.aes = list(size=2)))+ theme(aspect.ratio = 1/1)
      OESingleCell::save_ggplots(filename = file.path(output_dir,paste0(species,"ref_",refdata,"_",LEVEL,"_celltyping", "_plot")),
                                 plot = ggdim, width = (8+ (width4legendlabs/13)* ncols), dpi = 300, bg="white")
  }
  ## TOPN result
  # data_ob = Seurat::SetIdent( data_ob, value = "clusters")
  #top_celltype = celltyping_stat %>% dplyr::group_by(clusters) %>% dplyr::top_n(1,cell_num) %>% dplyr::ungroup() 
  top_celltype = celltyping_stat %>% dplyr::group_by(clusters) %>% dplyr::arrange(desc(cell_num)) %>% dplyr::do(head(.,1)) %>% dplyr::ungroup()
  data_ob[[paste0(refdata,".",LEVEL,".celltype")]] = plyr::mapvalues(x = data_ob[["clusters"]][[1]],
                                           from = as.vector(top_celltype[["clusters"]]),
                                           to = as.vector(top_celltype[[raw.metaname]]))
  data_ob[["celltype"]] <- data_ob[[paste0(refdata,".",LEVEL,".celltype")]] # the final celltyping results column

  full_celltyping_df = OESingleCell::colData(data_ob) %>%
    tibble::rownames_to_column(var = "barcode_inuse") %>%
    dplyr::rename( "Barcode" = "rawbc" ) %>%
    dplyr::select( Barcode, everything())
  write.table(full_celltyping_df, quote = F,
              file.path(output_dir,paste0(species,"ref_",refdata,
                                          "_",LEVEL,"_celltyping_results.xls",collapse = "")), sep = "\t", row.names = F)
  simplified_celltyping_df = OESingleCell::colData(data_ob) %>%
    dplyr::rename( "Barcode" = "rawbc") %>%
    dplyr::select( Barcode, sampleid, celltype, clusters,group)
  write.table(simplified_celltyping_df, quote = F,sep =",",row.names = F,
              file.path(output_dir,paste0(species,"ref_",refdata,
                                          "_",LEVEL,"_simplified_celltyping_results.csv",collapse = "")))

  ## obtain the top cluster number for each celltype (for the purpose of coloring)
  # top_celltype[["colors"]] = SelectColors(top_celltype[["clusters"]], palette = opt$palette)
  colorx = get_colors(data_ob@meta.data, groupby = "celltype", palette = opt$palette)[["new_celltype_pal"]]
  # colorx = top_celltype %>%
              # dplyr::mutate(colors = SelectColors(clusters, palette = opt$palette)) %>%
              # dplyr::select(-c(clusters, cell_num)) %>%
              # dplyr::group_by(.data[[raw.metaname]]) %>%
              # dplyr::slice_head(n = 1) %>%
              # dplyr::ungroup() %>% tibble::deframe()
  ggdim2 = Seurat::DimPlot(data_ob, reduction = opt$reduct,pt.size = pointsize, group.by = "celltype" ) +
            theme( plot.title = ggplot2::element_text(hjust = 0.5)) +
            scale_colour_manual( values = colorx )+ theme(aspect.ratio = 1/1)
  OESingleCell::save_ggplots(file.path(output_dir,paste0(species,"ref_",refdata,"_top.",LEVEL,"_celltyping_plot")),
                               plot = ggdim2, width = (7+ (width4legendlabs/12)* ncols), dpi = 300, bg="white")
  # data_ob@reductions$pca = raw_data_ob@reductions$pca
  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob, verbose = FALSE )
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }

  quit()
}


# ====================== Subcmd: visualize the markers in different ways =========
if ( "visualize" %in% args ){
  flip = opt$flip
  dotsplit = opt$dotsplit
  groupby = opt$groupby
  splitby = opt$splitby
  if (is.null(splitby)){
      legend_position = 'none'
  }else{
      legend_position = 'right'
  }
  if ( identical(groupby,splitby)){
      warning( "The variable specified by --splitby conflicted with the --groupby parameter, NULL will be used!")
      splitby = NULL
  }

 # read the specified assay and data slot in data object into memory
 # for visualization usually only "data" slot is loaded,which can save a lot of time and memory
 data_ob = ReadX(
              input = opt$input, informat = opt$informat,
              assays = assays,
              data.use = dataslots, # "data"
              reductions = opt$reduct, # only the used reduction results needed
              graphs = FALSE, # no graph object needed here
              verbose = FALSE)
  #get the subset of cells used  if necessay
  if ( !is.null(opt$predicate) ){
    desired_cells= subset(OESingleCell::colData(data_ob), eval( parse(text=opt$predicate)))
    # same for Seurat, SingleCellExperiment, summarizedExperiment
    data_ob = data_ob[,rownames(desired_cells)]
  }

  # if ( is.null(opt$cluster_name) ){
  #   data_ob[["clusters"]] = Seurat::Idents(data_ob)
  # }else{
  #   # data_ob = Seurat::SetIdent( data_ob, value = opt$cluster_name)
  #   data_ob[[opt$cluster_name]] = Seurat::Idents(data_ob)
  # }
  clusters = OESingleCell::FetchData(data_ob, vars = "clusters")[[1]]
  if(all(!is.na(as.numeric(clusters)))){
        data_ob[["clusters"]] = factor(clusters, levels = sort( unique(as.numeric(clusters))))
  }
  #determine the color schema for discrete and continious variables
  vcolors = unlist(strsplit(opt$vcolors,","))
  if ( length(vcolors) == 1 ){ # this means to use customized discrete color schema in OESingleCell package
    if ( is.null(discrete_palette[[vcolors]]) ){
      info = glue::glue("the customized discrete colors are: \n {paste(names(discrete_palette), lengths(discrete_palette), sep =': ', collapse = '\n')}.")
      warning("NO specified color schema found!")
      warning(info)
      stop()
    }
    if ( ! as.logical(opt$use_color_anno) ){
        data_ob@meta.data = data_ob@meta.data[ ,!grepl(paste0("^",groupby,"_col$" ), colnames(data_ob@meta.data))]
    }
    if ( !is.null(opt$color_file)){
        color_file = read.delim(opt$color_file, sep="\t", header = T)
        meta_anno = color_anno(data_ob@meta.data, color_file)
    } else {
        meta_anno = data_ob@meta.data
    }
    #discrete_colors = SelectColors(palette = vcolors)
    discrete_colors = get_colors(meta_anno, groupby = groupby, palette = vcolors)[["new_celltype_pal"]]
  }else{ # this means to use the customized color schema from command line specified by user
    discrete_colors = vcolors
  }
  ccolors = unlist(strsplit(opt$ccolors,","))
  if ( length(ccolors) == 1 ){ # this means to use customized discrete color schema in OESingleCell package
    if ( is.null(continuous_palette[[ccolors]]) ){
      info = glue::glue("the customized continious colors are: \n {paste(names(continuous_palette), lengths(continuous_palette), sep =': ', collapse = '\n')}.")
      warning("NO specified color schema found!")
      warning(info)
      stop()
    }
   # continious_colors = SelectColors(palette = ccolors, is.discrete = FALSE)
    continious_colors = continuous_palette[[ccolors]]
  }else{ # this means to use the customized color schema from command line specified by user
    continious_colors = ccolors
  }

  if ( is.null(opt$pointsize) ){
      if (dim(data_ob)[2] < 500){
          pointsize = 1.5
      } else pointsize = 0.5
  } else {
      pointsize = opt$pointsize
  }
  if ( is.null( opt$markers ) & is.null(opt$extraGene)){
      stop("NO marker genes is AVAILABLE!")
  }

  topn_markers = data.frame()
  if ( !is.null(opt$markers) ){
      markers2vis = read.table( opt$markers, sep="\t", header = T )
      topn_markers  = markers2vis %>%
          dplyr::group_by(cluster) %>%
          # dplyr::arrange(p_val, desc(avg_log2FC)) %>%
          dplyr::arrange(desc(gene_diff)) %>%
          dplyr::top_n(opt$topn, wt = !!rlang::sym(opt$topby) ) %>%
          dplyr::arrange(cluster) %>%
          dplyr::mutate(folder_suffix = paste0("cluster",cluster)) %>%
          dplyr::select(cluster,gene,folder_suffix)
  }
  if ( !is.null(opt$extraGene) ){
    extra_gene = read.table(opt$extraGene, sep="\t", header = T,stringsAsFactors = F)
    if (dim(extra_gene)[2] == 1 && colnames(extra_gene)[1] == "gene"){colnames(extra_gene)[1]="extra"}
    formated_extra_gene = as.data.frame(tidyr::gather(extra_gene,key = "cluster",value = "GENE"))
    match = OESingleCell::CaseMatch(search = as.vector(formated_extra_gene$GENE),match = rownames(data_ob))
    filtered_gene = formated_extra_gene$GENE[!formated_extra_gene$GENE %in% names(match )& formated_extra_gene$GENE != ""]
    if(length(filtered_gene)!=0){
        filtered_gene = as.data.frame(filtered_gene)
        colnames(filtered_gene) = "Gene"
        write.table(filtered_gene,file.path(output_dir,"genes_not_matched.xls"),quote = F,row.names=F)
        print("There are some mismatched gene symbol, Please check genes_not_matched.xls for the genename.")
    }
    formated_extra_gene = formated_extra_gene %>%
                          dplyr::filter(GENE %in% names(match)) %>%
                          dplyr::mutate(gene = match,folder_suffix = cluster) %>%
                          dplyr::select(cluster, gene,folder_suffix)
    topn_markers = rbind(topn_markers, formated_extra_gene)
  }

if ( is.null(opt$vismethod) ){
    print("NO marker gene visulization method provided,the default method vlnplot and featureplot will be used!")
    vismethods = c("vlnplot","featureplot")
}else if( opt$vismethod == "all" ){
    vismethods = c("vlnplot","featureplot","ridgeplot","dotplot","boxplot","splitby_featureplot")
}else{
    vismethods = unlist(strsplit(opt$vismethod,","))
}

cellmeta = OESingleCell::colData(data_ob)
root_dir = output_dir
comp = list()
if ( !is.null(opt$pvalue) ){
  all_comparisions = list()
  contrasts_list = unlist(strsplit(opt$pvalue, "\\+", perl = T))
  # contrasts_list = unlist(strsplit(pvalue, "\\+", perl = T)) ##delete
  for ( contrast in contrasts_list ){
    contrast = paste0(groupby,":",contrast)
    contrasts = unlist( strsplit(contrast,":",perl = T) )
    assay_metadata=data_ob@meta.data
    all_levels = as.vector(unique(assay_metadata[,contrasts[1]]))
    if ( contrasts[2] == "all" & contrasts[3] != "all" ){
        all_levels = all_levels[-which(all_levels==contrasts[3])] #delete the reference level
        all_comparisions = paste(all_levels,contrasts[3],sep = ":")
        break
    }else if( contrasts[2] == "all" & contrasts[3] == "all" ){
        all_comparisions = "all"
        break
    }else if ( contrasts[2] != "all" & contrasts[3] == "all" ){
        all_levels = all_levels[-which(all_levels==contrasts[2])]
        all_comparisions = paste(contrasts[2],all_levels,sep = ":")
        break
    }else{
        if ( !contrasts[2] %in% all_levels | !contrasts[3] %in% all_levels){
          print(paste0(contrasts[2],":",contrasts[3],"所选分组中细胞数为0,请检查分组比较信息。已跳过该分组。"))
        }else if ( table(assay_metadata[,groupby])[contrasts[2]]<=1 | table(assay_metadata[,groupby])[contrasts[3]]<=1){
          print(paste0(contrasts[2],":",contrasts[3],"所选分组中细胞数小于2,请检查分组比较信息。已跳过该分组。"))
        }else{
          all_comparisions = c(all_comparisions , paste0(contrasts[2],":",contrasts[3]))
        }
    }
  }
  my_comparisons = sort(unique((data_ob@meta.data[,groupby]))) ##找到分组信息
  comp=list()
  ##若为all:all,则通过循环生成各个分组两两结合比对的list
  if ( all_comparisions == "all" ){
    for(a in 1:(length(my_comparisons)-1)){
      for(b in 1:(length(my_comparisons)-a)){
      list=c(as.character(my_comparisons[a]),as.character(my_comparisons[a+b]))
      comp=c(comp,list(list))
      }
    }
  }else{
    for( i in all_comparisions ){
      list=strsplit(i,":",perl = T)
      comp=c(comp,list)
    }
  }
}
print(comp)
for ( vismethod in vismethods ){
  if ( vismethod == "vlnplot" ){

    modify_vlnplot<- function(data_ob, gene, pt.size = 0.1, groupby = groupby, plot.margin = unit(c(-0.75, 0, -0.75, 0), "cm"), ...) {
      p<- Seurat::VlnPlot(data_ob, 
                features = gene, 
                pt.size = pt.size, 
                group.by = groupby, 
                cols = discrete_colors,
                alpha = 0,... )  + 
      xlab("") + ylab("") + ggtitle(gene) + 
      theme(legend.position = "none", 
          axis.text.x = element_blank(), # 去除x轴文本
          axis.ticks.x = element_blank(), # 去除x轴下方凸出线条
          plot.margin = plot.margin ) 
      return(p)
    }

    StackedVlnPlot<- function(data_ob, gene, pt.size = 0.1, groupby = groupby, plot.margin = unit(c(-0.75, 0, -0.75, 0), "cm"), ...) {
      plot_list<- purrr::map(gene, function(x) modify_vlnplot(data_ob = data_ob,gene = x, pt.size = 0.1, groupby = groupby,...))
      plot_list[[length(plot_list)]]<- plot_list[[length(plot_list)]] +
      theme(axis.text.x = element_text(angle = 30))

      p<- patchwork::wrap_plots(plotlist = plot_list, ncol = 1)
      return(p)
    }

    # Draws a violin plot of single cell data (gene expression, metrics, PC scores, etc.)
    for ( clusterx in unique(topn_markers$folder_suffix) ){
      topn = topn_markers %>%
        dplyr::filter( folder_suffix == clusterx) %>%
        dplyr::select(cluster,gene,folder_suffix)
      topn_markers2vis = as.vector(topn$gene)
      topn_markers2vis_list <- split(topn_markers2vis, ceiling(seq_along(topn_markers2vis)/10))

      path4vis = file.path(root_dir,paste0("markers_vis4",clusterx,collapse = ""))
      if ( file.exists( path4vis ) ){
          output_dir = path4vis
      }else{
          output_dir = path4vis
          dir.create(output_dir, recursive = T)
      }
      
      if ( !is.null(opt$pvalue) & length(comp) != 0 ){
        suppressPackageStartupMessages( library("ggsignif") )
        suppressPackageStartupMessages( library("tibble") )
        .libPaths("/home/liuhongyan/miniconda3/envs/scvdj/lib/R/library")
        # .libPaths("/home/liuhongyan/miniconda3/envs/scvdj/lib/R/library")
        suppressPackageStartupMessages( library("ggstatsplot") )
        # suppressPackageStartupMessages( library("dplyr") )
        metadata <- data_ob@meta.data
        for(gene in topn_markers2vis){
          # max.feature.value <- max(data_ob@assays$RNA@data[gene,])
          # max.feature.value=max.feature.value + 0.4*length(comp)+0.5
          value <- as.matrix(data_ob[[assays]]@data[gene, ])
          metadata = data_ob@meta.data %>% tibble::rownames_to_column(var = "id")
          plotdata = cbind(metadata, value )
          plotdata["x"]=plotdata[groupby]
          gs <- ggstatsplot::ggbetweenstats(
            data = plotdata ,
            x = x,
            y = value,
            plot.type = "boxviolin",
            results.subtitle =FALSE,
            messages = FALSE,
            pairwise.comparisons = FALSE, 
            mean.label.size = 0, # size of the label for mean
            centrality.plotting = F,
            ylab = gene
          ) + 
          scale_color_manual(values = discrete_colors)  +
          theme(axis.text.x = element_text(size=8,colour="black"),
               axis.text.y = element_text(size=8,colour="black"),
               panel.grid.major =element_blank(), 
               panel.grid.minor = element_blank(),
               panel.background = element_blank(),
               axis.line = element_line(colour = "black")) +
          geom_signif(comparisons = comp, #指定比较对象
               test = "wilcox.test", #指定检验方法
               size = 0.4, #指定标记中线条的尺寸
               textsize = 2.6, #指定标记中文字部分的大小
               vjust = -0.05, #指定标记中文字部分与横线之间的距离指定标记中文字部分与横线之间的距离
               step_increase = 0.1, #指定每根线条距离高低
               #tip_length = c(0.2, 0.2), #指定短竖线的长度
               map_signif_level =T )  #F显示具体数值，T显示显著性 
        gs = gs + labs(x=groupby)
          OESingleCell::save_ggplots(file.path(output_dir, paste0(gene,"_violin_plot_with_pvalue")),
                            plot = gs,width = 7,height = 5+0.3*length(comp),dpi = 300 ,limitsize = F, bg="white")
        }
      } else {
      #识别字符串长度
      if(any(nchar(as.character(unique(cellmeta[[groupby]]))) >20)){char_length_excess = TRUE}else{char_length_excess = FALSE}
      if (char_length_excess == TRUE) {
          fig_i = 1
          topn_markers2vis_list <- split(topn_markers2vis, ceiling(seq_along(topn_markers2vis)/5))
      for (gene in topn_markers2vis_list) {
          gs = Seurat::VlnPlot(data_ob, features = gene,
                    cols = discrete_colors,
                    pt.size = 0.1, alpha = opt$alpha2use,
                    group.by = groupby,
                    split.by = splitby,
                    split.plot = as.logical(FALSE) ,ncol=1) &
               ggplot2::labs(y = "", x=NULL) &
               ggplot2::theme(
                    legend.position=legend_position,
                    legend.margin = ggplot2::margin(0,1,0,0, unit = "cm"),
                    plot.margin = ggplot2::margin(0.1, 0, 0, 0.1, unit = "cm"),
                    axis.text = ggplot2::element_text(margin = ggplot2::unit(0,"null")),
                    axis.title.x = ggplot2::element_text(size = 0),
                    axis.title.y = ggplot2::element_text(size = 12),
                    axis.text.x = ggplot2::element_text(size = 10, angle = 30),
                    axis.text.y=ggplot2::element_text(size = 8))
          if ( length(topn_markers2vis) <= 5 ) {
                    OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_plot",collapse="")),
                          plot = gs,
                          width = 8 + 0.5*(length(unique(cellmeta[[groupby]]))),
                          height = length(gene)*3,dpi = 300 ,limitsize = F, bg="white")
               } else {
                    OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_",fig_i,"_plot",collapse="")),
                          plot = gs,
                          width = 8 + 0.5*(length(unique(cellmeta[[groupby]]))),
                          height = length(gene)*3,dpi = 300 ,limitsize = F, bg="white") 
               }
          fig_i = fig_i + 1
        }
      }else{
        if ( opt$xlab == "TRUE") {
          fig_i = 1
          for (gene in topn_markers2vis_list) {
              gs = Seurat::VlnPlot(data_ob, features = gene,
                        cols = discrete_colors,
                        pt.size = 0.1, alpha = opt$alpha2use,
                        group.by = groupby,
                        split.by = splitby,
                        split.plot = as.logical(FALSE) ,ncol=1) &
                  ggplot2::labs(y = "", x=NULL) &
                  ggplot2::theme(
                        legend.position=legend_position,
                        legend.margin = ggplot2::margin(0,1,0,0, unit = "cm"),
                        plot.margin = ggplot2::margin(0.1, 0, 0, 0.1, unit = "cm"),
                        axis.text = ggplot2::element_text(margin = ggplot2::unit(0,"null")),
                        axis.title.x = ggplot2::element_text(size = 0),
                        axis.title.y = ggplot2::element_text(size = 12),
                        axis.text.x = ggplot2::element_text(size = 10, angle = 30),
                        axis.text.y=ggplot2::element_text(size = 8))
              if ( length(topn_markers2vis) <= 10 ) {
                        OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_plot",collapse="")),
                              plot = gs,
                              width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                              height = length(gene)*2,dpi = 300 ,limitsize = F, bg="white")
                  } else {
                        OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_",fig_i,"_plot",collapse="")),
                              plot = gs,
                              width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                              height = length(gene)*2,dpi = 300 ,limitsize = F, bg="white") 
                  }
              fig_i = fig_i + 1
            }
        }else{
          fig_i = 1
          for (gene in topn_markers2vis_list) {
              gs = StackedVlnPlot(data_ob,gene,pt.size = 0.1,groupby)
              if ( length(topn_markers2vis) <= 10 ) {
                        OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_plot",collapse="")),
                              plot = gs,
                              width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                              height = length(gene)*2,dpi = 300 ,limitsize = F, bg="white")
                  } else {
                        OESingleCell::save_ggplots(file.path(output_dir,paste0("marker_gene_violin_",fig_i,"_plot",collapse="")),
                              plot = gs,
                              width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                              height = length(gene)*2,dpi = 300 ,limitsize = F, bg="white") 
                  }
              fig_i = fig_i + 1
          }
        }
      }
      }
    }
  }  

  if ( vismethod == "featureplot" ){
      for ( clusterx in unique(topn_markers$folder_suffix) ){
          if ( !opt$reduct %in% Seurat::Reductions(data_ob) ){
              stop( "NO specified reduction found in the object!")
          }else{
              reduct = opt$reduct
          }
          topn = topn_markers %>%
                  dplyr::filter( folder_suffix == clusterx) %>%
                  dplyr::select(cluster,gene,folder_suffix)
          topn_markers2vis = as.vector(topn$gene)
          topn_markers2vis_list <- split(topn_markers2vis, ceiling(seq_along(topn_markers2vis)/10))
          path4vis = file.path(root_dir,paste0("markers_vis4",clusterx,collapse = ""))
          if ( file.exists( path4vis ) ){
              output_dir = path4vis
          }else{
              output_dir = path4vis
              dir.create(output_dir, recursive = T)
          }
          fig_i = 1
          for (gene in topn_markers2vis_list){
              data_feature <- FetchData(data_ob,vars = c(paste0(Key(data_ob[[reduct]]), c(1,2)), 'ident', gene),cells = Seurat::Cells(data_ob[[reduct]]),slot = 'data')
              plot_features <- setdiff(x = names(x = data_feature), y = c(paste0(Key(data_ob[[reduct]]), c(1,2)), 'ident'))
              max.cutoff <- mapply(FUN = function(cutoff, feature) {return(cutoff)},cutoff = 'q99',feature = plot_features)
              names(x = max.cutoff) <- plot_features
              for (i in seq_along(along.with = plot_features)) {
                f <- plot_features[i]
                data.feature <- data_feature[[f]]
                max.use <- Seurat:::SetQuantile(cutoff = max.cutoff[f], data = data.feature)
                data.feature[data.feature > max.use] <- max.use
                data_feature[[f]] <- data.feature
              }
              suppressMessages({
               ggfeatures = Seurat::FeaturePlot(data_ob,reduction= reduct,
                                    features = gene, split.by = splitby,
                                    keep.scale = "all",
                                    max.cutoff = 'q99',
                                    order = T,
                                    pt.size = pointsize, 
                                    ncol = ifelse( is.null(splitby) ,yes = ifelse(length(gene) >1, yes=2,no=1), no =2 ) ) &
                          # ggplot2::scale_colour_gradientn(colours = colorRampPalette(rev(RColorBrewer::brewer.pal(11, "Spectral")))(100) ) &
                          ggplot2::scale_color_gradientn(colours = continious_colors,limit = c(0,max(data_feature[,plot_features]))) &
                          ggplot2::theme(legend.position = "none",
                                legend.margin = ggplot2::margin(0,0.5,0,0, unit = "cm"),
                                plot.margin = ggplot2::margin(0.1, 0.1, 0.1, 0.1, unit = "cm"),
                                plot.title = ggplot2::element_text(hjust = 0.5) )
          })
          ggm = ggpubr::ggarrange(ggfeatures,common.legend = T, legend = "right")

          if ( length(topn_markers2vis) <= 10 ) {
               OESingleCell::save_ggplots(
                    file.path(output_dir, paste0("marker_gene_featureplot",collapse="")),
                    width =  4*ifelse( is.null(splitby) ,yes = ifelse(length(gene) >1, yes=2,no=1), no =length(unique(cellmeta[[splitby]]))),
                    height = 4*ifelse(is.null(splitby),
                                yes = ceiling(length(gene)/2),
                                no  = length(gene)),
                    plot = ggm, dpi = 300 ,limitsize = F,bg="white" )
               } else {
               OESingleCell::save_ggplots(
                    file.path(output_dir, paste0("marker_gene_featureplot_",fig_i,collapse="")),
                    width =  4*ifelse( is.null(splitby) ,yes = ifelse(length(gene) >1, yes=2,no=1), no =length(unique(cellmeta[[splitby]]))),
                    height = 4*ifelse(is.null(splitby),
                                yes = ceiling(length(gene)/2),
                                no  = length(gene)),
                    plot = ggm, dpi = 300 ,limitsize = F,bg="white" )
               }
          fig_i = fig_i + 1
        }
      }
  }
if ( vismethod == "splitby_featureplot" ){
    for ( clusterx in unique(topn_markers$folder_suffix) ){
      temp_reduct = opt$reduct
      temp_mtx = data_ob@reductions[[temp_reduct]]@cell.embeddings
      x_min = min(temp_mtx[,1])
      x_max = max(temp_mtx[,1])
      y_min = min(temp_mtx[,2])
      y_max = max(temp_mtx[,2])
          if ( !opt$reduct %in% names(Key(data_ob)) ){
              stop( "NO specified reduction found in the object!")
          }else{
              reduct = opt$reduct
          }
          topn = topn_markers %>% dplyr::filter( folder_suffix == clusterx) %>% dplyr::select(cluster,gene,folder_suffix)
          topn_markers2vis = as.vector(topn$gene)

          path4vis = file.path(root_dir, paste0("markers_vis4",clusterx,collapse = ""))
          if ( file.exists( path4vis ) ){
              output_dir = path4vis
          }else{
              output_dir = path4vis
              dir.create(output_dir, recursive = TRUE)
          }
          split <- SplitObject(data_ob,split.by=splitby)
          if( length(levels(data_ob@meta.data[,splitby])) == length(unique(data_ob@meta.data[,splitby])) ) {
          order=levels(data_ob@meta.data[,splitby]) 
          }else{
          order=sort(unique(data_ob@meta.data[,splitby])) 
          }
        
for (i in topn_markers2vis) {
    suppressMessages({
        gene_range <- range(FetchData(object = data_ob, vars = i))
        min.cutoff <- gene_range[1]
        max.cutoff <- gene_range[2]
        ggfeature = lapply(order,
                           function(x) {
                               p = FeaturePlot(split[[x]],
                                              features = i,
                                              reduction = reduct,
                                              max.cutoff = max.cutoff,
                                              #ncol = 2,
                                              pt.size = pointsize,
                                              order = TRUE) +
                                   theme(plot.title = element_text(hjust = 0.5)) +
                                   labs(title = x)+ scale_x_continuous(limits = c(x_min, x_max)) + scale_y_continuous(limits = c(y_min, y_max)) 

                               # 检查是否所有细胞的表达量相同
                               if (gene_range[1] == gene_range[2]) {
                                   # 如果是，使用固定颜色
                                   p = p + ggplot2::scale_color_gradientn(
                                       colours = continious_colors[1],
                                       limit = c(min.cutoff, max.cutoff))
                               } else {
                                   # 如果不是，正常应用颜色梯度
                                   p = p + ggplot2::scale_color_gradientn(
                                       colours = continious_colors,
                                       limit = c(min.cutoff, max.cutoff)
                                   )
                               }  
                           })
        ggfeature <- lapply(ggfeature, function(x) x)
        plot <- do.call(ggpubr::ggarrange,
                        c(ggfeature,
                          list(ncol = 2,
                               nrow = ceiling(length(ggfeature) / 2),
                               common.legend = TRUE,
                               legend = "right",
                               align = "none")))

        g = plot + labs(title = i) +
            theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 20),
                plot.margin = margin(t = 10, r = 10, b = 10, l = 10))

    }) 
    nrow = ceiling(length(ggfeature) / 2)
    ggplot2::ggsave(file.path(output_dir, paste0(i, "_", reduct,
                                        ifelse(is.null(splitby), "", paste0("_splitby_", splitby)),
                                        ".pdf", collapse = "")),
           plot = g, width = ifelse(length(ggfeature) == 1, 5, 10), height = nrow * 5,
           limitsize = FALSE, bg = "white")

    ggplot2::ggsave(file.path(output_dir, paste0(i, "_", reduct,
                                        ifelse(is.null(splitby), "", paste0("_splitby_", splitby)),
                                        ".png", collapse = "")),
           plot = g, width = ifelse(length(ggfeature) == 1, 5, 10), height = nrow * 5,
           limitsize = FALSE, dpi = 1000, bg = "white")
        }
        }
    }

  if ( vismethod == "boxplot" ){
    # Draws a violin plot of single cell data (gene expression, metrics, PC scores, etc.)
    for ( clusterx in unique(topn_markers$folder_suffix) ){
      topn = topn_markers %>%
        dplyr::filter( folder_suffix == clusterx) %>%
        dplyr::select(cluster,gene,folder_suffix)
      topn_markers2vis = as.vector(topn$gene)

      path4vis = file.path(root_dir,paste0("markers_vis4",clusterx,collapse = ""))
      if ( file.exists( path4vis ) ){
          output_dir = path4vis
      }else{
          output_dir = path4vis
          dir.create(output_dir, recursive = T)
      }
      # my_comparisons = sort(unique((data_ob@meta.data[,groupby])))
      # comp=list()
      # for(a in 1:(length(my_comparisons)-1)){
      #   for(b in 1:(length(my_comparisons)-a)){
      #   list=c(as.character(my_comparisons[a]),as.character(my_comparisons[a+b]))
      #   comp=c(comp,list(list))
      #   }
      # }
      for (gene in topn_markers2vis) {
          value <- data_ob@assays$RNA@data[gene, ]
          value_data <- as.data.frame(value)
          data_ob@meta.data[, gene] = value_data$value
          # for (i in value_data$value) {
          #     subset_ob <- subset(value_data, value == i)
          #     data_ob@meta.data[rownames(subset_ob), gene] <- i
          # }
      }
      metadata <- data_ob@meta.data
      metadata <- metadata[, c(groupby, topn_markers2vis)]
      for(geneset in topn_markers2vis){
        gene=metadata[,geneset]
        if ( !is.null(opt$pvalue) & length(comp) != 0 ){
        suppressPackageStartupMessages( library("ggsignif") )
        box <- ggplot(metadata, aes_string(x = groupby, y = gene, fill = groupby)) +
        geom_boxplot() +
        labs(x = groupby, y = geneset) +
        ggsignif::geom_signif(comparisons = comp ,test = "wilcox.test" ,map_signif_level = T ,step_increase = 0.1) +
        scale_fill_manual(values = discrete_colors) +
        theme(
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.background = element_blank(),
            legend.position = "none",
            axis.line = element_line(color = "black"))

        OESingleCell::save_ggplots(file.path(output_dir,paste0(geneset,"_boxplot_with_pvalue")),
                          plot = box,
                          width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                          height = 5,dpi = 300 ,limitsize = F, bg="white")
        }else{
        box <- ggplot(metadata, aes_string(x = groupby, y = gene, fill = groupby)) +
        geom_boxplot() +
        labs(x = groupby, y = geneset) +
        scale_fill_manual(values = discrete_colors) +
        theme(
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.background = element_blank(),
            legend.position = "none",
            axis.line = element_line(color = "black"))

        OESingleCell::save_ggplots(file.path(output_dir,paste0(geneset,"_boxplot")),
                          plot = box,
                          width = 5 + 0.5*(length(unique(cellmeta[[groupby]]))),
                          height = 5,dpi = 300 ,limitsize = F, bg="white")

        }
      }
    }
  }

  if ( vismethod == "dotplot" ){
    # 对字符串大写并进行缩写
    makeInitials <- function(charVec) {
        make.unique(vapply(strsplit(toupper(charVec), "\\."), 
                     function(x) ifelse(length(x)==1, substr(x, 1, 5), 
                                        ifelse(length(x) > 2, 
                                                paste(c(substr(x[1], 1, 3), substr(x[2:length(x)], 1, 2)),collapse = "."),
                                                paste(substr(x, 1, 3),collapse = "." ))), 
                     vector("character", 1L)))
    }
    if(!is.factor(data_ob@meta.data[,groupby])){data_ob@meta.data[,groupby] = factor(data_ob@meta.data[,groupby] ,levels=sort(unique(data_ob@meta.data[,groupby])))}
    # data_ob = Seurat::SetIdent( data_ob, value = groupby )
    Seurat::Idents(data_ob) = groupby
    group_len = length(unique(data_ob@meta.data[,groupby]))
    topn_markers = topn_markers[! duplicated(topn_markers$gene),]
    markers2vis4dotplot = unique(as.vector(topn_markers$gene))
    # 将基因数据框按照分列转换为列表
    marker_list <- split(topn_markers[,2], topn_markers$folder_suffix)
    ngap = length(marker_list)-1
    if(as.logical(dotsplit) == "TRUE"){
        # 按提供表格的列的顺序排列
        marker_list <- marker_list[unique(topn_markers$folder_suffix)]
        # 如果基因列表名称小于5个字符，就不进行大写和缩写
        names(marker_list) <- ifelse(stringr::str_length(names(marker_list))>5, makeInitials(names(marker_list)), names(marker_list))
        # 如果基因列表只有一个基因，名称改为5个字符防止显示不全
        names(marker_list) <- unlist(lapply(names(marker_list), 
                                                function(x){ if(length(marker_list[[x]])==1){  x = substr(x,1,5) }
                                                    return(x) 
                                                }) )
    } else { marker_list = markers2vis4dotplot }
    if ( as.logical(flip) == "TRUE") {
        if(length(markers2vis4dotplot) > 9){
            direction ="vertical"
            box = "vertical"
        }else{
            direction ="vertical"
            box = "horizontal"
        }
        ggdots = Seurat::DotPlot(object = data_ob,
                    features = marker_list ) + Seurat::RotatedAxis() +
                    guides(color = guide_colorbar(title = "Exp.avg",order = 1), 
                            size = guide_legend(title = "Exp %",order =2)) +
                    ggplot2::coord_flip() + 
                    ggplot2::scale_colour_gradientn(colours = colorRampPalette(continious_colors)(100) ) + 
                    theme( legend.position = "right", # 设置图例位置在底部
                            legend.direction = direction, # 设置图例排列方向为水平
                            legend.box = box, # 设置图例框的方向为水平
                            legend.box.just = "center", # 设置图例框居中显示
                            legend.spacing.x = unit(0.3, "cm"), # 设置图例条目之间的水平间距
                            strip.text = element_text(size = 8, face = "bold") # 设置分面标题字体
                        )
        OESingleCell::save_ggplots(
            file.path(root_dir,"marker_gene_dotplot"),
            plot = ggdots, dpi = 300 ,limitsize = F , 
            height= (length(markers2vis4dotplot)*0.2 + 1.8 + ngap*0.25) ,
            width=(0.25*group_len+2.2+max(nchar(markers2vis4dotplot))/10),
            bg="white")
    }else {
        if(group_len > 9){
            direction ="vertical"
            box = "vertical"
        }else{
            direction ="vertical"
            box = "horizontal"
        }
        ggdots = Seurat::DotPlot(object = data_ob,
                features = marker_list ) + Seurat::RotatedAxis() +
                guides(color = guide_colorbar(title = "Exp.avg",order = 1), 
                        size = guide_legend(title = "Exp %",order = 2)) +
                ggplot2::scale_colour_gradientn(colours = colorRampPalette(continious_colors)(100) ) + 
                 theme( legend.position = "right", # 设置图例位置在底部
                        legend.direction = direction, # 设置图例排列方向为水平
                        legend.box = box, # 设置图例框的方向为水平
                        legend.box.just = "center", # 设置图例框居中显示
                        legend.spacing.x = unit(0.3, "cm"), # 设置图例条目之间的水平间距
                        strip.text = element_text(size = 8, face = "bold") # 设置分面标题字体
                    )
        OESingleCell::save_ggplots(
            file.path(root_dir,"marker_gene_dotplot"),
            plot = ggdots, dpi = 300 ,limitsize = F , 
            height= (group_len*0.2 + 2) ,
            width=(0.25*length(markers2vis4dotplot) + 2.2 + max(nchar(names(table(data_ob@meta.data[,groupby]))))/10 + ngap*0.25),
            bg="white")
    }
  }

  if ( vismethod == "ridgeplot"){
      for ( clusterx in unique(topn_markers$folder_suffix) ){
        topn = topn_markers %>% filter( folder_suffix == clusterx) %>% dplyr::select(cluster,gene,folder_suffix)
        topn_markers2vis = as.vector(topn$gene)

        path4vis = file.path(output_dir,paste0("markers_vis4",clusterx,collapse = ""))
        if ( file.exists( path4vis ) ){
            output_dir = path4vis
        }else{
            output_dir = path4vis
            dir.create(output_dir, recursive = T)
        }
        # data_ob = Seurat::SetIdent( data_ob, value = groupby )
        Seurat::Idents(data_ob) = groupby
        ggridge = Seurat::RidgePlot(object = data_ob,
                                    features = topn_markers2vis,
                                    cols = discrete_colors,
                                    ncol = 1)
        OESingleCell::save_ggplots(
          file.path(output_dir,"marker_gene_ridgeplot"),
          plot = ggridge, dpi = 300 ,limitsize = F, bg="white")
      }
    }
  }
  system(paste0("bash /data/software/conda_envs/scrna_envs/pdf_overlap_checker/script/pdf_overlap_checker.sh ",root_dir))
  quit()
}

# ============== Subcmd: findallmarkers Find All markers for each cell group ===============
if ( "findallmarkers" %in% args ){
  #parse the command line parameters
  pct1_cutoff = opt$min_pct1
  pct2_cutoff = opt$max_pct2
  pct_fold_cutoff = opt$pct_fold
  dftest = opt$test
  topn = opt$topn_marker

 # read the specified assay and data slot in data object into memory
 data_ob = ReadX(input = opt$input,
              informat = opt$informat,
              assays = assays, data.use = dataslots, # "data"
              reductions = FALSE, # only the used reduction results needed
              graphs = FALSE, # no graph object needed here
              verbose = FALSE)

  #get the subset of cells used  if necessay
  if ( !is.null(opt$predicate) ){
    desired_cells= subset(OESingleCell::colData(data_ob), eval( parse(text=opt$predicate)))
    # same for Seurat, SingleCellExperiment, summarizedExperiment
    data_ob = data_ob[,rownames(desired_cells)]
  }


  #in default, the FindAllMarkers() function will use the default identity class
  #In order to select the different clustering result to find markers, change this
  #class value to one of the column in the cell annotation metadata table
  suppressWarnings({
    if ( is.null(opt$cluster_name) ){
      data_ob[["clusters"]] = Seurat::Idents(data_ob)
    }else{
      # data_ob = Seurat::SetIdent( data_ob, value = opt$cluster_name)
      Seurat::Idents(data_ob) = opt$cluster_name
    }
  })
  #find the differential expressed genes for each clusters
  #FindAllMarkers() is primarily used to find markers, but here it was also used
  #to find differentially expressed genes. The default logfc threshold was set to 0.25
  #,here we set to 0 as no prefiltering and then manually filter the genes to find markers
  # note that if test.use is "negbinom", "poisson", or "DESeq2", slot will be set to "counts" automatically
  global_DEGs = Seurat::FindAllMarkers(object = data_ob,
                                       only.pos = T, test.use = dftest,
                                       logfc.threshold = 0, min.pct = 0.25)
  if ("auc" %in% names(global_DEGs) ) global_DEGs = global_DEGs %>% dplyr::select(-auc)
  global_DEGs = global_DEGs %>%
    dplyr::mutate( gene_diff = round(global_DEGs$pct.1 / global_DEGs$pct.2, 3)) %>%
    dplyr::select( gene, everything() )
  global_DEGs1=global_DEGs
  colnames(global_DEGs1)=c("gene","p-value","avg_log2FC","pct.1","pct.2","q-value","cluster","gene_diff")
  write.table(global_DEGs1,file = file.path(output_dir,"all_markers_for_each_cluster.xls"),
            col.names =T,row.names = F,sep = "\t",quote=F)
  #find the significant differential expressed genes for each clusters against all other clustershttp://127.0.0.1:14418/help/library/Venice/html/CreateSignacObject.html
  #feature plot of potential marker gene for each cluster
  #for each gene to be a potential marker,in add to be a significant expressed gene, the gene should account for
  #large proportion in the interested cluster but as small as possiable in the other clusters, that means the pct.1 should
  # be bigger than the pct.2.
  if ( as.logical(opt$strict) == T ){
    if ( !is.null(opt$pvalue) ){
      topn_markers  = global_DEGs %>%
        dplyr::group_by(cluster) %>%
        dplyr::filter(avg_log2FC>=opt$avg_log2FC & p_val < opt$pvalue & pct.1 > pct1_cutoff & pct.2 < pct2_cutoff & gene_diff > pct_fold_cutoff)  %>%
        dplyr::arrange(p_val,desc(avg_log2FC),desc(gene_diff)) %>%
        dplyr::filter(gene_diff > pct_fold_cutoff)  %>%
        dplyr::top_n(topn,gene_diff)
    }else{
      topn_markers  = global_DEGs %>%
        dplyr::group_by(cluster) %>%
        dplyr::filter(avg_log2FC>=opt$avg_log2FC & p_val_adj < opt$FDR & pct.1 > pct1_cutoff & pct.2 < pct2_cutoff & gene_diff > pct_fold_cutoff)  %>%
        dplyr::arrange(p_val,desc(avg_log2FC),desc(gene_diff)) %>%
        dplyr::filter(gene_diff > pct_fold_cutoff)  %>%
        dplyr::top_n(topn,gene_diff)
    }
  }else{
    topn_markers  = global_DEGs %>% dplyr::group_by(cluster) %>%
      #filter(p_val < opt$pvalue ) %>%
      dplyr::arrange(p_val,desc(avg_log2FC),desc(gene_diff)) %>%
      # filter(gene_diff > pct_fold_cutoff)  %>%
      dplyr::top_n(topn,gene_diff)
  }
  topn_markers1=topn_markers
  colnames(topn_markers1)=c("gene","p-value","avg_log2FC","pct.1","pct.2","q-value","cluster","gene_diff")
  write.table(topn_markers1,file = file.path(output_dir,paste0("top", topn, "_markers_for_each_cluster.xls", collapse = "")),
              col.names =T,row.names = F,sep = "\t",quote=F)
  quit()
}

# ===================== Subcmd: subset the data object using condditional expression on cells =======
if ( "subset" %in% args ){ # subset the object using different conditions
    data_ob = ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots)
    group2use = opt$group2use
    levels = opt$levels
    data_obx = data_ob
    if ( is.null(opt$low) | opt$low == "NULL" ){
        opt$low = -Inf
    }
    if ( is.null(opt$high) | opt$high == "NULL" ){
        opt$high = Inf
    }
    if ( !is.null(levels)){
        levels_id = unlist(strsplit( levels,",",perl = T))
        if ( is.null(group2use) ){ group2use = "idents" }
        if ( group2use == "idents" ){
            if ( typeof(Idents(data_obx)) == "integer" ){ # the idents is clustering id
                data_obx = SubsetData(data_obx, ident.use = levels_id,
                                low.threshold = opt$low, high.threshold = opt$high)
            }
        } else{ #subset cells on metadata using other cell annotations
            data_obx = SubsetData(data_obx, subset.name = group2use,
                                   accept.value = levels_id,
                                   low.threshold = opt$low, high.threshold = opt$high
                      )
        }
        desired_cells = FetchData(data_obx, vars = rownames(data_obx)) %>% as.data.frame
    }else{
        desired_cells = FetchData(data_obx, vars = rownames(data_obx)) %>% as.data.frame
    }
    # subset cells on the expression matrix using logical exprssion on features
    if ( !is.null(opt$predicate) ){
        # levels = gsub( ".*\\((.*)\\)", "\\1", opt$cellfilter, perl =T)
        # predicate = gsub( "\\(.*\\)", glue::glue("({levels})"), opt$cellfilter, perl = T)

        df = OESingleCell::colData(data_obx)
        desired_cells= subset(df, eval( parse(text=opt$predicate)))
        data_obx = data_obx[, rownames(desired_cells) ]
    }

    if ( !is.null(opt$feature4subset) ){
        feature_predicate = opt$feature4subset
        count_df_T = Matrix::t(GetAssayData(data_obx, assay = opt$assay, slot = opt$slot))
        desired_cells = subset( as.data.frame(count_df_T), eval(expr = parse(text=feature_predicate)))
        data_obx = data_obx[, rownames(desired_cells)]
    }

    desired_cell_id = colnames(data_obx)

    # keep only specified features
    if ( !is.null( opt$geneset) ){
        genes = read.table(opt$geneset, sep = "\t", header = T)
        desired_features = as.vector( genes$gene)
    }else{
        desired_features = NULL
    }

    to_invert = opt$invert
    data_ob = subset(data_ob, features = desired_features,
                        cells = desired_cell_id, invert = to_invert)
    saveObject(data_ob, outdir = output_dir, splitby = opt$seperateby,
                outformat = opt$outformat, prefix = opt$prefix)
    quit()
}

# subcommand merge is invoked
if ( "merge" %in% args ){
  seuy = lapply(strsplit(opt$toadd, ","), function(seu){
      seux = readObject( input = seu, assay = opt$assay, informat = opt$adformat)
      if ( seux@version < 3 ){
          seux = UpdateSeuratObject(seux)
      }
  })
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)
  data_ob = merge( data_ob, y = seuy, merge.data = T)
  saveObject(data_ob, outdir = output_dir, splitby = opt$seperateby,
          outformat = opt$outformat, prefix = opt$prefix)
  quit()
}


# =============== Subcmd: updata the metedata of cells or features in the data_ob ============
if ( "update" %in% args ){
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)
  if ( !is.null(opt$admeta) ){
      cellnames = colnames(data_ob)
      additional_metadata = read.csv(opt$admeta,sep=",",header =T, row.names=1)
      if ( opt$annlevel == "sample" ){
          #the index order is the same as the row index of the assay metadata
          sampleidx =  gsub("(_|-)[ATGC]{16,}.*","",cellnames,perl=T)
          #integrate the additional metadata from the assay design
          additional_cell_meta = vector()
          for ( colidx in colnames(additional_metadata) ){
              additional_cell_meta = cbind(additional_cell_meta,
              as.vector(additional_metadata[sampleidx, colidx]))
          }
          colnames(additional_cell_meta) = colnames(additional_metadata)
          rownames(additional_cell_meta) = cellnames
          additional_cell_meta = as.data.frame(additional_cell_meta)
          data_ob = AddMetaData( data_ob, additional_cell_meta)
      }else{# the annotation level is cell, make sure the barcodes are in the same pattern as the ones in the object
          additional_cell_meta = as.data.frame(additional_metadata)
          # TO DO if the cells in the supplied annotation is different from the cells in seurat object
          data_ob = AddMetaData( data_ob, metadata = additional_metadata)
      }
  }

  cellmeta = OESingleCell::colData(data_ob)
  if ( !is.null(opt$recode) ){
    # the format should be as follows:
    # seurat_clusters
    # 0:Naive CD4 T
    # 1:Memory CD4 T
    # 2:CD14+ Mono
    # 3:B
    # 4:CD8 T

    recode_df = read.table(opt$recode, header = T, sep = "\t")
    recode_id = colnames(recode_df)[1]
    from_to = recode_df %>% tidyr::separate(1, c("from", "to"), sep = ":") %>% tibble::deframe()
    new_meta = dplyr::recode(as.vector(cellmeta[[recode_id]]), !!!from_to )
    data_ob = OESingleCell::AddMetaData(data_ob, metadata = new_meta, col.name = recode_id )
  }

  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob, verbose = FALSE )
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }

  quit()
}

if ( "split" %in% args ){
    data_ob = ReadX(input = opt$input, informat = opt$informat ) # all assay must be loaded

    if ( !is.null( opt$splitby) ){
        seurat_list = OESingleCell::SplitObject( data_ob, split.by = opt$splitby )
        lapply( names(seurat_list), function(x){
           SeuratDisk::SaveH5Seurat(seurat_list[[x]], filename = file.path(output_dir, glue::glue("{x}.rds")),overwrite = T )
        })
    }
    quit()
}

if ( "findneighbors" %in% args ){
  if (! is.null(opt$features)){
    if (! file.exists(opt$features)){
      stop((paste('Supplied genes file', opt$features, 'does not exist')))
    }else{
      features <- readLines(opt$features)
    }
  }

  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)

  data_ob <- Seurat::FindNeighbors(data_ob,
               k.param = opt$k_param,
               nn.method = opt$nn_method,
               annoy.metric = opt$dist_metric,
               nn.eps = opt$nn_eps,
               verbose = FALSE,
               force.recalc = opt$force_recalc,
               features = features,
               reduction = opt$reduction,
               dims = dims,
               assay = opt$assay,
               graph.name = opt$graph_name )
  OESingleCell::SaveX(data_ob, outformat = opt$outformat,output = opt$input, update = T, graphs = data_ob@graphs)

  quit()
}

if ( "metacell" %in% args ){
    data_ob = ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots)
    if ( !is.null( opt$features) ){
        genes = read.table(opt$features, sep = "\t", header = T)
        desired_features = as.vector( genes$gene)
    }else{
        desired_features = NULL
    }
    if ( !is.null(opt$avgby) ){
        avgby = opt$avgby
    }else{
        avgby = "clusters"
    }
    # data_ob = SetIdent( data_ob, value = avgby)
    Seurat::Idents(data_ob) = avgby
    avg_mtx = Seurat::AverageExpression(data_ob, assays = opt$assay, features = desired_features, slot = opt$slot)
    write.table(avg_mtx, file.path(output_dir,paste0("average_expression_matrix_by_",avgby,".xls")),
                sep = "\t", col.names = T,row.names = T)
    # output metadata either
}

if ( "rmambients" %in% args ){
    data_ob = ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots)

    # remove the empty droplets using dropletuitls if necessary
    emptyRemoved = RemoveEmptyDrops(
                  fdrThreshold=as.numeric(opt$fdr),
                  emptyDropNIters= as.numeric(opt$iters),
                  raw_count = GetAssayData(data_ob, slot = "counts") )
    subset_se = data_ob[, colnames(emptyRemoved)]
    # TO DO
    # make a UMI rank plot
    OESingleCell::SaveX(data_ob, output = opt$input, assay = assays[1],
                        outformat = opt$outformat,
                        update = F)
    quit()
}

# =============== Subcmd: normalize, normalize the data ============
if ( "normalize" %in% args ){
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots, # counts only
                    verbose =F )
  if ( !is.null(opt$vars2regress) ){
    vars2regress = unlist(strsplit(opt$vars2regress, ",", perl =T))
  }else{
    vars2regress = NULL
  }

  if ( tolower(opt$nmethod) == "sct" ){
    data_ob = Seurat::SCTransform(data_ob, method = "glmGamPoi",
                                  vars.to.regress = vars2regress,
                                  verbose = FALSE,return.only.var.genes = FALSE)
    SeuratDisk::UpdateH5Seurat(file = opt$input, data_ob, assay = "SCT", verbose = F)
    # OESingleCell::SaveX(data_ob, output = opt$input, assay = "SCT",
    #                   outformat = opt$outformat, update = T)
  }else{
    data_ob <- Seurat::NormalizeData(data_ob, normalization.method = opt$nmethod,
                             scale.factor = opt$scale_factor, margin = opt$margin,
                             block.size = opt$block_size, verbose = FALSE)
    OESingleCell::SaveX(data_ob, output = opt$input, assay = assays[1],
                      outformat = opt$outformat, update = T)
  }
  quit()
}

# =============== Subcmd: convert, change the data object to target format ============
if ( "convert" %in% args ){
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)
  data_obx = ConvertX(data_ob, from = "", to = "")
  OESingleCell::SaveX(data_obx, output = opt$input, assay = assays[1],
                      outformat = opt$outformat,
                      update = F)
}

# Retreives data (feature expression, PCA scores, metrics, etc.) for a set of cells in a Seurat object
# =============== Subcmd: fetch, extract desired cell annotation ============
if ( "fetch" %in% args ){ # subcommand fetch is invoked
    if ( !is.null(opt$vars) ){
        var_list = unlist( strsplit(opt$vars, ",", perl = T) )
    }else{
        var_list = c("group", "ident")
    }
    data_ob = ReadX(input = opt$input, informat = opt$informat,
                    assays = assays, data.use = dataslots)

    desired_df = OESingleCell::FetchData(data_ob, slot = dataslots[1], vars = var_list )
    desired_df$cellbarcode = rownames(desired_df)
    if ( !is.null(opt$header) ){
        colnames(desired_df) = unlist( strsplit(opt$header, ",", perl = T) )
    }
    write.table(desired_df, file.path(output_dir,
                glue::glue("{opt$prefix}_cellinfo.xls")),
                row.names = F,col.names = T, sep = "\t")
    quit()
}


# =============== Subcmd: downsample, subset cells randomly while keep heterogencity ============
if ( "downsample" %in% args ){  #### TO DO
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots)

  data_ob = DownSample(data_ob, N = opt$targetN, slot = dataslots[1], PCs = opt$usePCA, verbose = F)

  output = file.path(output_dir, glue::glue("downsampled.{outformat}"))
  OESingleCell::SaveX(data_ob, output = output, outformat = opt$outformat, update = F)

  quit()
}

# =============== Subcmd: diffexp, find the differential expressed genes ============
if ( "diffexp" %in% args ){
  #parse the design
  if ( is.null( opt$design ) ){
      warning("NO assay design is PROVIDED\n")
  }else{
      design = opt$design
  }

  if ( is.null(opt$pvalue) && is.null(opt$fdr) ){
      stop("None of P-value or FDR is AVAILABLE! Filtering can be performed using any one of (-p), (-f) at one time.", call.=FALSE)
  }else if ( !is.null(opt$fdr)){
      fdr = as.numeric(opt$fdr)
      pvalue = NULL
  }else{
      pvalue = as.numeric(opt$pvalue)
      fdr = NULL
  }

 # read the specified assay and data slot in data object into memory
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots, verbose = F)
  message("Loading Data object Finished!")

  #check the metadata of the assay design,which describe the expriement groupping of each
  #sample in the assay
  if ( !is.null( opt$addition_metadata)  ){ #the additional metadata for each sample
      add_assay_metadata = read.table(opt$addition_metadata,sep=",",header =T )
      # cellnames = data_ob@cell.names
      cellnames = colnames(data_ob) #seurat v3 style
      sampleidx =  gsub("_.*","",cellnames,perl=T) #the index order is the same as the row index of the assay metadata
      #integrate the additional metadata from the assay design
      additional_cell_meta = vector( )
      for ( colidx in colnames(add_assay_metadata) ){
          additional_cell_meta = cbind(additional_cell_meta, as.vector(add_assay_metadata[sampleidx, colidx]))
      }
      colnames(additional_cell_meta) = colnames(assay_metadata)
      rownames(additional_cell_meta) = cellnames
      additional_cell_meta = as.data.frame(additional_cell_meta)
      data_ob = AddMetaData( data_ob, additional_cell_meta )

      # assay_metadata = data_ob@meta.data
      assay_metadata = OESingleCell::colData(data_ob)
  }else{
      assay_metadata = OESingleCell::colData(data_ob)
  }

  # subset cells on the expression matrix using logical exprssion on features
  if ( !is.null(opt$predicate) ){
      desired_cells= subset(assay_metadata, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }


  #parse the contrast for this assay
  #if the constrast is not specified by the user explicitly from the command line,
  #the final differential result will use last level of the last variable in the
  #design formula over the first level of this variable. The levels for each
  #factor is aphabetly ordered by default,which can be reordered by the user.
  #if available,the contrast string from the user must obey the right format:
  #the_interested_factor:the_interested_levels_in_this_factor:the_reference_level_in_this_factor
  if ( is.null(opt$contrast ) ){ #no contrast is provided
      factors_indesign = strsplit(opt$design,"[~+ ]+",perl = T)
      last_factor_indesign = factors_indesign[length(factors_indesign)]
      if ( is.null(assay_metadata[,last_factor_indesign]) ){
          stop("The factor in design formula does not exist in assay metadata.")
      }
      variable_levels = levels(assay_metadata[,last_factor_indesign])
      contrast = paste( last_factor_indesign,variable_levels[length(variable_levels)],variable_levels[1],sep = ":" )
  }else{
      contrast = opt$contrast
  }
  contrasts = unlist( strsplit(contrast,":",perl = T) )
  all_levels = as.vector(unique(assay_metadata[,contrasts[1]]))
  if ( contrasts[2] == "all" & contrasts[3] != "all" ){
      all_levels = all_levels[-which(all_levels==contrasts[3])] #delete the reference level
      all_comparisions = paste(contrasts[1],all_levels,contrasts[3],sep = ":")
  }else if( contrasts[2] == "all" & contrasts[3] == "all" ){

      # combine_of2 = combn(all_levels,2) #random combination of two group
      # all_comparisions = c( paste(contrasts[1],combine_of2[2,],combine_of2[1,],sep = ":"),
      #                       paste(contrasts[1],combine_of2[1,],combine_of2[2,],sep = ":"))
      all_comparisions = lapply(all_levels,
                      function(x) paste(contrasts[1],x,paste0(all_levels[-which(all_levels==x)],collapse = ","),sep = ":"))
      all_comparisions = unlist(all_comparisions)
  }else if ( contrasts[2] != "all" & contrasts[3] == "all" ){
      #delete the interested level in the  reference level
      ref_levels = paste0(all_levels[-which(all_levels==contrasts[2])],collapse = ",")
      all_comparisions = paste(contrasts[1],contrasts[2],ref_levels,sep = ":")
  }else{
      all_comparisions = contrast
  }

  # Differential expression analysidataslotss
  #parse the contrast string to a list for later use
  future.apply::future_lapply( all_comparisions, function( contrast){
      RunDiffexp( object = data_ob,
              test = opt$test,fdr = fdr,
              fc.thres = opt$FC,
              pval.thres = pvalue,
              contrast = contrast,
              outputdir = output_dir)
  }, future.seed = 2020)

  quit()
}

# =============== Subcmd: write10x, save the count matrix in mtx/h5 format ============
if ( "write10x" %in% args ){
  # read the specified assay and data slot in data object into memory
  # only counts dataslot needed here
  is.overwrite = as.logical(opt$overwrite)
  is.h5 = as.logical(opt$h5)

  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots, verbose = F)
  message("Loading Data object Finished!")
  if ( is.h5 ){
  }else{
    Write10X(data_ob, assay = assays,
             split.by = opt$split.by,
             version = opt$version,
             path = output_dir,
             overwrite = is.overwrite)
  }
  quit()
}

# =============== Subcmd: findhvg, find the variable features ============
if ( "findhvg" %in% args ){
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots,  # counts is enough
                  verbose = F)

  if ( opt$select_method %in% c("vst", "dispsersion", "mean.var.plot") ){
    data_ob = OESingleCell::FindVariableFeatures(
      data_ob,
      assay = assays[1],
      selection.method = opt$select_method,
      loess.span = opt$loess_span,
      nfeatures = opt$nfeature,
      verbose = F)
  }else if ( opt$select_method %in% c("markvariogram", "moransi") ) {
      data_list = OESingleCell::SplitObject(data_ob,split.by="sampleid")
      spatial_DEGs_list = future.apply::future_lapply(1:length(data_list), function(sidx) {
        datax = Seurat::FindSpatiallyVariableFeatures(data_list[[sidx]] ,
                                            assay = assays[1],
                                            slot = "scale.data",
                                            image = Seurat::Images(data_list[[sidx]])[sidx],
                                            selection.method = opt$select_method,
                                            r.metric = 5,
                                            nfeatures = opt$nfeature,
                                            verbose = TRUE)
        spatial_DEGs = Seurat::SpatiallyVariableFeatures(datax, selection.method = tolower(opt$select_method) )
      })
      names(spatial_DEGs_list) = names(data_list)
      global_DEGs = stack(spatial_DEGs_list) %>% rename( gene = values, slice = ind)
      write.table(global_DEGs,
                  file = file.path(output_dir,paste0("top", nfeatures, "_for_all_spots.xls", collapse = "")),
                  col.names =T,row.names = F,sep = "\t",quote = FALSE)
  }

  if ( tolower(opt$outformat) == "h5seurat" ){
    hfile =  SeuratDisk::h5Seurat$new(filename = opt$input, mode = 'r+')
    on.exit(expr = hfile$close_all())
    assay_group = hfile[[glue::glue("assays/{assays[1]}")]]
    # Write out variable features
    assay_group$link_delete("variable.features")
    SeuratDisk::WriteH5Group( OESingleCell::VariableFeatures(data_ob),
                              name = 'variable.features',
                              hgroup = assay_group,
                              verbose = F)
    # Write out meta.features
    # attrs = hdf5r::h5attr_names(assay_group[["meta.features"]])
    # if ( length(attrs) ){
    #   sapply(attrs, function(x) assay_group[["meta.features"]]$attr_delete(x) )
    # }
    # assay_group$link_delete("meta.features")
    # assayx = Seurat::GetAssay( data_ob, assay = assays[1] )
    # print("XXXX")
    # currently I can not fix the error yet:
    # Can't create dataset _index - already exists!
    # SeuratDisk::WriteH5Group( assayx[[]], name = 'meta.features',
    #                           hgroup = assay_group,
    #                           verbose = F )
  }else{
    OESingleCell::SaveX(data_ob, output = opt$input, outformat = opt$outformat)
  }
  quit()
}

# =============== Subcmd: scale, scale data and regress out variance ============
if ( "scale" %in% args ){
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays,
                  data.use = dataslots,  # counts is enough
                  verbose = F)
  data_ob = Seurat::ScaleData(data_ob,
                          assay = assays[1],
                          vars.to.regress = unlist(strsplit(opt$vars2regress, ",", perl = T)),
                          split.by = NULL,
                          model.use = opt$model,
                          use.umi = as.logical(opt$use_umi),
                          scale.max = 10,
                          block.size = opt$block_size,
                          min.cells.to.block = 3000,
                          verbose = TRUE )
  OESingleCell::SaveX(data_ob, output = otp$input, assay = assays[1],
                      outformat = opt$outformat, update = T)

  quit()
}


# =============== Subcmd: score, gene module score calculation =========
if ( "score" %in% args ){
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays,
                  data.use = dataslots,  # data slot is enough
                  verbose = F)

  # gmt = GSEABase::getGmt(con=opt$gset)
  gset_list = GSEABase::geneIds(GSEABase::getGmt(con=opt$gmt))
  # filter gene sets
  gset_list = gset_list[lengths(gset_list)> opt$min.size]
  data_ob = Seurat::AddModuleScore(data_ob, features = gset_list, name = "module")

  cellmeta = OESingleCell::colData(data_ob)
  cellmeta = cellmeta %>%
              dplyr::rename_at(dplyr::vars(dplyr::starts_with("module")), ~ names(gset_list))
  gset_score = cellmeta %>%
                tibble::rownames_to_column(var = "barcode") %>%
                dplyr::select( barcode, names(gset_list) )
  write.table(gset_score, file = file.path(output_dir, "gene_module_scores.xls"), sep = "\t", row.names = F)

  if ( !is.null(opt$plot) ){
    vismethods = unlist(strsplit(opt$plot,","))
    # violin plot or featureplot for each gene module in specified group
    ccolors = unlist(strsplit(opt$ccolors,","))
    if ( length(ccolors) == 1 ){ # this means to use customized discrete color schema in OESingleCell package
        info = glue::glue("the customized continious colors are: \n {paste(names(continious_palette), lengths(continious_palette), sep =': ', collapse = '\n')}.")
        warning("NO specified color schema found!")
        warning(info)
        stop()
      continious_colors = continious_colors[[ccolors]]
    }else{ # this means to use the customized color schema from command line specified by user
      continious_colors = ccolors
    }

    switch(vismethods,
          "featureplot" = {
            suppressMessages({
              data_feature <- FetchData(data_ob,vars = c(paste0(Key(data_ob[[reduct]]), c(1,2)), 'ident', names(gset_list)),cells = Seurat::Cells(data_ob[[reduct]]),slot = 'data')
              plot_features <- setdiff(x = names(x = data_feature), y = c(paste0(Key(data_ob[[reduct]]), c(1,2)), 'ident'))
              max.cutoff <- mapply(FUN = function(cutoff, feature) {return(cutoff)},cutoff = 'q99',feature = plot_features)
              names(x = max.cutoff) <- plot_features
              for (i in seq_along(along.with = plot_features)) {
                f <- plot_features[i]
                data.feature <- data_feature[[f]]
                max.use <- Seurat:::SetQuantile(cutoff = max.cutoff[f], data = data.feature)
                data.feature[data.feature > max.use] <- max.use
                data_feature[[f]] <- data.feature
              }
              ggmodules = Seurat::FeaturePlot(data_ob,reduction= opt$reduct,
                              features = names(gset_list), split.by = opt$splitby,
                              keep.scale = "all",
                              max.cutoff = 'q99',
                              order = T,
                              pt.size = opt$pointsize) &
                          ggplot2::scale_color_gradientn(colours = continious_colors,limit = c(0,max(data_feature[,plot_features]))) &
                          ggplot2::theme(legend.position = "none",
                             legend.margin = ggplot2::margin(0,0.5,0,0, unit = "cm"),
                             plot.margin = ggplot2::margin(0, 0, 0, 0.1, unit = "cm"),
                             plot.title = ggplot2::element_text(hjust = 0.5) ) })
          ggm = ggpubr::ggarrange(ggmodules,common.legend = T, legend = "right")
          OESingleCell::save_ggplots(
              file.path(output_dir, "gene_module_featureplot"),
              width =  4*ifelse(is.null(splitby),yes = 2, no =length(unique(cellmeta[[splitby]]))),
              height = 3*ifelse(is.null(splitby),
                                yes = ceiling(length(topn_markers2vis)/2),
                                no  = length(topn_markers2vis)),
              plot = ggm, dpi = 300 ,limitsize = F,bg="white" )
           },
          "vlnplot" = {
            gs = lapply(topn_markers2vis, function(x)
                        Seurat::VlnPlot(data_ob, features = x,
                                      cols = discrete_colors[1:length(unique(cellmeta[[groupby]]))],
                                      pt.size = opt$pointsize, alpha = opt$alpha2use,
                                      group.by = groupby,
                                      split.by = splitby,
                                      split.plot = as.logical(opt$dodge) )+
                        labs(title = "",y = x, x=NULL) +
                        ggplot2::theme( legend.position="none",
                          legend.margin = ggplot2::margin(0,1,0,0, unit = "cm"),
                          plot.margin = ggplot2::margin(0.1, 0, 0, 0.1, unit = "cm"),
                            # unit(c(-0.1,2,-0.1,0.1), "null"),
                          # panel.spacing.x = unit(0.1,"null"),
                          axis.text = ggplot2::element_text(margin = unit(0,"null")),
                          axis.title.x = ggplot2::element_text(size = 0),
                          axis.title.y = ggplot2::element_text(size = 12),
                          axis.text.x = ggplot2::element_text(size = 10, angle = 30),
                          axis.text.y=ggplot2::element_text(size = 8)))
                # gga = gridExtra::grid.arrange(grobs = gs, ncol=1, padding = unit(0, "line") )
                ggb = do.call(ggpubr::ggarrange,
                              c(gs,list( ncol = 1, align = "v", common.legend = TRUE, legend = "right")))
                OESingleCell::save_ggplots(plot = ggb,
                                 file.path(output_dir,"gene_module_violin_plot"),
                                 width = length(unique(cellmeta[[groupby]])),
                                 height = length(topn_markers2vis)*2, bg="white")

          }
          )
  }
}


# =============== Subcmd: summarize, summarizing and visualizing the clustering analysis results =========
if ( "summarize" %in% args ){
  library(gridExtra)
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, reduction = opt$reduct, data.use = dataslots,  # data slot is enough
                  verbose = F)
  if ( is.null(opt$pointsize) ){
      if (dim(data_ob)[2] < 500){
          pointsize = 1.5
      } else pointsize = 0.5
  } else {
      pointsize = opt$pointsize
  }
  
  if (!is.null(opt$predicate)) {
    df = OESingleCell::colData(data_ob)
    desired_cells = subset(df, eval(parse(text = opt$predicate)))
    data_ob = data_ob[, rownames(desired_cells)]
    data_ob@meta.data$sampleid <- droplevels(data_ob@meta.data$sampleid)
    data_ob@meta.data$group <- droplevels(data_ob@meta.data$group)
  }

  groupfactors = unlist(strsplit(opt$groupby, ",", perl = T))
  #color_schema = SelectColors(palette = opt$palette)
  #color_schemas = SelectColors(palette = 'customecol2')[11:50]  # 固定sampleid和group的分组颜色
  for (groupfactor in groupfactors ){
    output_dir = file.path(output_dir, paste0( "visualize_cluster_by_", groupfactor, collapse = ""))
    if ( !file.exists(output_dir) ){
      dir.create(output_dir, recursive = T)
    }
    color_counter = 0
    nlevel = length(unique(OESingleCell::colData(data_ob)[[groupfactor]]))
    if ( !is.null(opt$facetby) ){
      for ( facetbyx in unlist( strsplit( opt$facetby, "," ) )){
         if ( !is.null(facetbyx) ){
             nrow = ceiling(length(unique(OESingleCell::colData(data_ob)[[facetbyx]]))/2)
             ncol = 2
             if (as.character(nrow) == "1") {
             higher_ob = 5
             #} else if (as.character(nrow) == "2"| as.character(nrow) == "3") {
             #higher_ob = 4
             } else {
             higher_ob = 3 
             }
         }
         #nlevel = length(unique(OESingleCell::colData(data_ob)[[groupfactor]]))
         color_counter = nlevel
         #data_ob = Seurat::SetIdent( data_ob, value = groupfactor)
         if ( ! as.logical(opt$use_color_anno )){
             data_ob@meta.data = data_ob@meta.data[ ,!grepl(paste0("^",groupfactor,"_col$" ), colnames(data_ob@meta.data))]
             data_ob@meta.data = data_ob@meta.data[ ,!grepl(paste0("^",facetbyx,"_col$" ), colnames(data_ob@meta.data))]
         }
         if ( !is.null(opt$color_file)){
             color_file = read.delim(opt$color_file, sep="\t", header = T)
             meta_anno = color_anno(data_ob@meta.data, color_file)
         } else {
             meta_anno = data_ob@meta.data
        }
         color_use = get_colors(meta_anno, groupfactor, opt$palette)
         user_color_pal = color_use[["new_celltype_pal"]]
         user_color_pal = na.omit(user_color_pal)
         color_use = user_color_pal
         groupvis_split = Seurat::DimPlot(object = data_ob,
                          dims = c(1,2),reduction = opt$reduct,
                          pt.size = as.numeric(pointsize), ncol = 2,
                          order = names(color_use),
                          group.by = groupfactor, split.by = facetbyx)+
             ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5))
         groupvis_split = groupvis_split + theme(aspect.ratio = 1/1)+
                          ggplot2::scale_colour_manual( values = color_use,
                                               breaks = names(color_use),
                                               labels = names(color_use) )

         OESingleCell::save_ggplots(file.path(output_dir,paste0("splitby-",facetbyx,"_split_plot",collapse="")),
                                    limitsize = FALSE, plot = groupvis_split, width = 10, height = higher_ob*nrow, bg="white" )


         nfacet = length(unique(OESingleCell::colData(data_ob)[[facetbyx]]))
         color_use1 = get_colors(meta_anno, facetbyx, opt$palette)
         user_color_pal1 = color_use1[["new_celltype_pal"]]
         user_color_pal1 = na.omit(user_color_pal1)
         color_use1 = user_color_pal1
         groupvis_all = Seurat::DimPlot(object = data_ob, dims = c(1,2),
                                        reduction = opt$reduct,
                                        pt.size = as.numeric(pointsize),
                                        group.by = facetbyx)+
                         ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5)) + theme(aspect.ratio = 1/1)+
                         ggplot2::scale_colour_manual( values = color_use1)
         OESingleCell::save_ggplots(file.path(output_dir,paste0("groupby-",facetbyx, "_contrast_plot",collapse="")),
                                    limitsize = FALSE, plot = groupvis_all, width = 7, height = 7, bg="white" )
         color_counter = color_counter + nfacet

#### density plot
         groupby_df = subset(data_ob@meta.data, select = facetbyx)
         colnames(groupby_df) = "facetbyx"
         plot_data = Seurat::Embeddings(data_ob, reduction = opt$reduct)
         plot_data = cbind(plot_data, groupby_df)
         xx=(max(plot_data[,1])-min(plot_data[,1]))/10
         yy=(max(plot_data[,2])-min(plot_data[,2]))/10
         xlim = c(floor(min(plot_data[,1])-xx), ceiling(max(plot_data[,1])+xx))
         ylim = c(floor(min(plot_data[,2])-yy), ceiling(max(plot_data[,2])+yy))
         # ptsize = abs(xlim[2]-xlim[1])/nrow(plot_data)*50
         ptsize = abs(xlim[2]-xlim[1])*abs(ylim[2]-ylim[1])*0.4/nrow(plot_data)
         if(is.factor(plot_data$facetbyx)){
            ipt = levels(plot_data$facetbyx)
         }else{
            ipt = unique(plot_data$facetbyx)
         }
         density_split = lapply(ipt, function(x) ggplot() + 
                                                                        stat_density_2d(geom="raster",contour = F,
                                                                                        data = subset(plot_data,facetbyx == x), alpha=1, 
                                                                                        aes_string(x = colnames(plot_data)[1], y = colnames(plot_data)[2], fill="..density..")) + 
                                                                        scale_fill_viridis_c(option = "magma") + 
                                                                        geom_point(data = subset(plot_data,facetbyx == x), 
                                                                                   aes_string(x = colnames(plot_data)[1], y = colnames(plot_data)[2]),
                                                                                   size = ptsize,shape = 16 ,color="white",alpha=0.7) + 
                                                                        xlim(xlim) + ylim(ylim) + labs(title = x) +
                                                                        theme(legend.position="none", plot.title = element_text(hjust = 0.5),
                                                                              axis.ticks.x=element_blank(), axis.text.x=element_blank(),
                                                                              axis.ticks.y=element_blank(), axis.text.y=element_blank(),
                                                                              panel.background = element_rect(fill = 'black', colour = 'black'), 
                                                                              panel.grid.major = element_line(colour = "black"),
                                                                              panel.grid.minor = element_line(colour = "black")))

         density_split_grid = gridExtra::grid.arrange(grobs = density_split, ncol = ncol)
         OESingleCell::save_ggplots(file.path(output_dir,paste0("splitby-",facetbyx,"_density_plot",collapse="")),
                                    limitsize = FALSE, plot = density_split_grid, width= ifelse(length(density_split)==1, 7, 6*ncol ), height = nrow*6, bg="white")

     }
    }else{
      if ( as.numeric(opt$dims) == 2 ){
          groupvis = Seurat::DimPlot(object = data_ob, dims = c(1,2),reduction = opt$reduct,
          pt.size = as.numeric(pointsize), group.by = groupfactor)+
              ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5)) +
              ggplot2::scale_colour_manual( values = color_schema[nlevel:nlevel*2])+ theme(aspect.ratio = 1/1)
          OESingleCell::save_ggplots(file.path(output_dir,paste0("groupby-",groupfactor, "_contrast_plot",collapse="")),
                                     plot = groupvis,
                                     limitsize = FALSE, width = 15, height = 10, bg="white" )
      }else{
          suppressPackageStartupMessages(library("SeuratPlotly"))
          groupvis = SeuratPlotly::DimPlotly3d(data_ob, reduction= opt$reduct,
                              pt_size = as.numeric(pointsize),
                              grouping_var = groupfactor,
                              plot_grid = F)
          htmlwidgets::saveWidget(groupvis, file = file.path(output_dir,paste0("groupby-",groupfactor,"_contrast_3D_plot.html",collapse="")))
      }
    }
  }

##细胞比例面积图  
Plot_area=function(x, prop.by = "res.1", group.by = "sampleid", split.by = NULL, 
     ncol = NULL, cols = NULL) 
{
    df <- as.data.frame( x@meta.data[,c(prop.by, group.by)]) %>%
                    table() %>% as.data.frame()  %>% dplyr::rename(cell_number=Freq) %>% 
                    dplyr::arrange(get(group.by)) %>% 
                    dplyr::group_by(.dots= group.by) %>% 
                    dplyr::mutate(freq =(cell_number / sum(cell_number)) * 100) %>% 
                    as.data.frame()
    p =  ggplot(df, aes_string(x=group.by, y="freq", fill=prop.by,group=prop.by)) + 
  geom_area(size=0.4,colour="white")+
  labs(x = NULL, y = "Proportion [%]")+
  theme_bw()+
  scale_x_discrete(expand = c(0, 0.02)) +scale_y_continuous(expand = c(0, 0), labels = seq(0, 100, 25))+
  scale_fill_manual(values=cols)+
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        strip.background = element_rect(fill = NA, color = NA),
        panel.border = element_blank(),
        axis.ticks.x = element_blank(), 
        axis.text = element_text(color = "black", size=10), 
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))+
        geom_vline(aes_string(xintercept = group.by),linetype="dashed", size=0.4, colour="white")
}

#细胞组间占比柱状图
Plot_dodge_barplot=function(data,x.by = "clusters", group.by = "group",cols= summary_colors){
  df <- as.data.frame(data)
  df[[x.by]] = factor(as.character(df[[x.by]]), levels= levels(data[[x.by]]))
  df[[group.by]]=factor(as.character(df[[group.by]]),levels=levels(data[[group.by]]))
  if (x.by == "clusters") {
  angle_size = 0
  hjust_size = 0.5
  vjust_size = 0
  } else {
  angle_size = 45
  hjust_size = 0.85
  vjust_size = 0.85
  }
  p<- ggplot(df, aes_string(x = x.by, y = "freq")) +  #下面fun后边跟的median或者mean一定要加引号！！否则会报错
    geom_bar(stat = "summary", fun ="mean", position = position_dodge(0.85),alpha=0.5,aes_string(fill = group.by,color=group.by),width=0.7) +
    stat_summary(fun.data = 'mean_se', geom = "errorbar", width = 0.4,position = position_dodge(0.85),aes_string(fill = group.by,color=group.by))+
    geom_point(position=position_jitterdodge(jitter.width = 0.2, dodge.width = 0.85), size=2, alpha=1,aes_string(fill = group.by,color=group.by)) +
    scale_fill_manual(values = cols )+ theme_bw() + scale_color_manual(values = cols )+
    labs(x = x.by ,y = "Frequency") +
    theme(axis.text=element_text(size=10, angle = 0,color="black",face = "bold"),
          axis.text.x=element_text(size=10, hjust = hjust_size, angle = angle_size, vjust = vjust_size),
          strip.background = element_rect(fill = NA,color = NA), 
          axis.title.x=element_text(size=18),axis.title.y=element_text(size=14),panel.grid =element_blank()) 

}

Plot_dodge_barplot_withP=function(data,x.by = "clusters", group.by = "group",cols= summary_colors,output_dir){
  df <- as.data.frame(data)
  df[[x.by]] = factor(as.character(df[[x.by]]), levels= levels(data[[x.by]]))
  df[[group.by]]=factor(as.character(df[[group.by]]),levels=levels(data[[group.by]]))
  stat.test <- df %>%  group_by(.dots=x.by) %>% wilcox_test(as.formula(paste("freq ~", group.by))) %>% add_significance("p")  ### wilcox_test
  if ("p.adj" %in% names(stat.test) & "p.adj.signif" %in% names(stat.test)){
  stat.test=stat.test %>% select(-c("p.adj","p.adj.signif"))
  }
  #输出统计结果到表格
  output_data=stat.test %>% select(-c(".y.")) %>% rename(c(p_value=p,label=p.signif,groupA=group1,groupB=group2))
  write.table(output_data,file.path(output_dir,paste0("groupby_",group.by,"_statistic_results_pvalue.xls")),sep="\t",row.names=FALSE)
  #都是ns时全部ns都展示。不都是ns时，隐藏掉ns值
  if (all(stat.test[["p.signif"]] == "ns")){
  stat.test <- stat.test %>% add_xy_position(x = x.by, dodge = 0.85,step.increase=0.03)
  }else{
  stat.test <- subset(stat.test,p.signif!="ns")
  max_freq <- df %>%
  group_by(.dots=x.by) %>%
  summarise(max_freq = max(freq, na.rm = TRUE)+0.02*max(df$freq))
  stat.test <- stat.test %>%
    left_join(max_freq, by = x.by) %>%
    rename(y.position = max_freq) %>% add_x_position(x = x.by, dodge = 0.85)
   }

  if (x.by == "clusters") {
  angle_size = 0
  hjust_size = 0.5
  vjust_size = 0
  } else {
  angle_size = 45
  hjust_size = 0.85
  vjust_size = 0.85
  }
  p<- ggplot(df, aes_string(x = x.by, y = "freq")) +  #下面fun后边跟的median或者mean一定要加引号！！否则会报错
  geom_bar(stat = "summary", fun ="mean", position = position_dodge(0.85),alpha=0.5,aes_string(fill = group.by,color=group.by),width=0.7) +
  stat_summary(fun.data = 'mean_se', geom = "errorbar", width = 0.4,position = position_dodge(0.85),aes_string(fill = group.by,color=group.by))+
  geom_point(position=position_jitterdodge(jitter.width = 0.2, dodge.width = 0.85), size=2, alpha=1,aes_string(fill = group.by,color=group.by)) +
   scale_fill_manual(values = cols )+ theme_bw() + scale_color_manual(values = cols )+
   labs(x = x.by ,y = "Frequency") +
   theme(axis.text=element_text(size=10, angle = 0,color="black",face = "bold"),
         axis.text.x=element_text(size=10, hjust = hjust_size, angle = angle_size, vjust = vjust_size),
         strip.background = element_rect(fill = NA,color = NA), 
         axis.title.x=element_text(size=18),axis.title.y=element_text(size=14),panel.grid =element_blank()) +
    stat_pvalue_manual(
    stat.test, label = "p.signif", tip.length = 0.01,step.increase=0.05,step.group.by=x.by,label.size = 6) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1)))
}

    if ( as.logical(opt$dosummary) ){
        data_ob = Seurat::SetIdent( data_ob, value = opt$groupby )
        data_ob@meta.data[[opt$groupby]] <- factor( data_ob@meta.data[[opt$groupby]],levels=unique(sort(data_ob@meta.data[[ opt$groupby]] )))
        DATA <- suppressMessages(OESingleCell::colData(data_ob)[,c("sampleid", opt$groupby)] %>%
                dplyr::group_by( .dots= c("sampleid", opt$groupby)) %>%
                dplyr::summarize(cell_number = dplyr::n()) %>%
                dplyr::mutate(freq = (cell_number / sum(cell_number)) * 100))
      #映射group
      facet_factors <- unlist(strsplit(opt$facetby, ","))
      #先剔除一些可以预判的分组中不适合绘制dodge_barplot的值
      facet_factors <- facet_factors[!facet_factors %in% c("sampleid","clusters")]
      #双重保险，再通过与sampleid的对应关系检查一下设置的分组中是否有不适合绘制dodge_barplot的值
        for (i in facet_factors) {
          group.by=i
          result <- data_ob@meta.data %>%
            dplyr::group_by(sampleid) %>%
            dplyr::summarise(unique_num = dplyr::n_distinct(!!sym(group.by)))
          if (!all(result$unique_num)==1){
              facet_factors <- setdiff(facet_factors, i)
          }
        }
        for (group.by in facet_factors) {
        sampleid_group=OESingleCell::colData(data_ob)[,c("sampleid", group.by)] %>% dplyr::distinct()
        for (i in unique(sampleid_group$sampleid)){
        DATA[which(DATA$sampleid==i),group.by]=sampleid_group[which(sampleid_group$sampleid==i),group.by]
        }
        }
        write.table(as.data.frame(DATA), file.path(output_dir,file="clust_cond_freq_info.xls"),
                sep="\t", col.names=T, row.names =F)
        # visulaize the summary statistics of cells clusters in each groupping factor
        if ( !is.null(opt$facetby) ){
            for (facetbyx in unlist( strsplit( opt$facetby, "," ) )){
                if ( ! as.logical(opt$use_color_anno )){
                    data_ob@meta.data = data_ob@meta.data[ ,!grepl(paste0("^",facetbyx,"_col$" ), colnames(data_ob@meta.data))]
                }
                if ( !is.null(opt$color_file)){
                    color_file = read.delim(opt$color_file, sep="\t", header = T)
                    meta_anno = color_anno(data_ob@meta.data, color_file)
                } else {
                    meta_anno = data_ob@meta.data
                }
                color_use = get_colors(meta_anno, opt$groupby, opt$palette)
                user_color_pal = color_use[["new_celltype_pal"]]
                user_color_pal = na.omit(user_color_pal)
                clust_sum_all = OESingleCell::PlotAbundances(data_ob,
                                                     prop.by = opt$groupby,
                                                     group.by = facetbyx,
                                                     method = "barplot",
                                                     cols= user_color_pal)
                OESingleCell::save_ggplots(file.path(output_dir,paste0("groupby-",facetbyx,"_summary_plot",collapse="")),
                    dpi=300, plot = clust_sum_all,width = 7, height = 7, bg="white" )
                if (opt$area_plot==TRUE){
                clust_area_all = Plot_area(data_ob, group.by = facetbyx, 
                            prop.by = opt$groupby,
                            #cols= unname(SelectColors(1:length(unique(data_ob@meta.data[, opt$groupby])), palette = opt$palette))
                            cols= color_use[["user_color_pal"]]
                    )
                    OESingleCell::save_ggplots(
                        file.path(output_dir,paste0("groupby-",facetbyx,"_area_plot",collapse="")),
                        plot = clust_area_all,
                        width = ifelse(length(unique(data_ob@meta.data[, facetbyx]))<=1,3,length(unique(data_ob@meta.data[, facetbyx])) * 1+2),
                        height = 6,
                        dpi = 300, bg="white"
                    )
                }
             }
        }
        data_ob = Seurat::SetIdent(data_ob, value = "sampleid")
        if ( ! as.logical(opt$use_color_anno )){
            data_ob@meta.data = data_ob@meta.data[ ,!grepl(paste0("^",'sampleid',"_col$" ), colnames(data_ob@meta.data))]
         }
         if ( !is.null(opt$color_file)){
            color_file = read.delim(opt$color_file, sep="\t", header = T)
            meta_anno = color_anno(data_ob@meta.data, color_file)
         } else {
            meta_anno = data_ob@meta.data
         }
        color_use2 = get_colors(meta_anno, "sampleid", opt$palette)
        user_color_pal2 = color_use2[["new_celltype_pal"]]
        user_color_pal2 = na.omit(user_color_pal2)
        #summary_colors = SelectColors(palette = 'customecol2')[11:50]  # 固定sampleid的分组颜色
        summary_colors = user_color_pal2
        clust_sum_all2 = OESingleCell::PlotAbundances(data_ob, prop.by = "sampleid",
                                        group.by = opt$groupby,
                                        method = "barplot",
                                        cols= summary_colors)
        OESingleCell::save_ggplots(file.path(output_dir,paste0("groupby-",opt$groupby, "_summary_plot",collapse="")),
                                   dpi=300, plot = clust_sum_all2,width = 7, height = 7, bg="white" )

      ########绘制dodge barplot#########
      library(ggpubr)
      library(rstatix)
      library(dplyr)
      library(gtools)
      facet_factors <- unlist(strsplit(opt$facetby, ","))
      #先剔除一些可以预判的分组中不适合绘制dodge_barplot的值
      facet_factors <- facet_factors[!facet_factors %in% c("sampleid","clusters")]
      #双重保险，再通过与sampleid的对应关系检查一下设置的分组中是否有不适合绘制dodge_barplot的值
      for (i in facet_factors) {
        group.by=i
        result <- data_ob@meta.data %>%
          dplyr::group_by(sampleid) %>%
          dplyr::summarise(unique_num = dplyr::n_distinct(!!sym(group.by)))
        if (!all(result$unique_num)==1){
            facet_factors <- setdiff(facet_factors, i)
        }
      }
      for (group.by in facet_factors) {
      x_by=opt$groupby
     #判断是否每个横坐标有2个及2个以上的分组没有样本
      total_sub_num=c()
      ##首先，计算一共有多少个分组
      num_group=length(unique(DATA$group))
      ##计算每个横坐标中有多少个分组存在
      for (i in unique(DATA[[opt$groupby]])){
      sub_data=subset(DATA,DATA[[opt$groupby]]==i)
      ##计算差值，算出各横坐标中缺少几个分组
      sub_num=num_group-length(unique(sub_data$group))
      ##统计各个横坐标中缺少分组的数值，后续会判断是否都小于2
      total_sub_num=c(total_sub_num,sub_num)
      }
      #填充每个cluster缺失的group的cellnumber为0
      # 步骤1: 为每个sampleid生成完整的clusters序列
      full_clusters <- expand.grid(sampleid = unique(DATA$sampleid), x_by = unique(DATA[[x_by]]))
      colnames(full_clusters)[which(colnames(full_clusters) == "x_by" )] <- x_by
      # 步骤2: 合并原始数据和完整的clusters序列  
      df_full <- merge(full_clusters, DATA, by = c("sampleid", x_by), all.x = TRUE)
      # 步骤3: 填充缺失的group和cellnumber  
      df_full[[group.by]][is.na(df_full[[group.by]])] <-   
        sapply(df_full$sampleid[is.na(df_full[[group.by]])], function(sid) {  
          DATA[[group.by]][DATA$sampleid == sid][1]
        })  
      df_full$cell_number[is.na(df_full$cell_number)] <- 0
      df_full$freq[is.na(df_full$freq)] <- 0 
      DATA=df_full
      if (is.factor(data_ob@meta.data[[opt$groupby]]) == FALSE) {
          if (opt$groupby=="clusters"){
            data_ob@meta.data[[opt$groupby]] = factor(data_ob@meta.data[[opt$groupby]], levels = unique(sort(as.numeric(data_ob@meta.data[[opt$groupby]]))))
          } else {
            data_ob@meta.data[[opt$groupby]] = as.factor(data_ob@meta.data[[opt$groupby]])
          }
      }
      if (is.factor(data_ob@meta.data[[group.by]]) == FALSE) {
          data_ob@meta.data[[group.by]] = as.factor(data_ob@meta.data[[group.by]])
      }
      DATA[[opt$groupby]] = factor(DATA[[opt$groupby]], levels = levels(data_ob@meta.data[[opt$groupby]]))
      DATA[[group.by]] = factor(DATA[[group.by]], levels = levels(data_ob@meta.data[[group.by]]))
      color_use = get_colors(meta_anno,group.by, opt$palette)
      user_color_pal = color_use[["new_celltype_pal"]]
      user_color_pal = na.omit(user_color_pal)
      color_use = user_color_pal
      dodge_barplot=Plot_dodge_barplot(DATA,x_by,group.by,cols= color_use)
      OESingleCell::save_ggplots(file.path(output_dir,paste0(group.by,"_dodge_barplot_by",x_by,collapse="")),
          dpi=300, plot = dodge_barplot,width = 0.25*length(unique(DATA[[x_by]]))*length(unique(DATA$group))+3, height = 6, bg="white" ,limitsize = FALSE)
      #判断是否组内有至少3个重复样本。若有，才出带p值的图
      n_sampleid <- as.data.frame(DATA) %>%
      group_by(.dots=group.by) %>%
      summarize(count_distinct_sampleid = n_distinct(sampleid))
      
      if (length(unique(DATA[[group.by]])) >= 2) {
      if (all(n_sampleid$count_distinct_sampleid >= 3)){
        #每个横坐标有2个及2个以上的分组中没有细胞，不绘制带p值的dodge barplot
        if (all(total_sub_num < 2)) {
        dodge_barplot_withP=Plot_dodge_barplot_withP(DATA,opt$groupby,group.by,cols= color_use,output_dir)
        OESingleCell::save_ggplots(file.path(output_dir,paste0(group.by,"_dodge_barplot_by",opt$groupby,"_withpvalue",collapse="")),
          dpi=300, dodge_barplot_withP,width = 0.25*length(unique(DATA[[opt$groupby]]))*length(unique(DATA$group))+3, height = 6, bg="white",limitsize = FALSE )
        }else{
              print(paste0(group.by,"某个横坐标中，所有样本cell_number都为0的分组数大于二，不出带p值的图"))
              }
      }else{
            print(paste0(group.by,"不满足每个组内有至少3个重复样本，不出带p值的图"))
      }
      }else {
        print(paste0(group.by,"只有1个分组，不出带p值的图"))
      }
      }
      ###########绘制area plot############
      #默认不出
        if (opt$area_plot==TRUE){
        clust_area_all = Plot_area(data_ob, group.by = opt$groupby, 
                                        prop.by = "sampleid",
                                        cols= summary_colors)
        # 添加宽度判断
        width1 = ifelse(length(unique(data_ob@meta.data[, opt$groupby]))<=1,2,length(unique(data_ob@meta.data[, opt$groupby])) * 1) # 判断图例宽度
        width2 = as.integer(max(nchar(as.character(data_ob@meta.data$sampleid)))/5) # 判断图例宽度
        width_all = width1 + width2
        OESingleCell::save_ggplots(
                file.path(output_dir,paste0("groupby-",opt$groupby, "_area_plot",collapse="")),
                plot = clust_area_all,
                width = width_all,
                height = 6,
                dpi = 300, bg="white"
            )  
        }
    }
    quit()
}

# =============== Subcmd: dimreduce, run dimension reduction =========
if ( "dimreduce" %in% args ){
  if ( is.null(opt$reduct1 )){
    print("NO first level dimension reduction methods specified,the default PCA will be used!")
    reduct1 = "pca"
  }else{
    reduct1 = tolower(opt$reduct1)
  }

  if ( !is.null(opt$reduct2) ){
    reduct2 = tolower(unlist(strsplit(opt$reduct2,",",  perl = T)))
  }else{
    # if no secondary reduction method specified, use primary reduction instead
    reduct2 = reduct1
  }

  if ( !is.null(opt$batchid) ){
    batchid = opt$batchid
  }

  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, reduction = opt$reduct, data.use = dataslots,  # data,scale.data
                  verbose = F)

  # get the subset of cells used for visualization if necessay
  # subset cells on the expression matrix using logical exprssion on features
  if ( !is.null(opt$predicate) ){
      df = OESingleCell::colData(data_ob)
      desired_cells= subset(df, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }

  # check out wether the specified primary reduction has beed calculated
  is.rerun_reduct1 = FALSE; is.rerun_reduct2 = FALSE
  switch(as.character(opt$rerun),
         "reduct1" = {
           is.rerun_reduct1 = TRUE
         },
         "reduct2" = {
           is.rerun_reduct2 = TRUE
         },
         "all" = {
           is.rerun_reduct1 = TRUE
           is.rerun_reduct2 = TRUE
         } )

  if ( !is.null(reduct1 )){ # primary reduction is specified
    # if no previous reduction found, catch the error and rerun the
    # reduction without stop with error
    if ( !reduct1 %in% OESingleCell::Reductions(data_ob) | is.rerun_reduct1 ){
      print( "NO specified primary reduction found in the object! Rerun begins!")
      message(paste0("Beginning ", reduct1, " Dimension Reduction"))
      dim_outdir = file.path(output_dir,paste0(reduct1, "_Dimension_Reduction"))
      if ( !dir.exists(dim_outdir) ){
        dir.create(dim_outdir, recursive = T)
      }

      data_ob = RunDimReduc(data_ob, reduct1 = reduct1 ,
                              reduct2 = reduct1,
                              feature.use = OESingleCell::VariableFeatures(data_ob),
                              perplexity = perplexity,
                              assay.use = OESingleCell::DefaultAssay(data_ob),
                              batch.use = batchid, npcs.use = opt$components )
      reduct1_coord = OESingleCell::FetchData(data_ob,
                                var = c("rawbc", paste0(Seurat::Key(data_ob)[reduct1], 1:2))) %>%
                      dplyr::rename( "Barcode" = "rawbc")
      write.table( reduct1_coord, file.path(dim_outdir, paste0(reduct1, "_Dimension_Reduction_coordination.csv")),
                   sep = ",", col.names = T, row.names = F, quote = F)
    }else{
      print("The specified reduction results have beed calculated!Skip it!")
    }
  }

  if ( opt$reduct1 %in% c("pca","cca","harmony","ica", "lsi") ){ #if the prevous reduction is primary reduction
      #check the components
      # find the optimal components for secondary reduction
      optimal_pc = tryCatch(
                expr = Seurat::Command(data_ob, command = glue::glue("FindNeighbors.{opt$assay}.{opt$reduct1}"), value = "dims"),
                error = function(...){ return(NULL) }
              )
      if ( is.null(optimal_pc) ){ #if previous optimal components not available
          print( "NO previous optimal components is AVAILABLE, the optimal components number be detected automatically.")
          elb = Seurat::ElbowPlot(data_ob, reduction = opt$reduct1)
          optimal_pc = OESingleCell::FindElbow(elb$data)
          # suppressWarnings({ Misc(data_ob, "optimal_pc") = optimal_pc})
      }
  }else{ # reduct1 is not primary reduction and previouly run without primary reduction
          # the exception is mnn, it's better to be specified from command line with relative low value
          optimal_pc = min(opt$components, ncol(OESingleCell::Embeddings(data_ob,reduction = opt$reduct1)))
  }

  # different reduction method from primary reduction specified or forced to rerun
  if ( !opt$reduct2 %in% OESingleCell::Reductions(data_ob) | (opt$reduct2 != reduct1 & is.rerun_reduct2) ){
      message(paste0("Beginning ", opt$reduct2, " Dimension Reduction"))
      output_dir = file.path(output_dir,paste0(opt$reduct2, "_Dimension_Reduction"))
      if ( !dir.exists(output_dir) ){
        dir.create(output_dir, recursive = T)
      }

      data_ob = RunDimReduc(data_ob, reduct1 = reduct1 , reduct2 = opt$reduct2,
                              feature.use = VariableFeatures(data_ob),
                              assay.use = DefaultAssay(data_ob),
                              batch.use = batchid, npcs.use = optimal_pc)
      reduct1_coord = OESingleCell::FetchData(data_ob,
                                var = c("rawbc", paste0( Key(data_ob)[opt$reduct2], 1:2))) %>%
                      dplyr::rename( "Barcode" = "rawbc")
      write.table( reduct1_coord, file.path(dim_outdir, paste0(opt$reduct2, "_Dimension_Reduction_coordination.csv")),
                   sep = ",", col.names = T, row.names = F, quote = F)
  }

  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob,
                                 reduction = unique(c(opt$reduct1, opt$reduct2)))
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }
  quit()
}

# =============== Subcmd: clusterx, run data clustering =========
if ( "clusterx" %in% args ){
   # read the specified assay and data slot in data object into memory
  data_ob = ReadX(input = opt$input, informat = opt$informat,
                  assays = assays, data.use = dataslots, verbose = F)

  # get the subset of cells used for visualization if necessay
  # subset cells on the expression matrix using logical exprssion on features
  if ( !is.null(opt$predicate) ){
      df = OESingleCell::colData(data_ob)
      desired_cells= subset(df, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }

  if ( !is.null(opt$graphid) ){
    stopifnot( opt$graphid %in% SeuratObject::Graphs(data_ob) )
  }

  #Clustering with the reduction results using different clustering methods
  clustering.alg = c("snn" = 1, "louvain" = 2, "slm" = 3, "leidn" = 4)
  message(glue::glue("Beginning to group the cells using algorithm {opt$algorithm}!" ) )
  data_ob = Seurat::FindClusters(object = data_ob, resolution = opt$resolution,
                                 graph.name = opt$graphid,
                                 algorithm = clustering.alg[opt$algorithm], verbose = F)
  message("Clustering Finished!")

  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob )
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }
  quit()
}

# =============== Subcmd: findneighbor, SNN or wSNN calculation =========
if ( "findneighbor" %in% args ){
   # read the specified assay and data slot in data object into memory
  data_ob = ReadX(input = opt$input,
                                informat = opt$informat,
                                assays = assays,
                                data.use = dataslots, # data slot is enough
                                verbose = F)

  reductions = unlist(strsplit(opt$reduction, ",", perl = T))
  dims = lapply(unlist(strsplit(opt$dims, ",", perl = T)), function(x){eval( parse(text = x))})
  if ( length(assays) > 1 ){ # multimodal assays
    data_ob = Seurat::FindMultiModalNeighbors(data_ob,
                                              k.nn = opt$k_param,
                                              reduction.list = as.list(reductions),
                                              dims.list = dims,
                                              verbose = F)
  }else{ # monomodal assays
    data_ob = Seurat::FindNeighbors( data_ob,
                                   k.nn = opt$k_param,
                                   reduction = reductions[1],
                                   dims = dims[1],
                                   force.recalc = T, verbose = F)

  }

  if ( as.logical(opt$update) ){
    SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob,
                                 reduction = reductions, verbose = F)
  }else{
    OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                        outformat = opt$outformat, prefix = opt$prefix)
  }

  quit()
}


# =============== Subcmd: infercnv, copy number variation inference =========
if ( "infercnv" %in% args ){
  # read the specified assay and data slot in data object into memory
  data_ob = ReadX(input = opt$input,
                                informat = opt$informat,
                                assays = assays, # only RNA assay is valid
                                data.use = "counts", # counts slot is enough
                                verbose = F)

  # prepare the gene annotation file.
  if ( !is.null( opt$gene_order) ){
    gene_order_f = opt$gene_order
  }else if ( !is.null( opt$gtf ) ){
    gtf = plyranges::read_gff(opt$gtf)
    gene.chr = gtf %>% plyranges::filter(type == "gene" & gene_name %in% rownames(seurat_ob)) %>%
      as.data.frame() %>%
      dplyr::select(gene_name, seqnames, start, end) %>%
      dplyr::distinct(gene_name, .keep_all=T) %>%
      dplyr::mutate( seqnames = paste0("chr", seqnames))
    tempdir = tempdir()
    gene_order_f = file.path( tempdir, "gene_order_file.xls" )
    write.table(gene.chr, gene_order_f, col.names =F, row.names =F, sep = "\t", quote =F )
  }else{
    stop("NO gene coordination annotation file is not available!")
  }

  # if ( !is.null(opt$chr2exclude) ){
  #     chr2exclude = unlist(strsplit(opt$chr2exclude, ",", perl =T))
  # }else{
  #     chr2exclude = "chrM"
  # }

  # split the whole seurat to equal parts with almost same normal cells and tumor cells for pallalization.
  # for the tumor cells, equally seperate them to even parts.
  # for the normal cells, we tend to substract all the normal cells out and downsample to the desired number
  # for high efficiency.
  # then combine the same normal cells with different tumor cells parts.

  # make the celltype annotation file for CNV run
  #a description of the cells, indicating the cell type classifications.
  # The annotations_file, containing the cell name and the cell type classification, tab-delimited without header.
  #             V1                   V2
  # 1 MGH54_P2_C12 Microglia/Macrophage
  # 2 MGH36_P6_F03 Microglia/Macrophage
  # 3 MGH53_P4_H08 Microglia/Macrophage
  # 4 MGH53_P2_E09 Microglia/Macrophage
  # 5 MGH36_P5_E12 Oligodendrocytes (non-malignant)
  # 6 MGH54_P2_H07 Oligodendrocytes (non-malignant)
  # ...
  # 179  93_P9_H03 malignant
  # 180 93_P10_D04 malignant
  # 181  93_P8_G09 malignant
  # 182 93_P10_B10 malignant
  # 183  93_P9_C07 malignant
  # 184  93_P8_A12 malignant
  cellanno = FetchData(seurat_ob, vars = opt$celltype ) %>% tibble::rownames_to_column(var = "cellbarcode")
  if ( !is.null( opt$refgroup ) ){
    refcells = unlist(strsplit(opt$refgroup, ",", perl = T))
    count_mat = GetAssayData(seurat_ob, "counts")
  }else if ( !is.null( opt$malignant ) ){
    malignant = unlist(strsplit(opt$malignant, ",", perl = T))
    refcells = setdiff( unique(seurat_ob@meta.data[, opt$celltype]), malignant)
    count_mat = GetAssayData(seurat_ob, "counts")
  }else{
    print("NO reference normal cells or malignant cells are specified!
           The internal customized normal reference data will be used!")
    refexp = readRDSMC(opt$refexp, cores = 10)
    refcell_anno = data.frame(cellbarcode = colnames(refexp), celltype = "normal")
    cellanno = rbind(cellanno, refcell_anno )
    com.genes = intersect( rownames(seurat_ob), rownames(refexp) )
    count_mat = cbind(GetAssayData(seurat_ob, "counts")[com.genes,], refexp[com.genes,])
  }
  cnv_celltyping = file.path(tempdir, "cnv_celltype_group.xls")
  write.table(cellanno, cnv_celltyping, sep = "\t", col.names = F,row.names = F, quote = F)

  # main workflow
  infercnv_obj = infercnv::CreateInfercnvObject(raw_counts_matrix= count_mat,
                                      annotations_file= cnv_celltyping,
                                      delim="\t",
                                      gene_order_file= gene_order_f,
                                      ref_group_names=refcells)
  infercnv_obj = infercnv::run(infercnv_obj,
                               cutoff= opt$cutoff,
                               analysis_mode= opt$mode, # detect the subclusters  of tumor
                               tumor_subcluster_pval=opt$pval,
                               hclust_method = opt$clusting2use,
                               out_dir= output_dir,
                               num_threads=opt$ncores,
                               cluster_by_groups=TRUE,
                               denoise=TRUE,
                               no_plot = T,
                               no_prelim_plot = F,
                               HMM=as.logical(opt$doHMM))

  # visualize the cnv value for each cell in heatmap for optimal cluster numbers
  pdf( file.path(output_dir, "raw_heatmap.pdf"), width = 18, height = 12 )
  ComplexHeatmap::Heatmap(
    t(as.matrix(infercnv_obj@expr.data)),
    cluster_rows = FALSE,
    cluster_columns = FALSE,
    show_row_names =F,
    show_column_names = F,
    name="CNV level",
    use_raster=TRUE,
    raster_quality=4 )
  dev.off()

  # automatics cnv level inference for each cell
  if ( as.logical(opt$do_cnvlevel) ){
    # TO DO
  }

  quit()
}


# =============== Subcmd: vdj, parsing the vdj output from cellranger =========
if ( "vdj" %in% args ){
  vdj_path = normalizePath(sub("\\/$","",opt$vdj,perl=T))
  if (all(file.exists(Sys.glob(file.path(vdj_path,assay_metadata$sampleid))) )){
    # # glob all the clonotype annotation file for all the samples
    clonotypes_tbs = file.path(vdj_path,assay_metadata$sampleid,"outs","clonotypes.csv")
    names(clonotypes_tbs) = assay_metadata$sampleid
    json4samples = file.path(vdj_path,assay_metadata$sampleid,"outs","all_contig_annotations.json")
    names(json4samples) = assay_metadata$sampleid
  }else{
    stop("NO Cellranger VDJ output directory available! Please make sure the samples' ID in the metadata are the same as
        the output directories' name of the Cellranger VDJ results.")
  }
  # join the clonotype.csv and filtered_contig_annotations.csv table using the clonotype id
  # concatenate the table to relabel the clonotype id
  merged_profile = future.apply::future_lapply( names(json4samples), function(idx){
    # parse the all_contig_annotations.json file
    clonotypes_df = data.table::fread( clonotypes_tbs[idx]) %>% as_tibble() # read in the clonotypes.csv
    productive_summ = jsonlite::fromJSON(json4samples[idx]) %>% # all contig annotation nested data.frame
      dplyr::filter( is_cell != "FALSE" & high_confidence != "FALSE" & !is.null(cdr3) & productive == TRUE) %>%
      dplyr::mutate(raw_clonotype_id = info$raw_clonotype_id) %>%
      dplyr::select(-c("info", "filtered", "primer_annotations", "frame", "clonotype",
                "quals", "is_cell", "productive", "high_confidence")) %>%
      dplyr::drop_na( raw_clonotype_id ) %>% dplyr::drop_na(cdr3)
    anno_list = future.apply::future_lapply( productive_summ$annotations, function(anno){
      anno = anno %>%
        dplyr::select(-c("annotation_length","annotation_match_end",
                  "annotation_match_start","cigar","mismatches", "score" )) %>%
        dplyr::mutate( region_type = feature$region_type,  # extract the immune allel gene segment annotation
                region = feature$gene_name, chain = feature$chain) %>%
        dplyr::filter( !region_type %in% c("5'UTR", "C-REGION")) %>%
        dplyr::select(-feature)

      if ( !"D-REGION" %in% unique(anno[["region_type"]]) ){
        D_region = c(
          contig_match_end = "NA",
          contig_match_start = "NA",
          region_type = "D-REGION",
          region = "NA",
          chain = unique(anno[["chain"]])[1]
        )
        anno = rbind( anno, D_region[colnames(anno)] )
      }
      anno_row = anno %>%
        mutate(region_type = gsub( "L?-REGION\\+?", "", region_type, perl = T)) %>%
        arrange( factor( region_type, levels = c("V", "D", "J"))) %>%
        unite( "range", c("contig_match_start", "contig_match_end"), sep = ":") %>%
        unite( "segments", c("region", "range"), sep = ":") %>%
        summarize( segments= paste(segments, collapse=","), chain = unique(chain)[1]  )
    })
    anno_df = do.call(rbind, anno_list )
    productive_summ = cbind( productive_summ, anno_df ) %>% select(-annotations)%>%
      dplyr::rename( "clonotype_id" = "raw_clonotype_id",
                     "contig_id" = "contig_name", "cdr3_aa" = "cdr3", "cdr3_nt" = "cdr3_seq"  ) %>%
      inner_join( clonotypes_df, by = "clonotype_id") %>%
      select( -c("aa_sequence", "proportion", "frequency") ) %>%
      mutate( sampleid = idx ) %>%
      mutate( barcode = paste(sampleid, gsub("-\\d+","",barcode), sep = "-"))
    productive_summ
  })

  # merge all the annotation from each to one data.frame
  merged_profile = as.data.frame(do.call(rbind, merged_profile))

  # unification of two immunological sequences' annotation into one line in the same cell if exits.
  integrated_profile =  merged_profile %>%
    mutate( umis = umi_count,
            reads = read_count,
            chainx = chain,
            read_count = paste0( chain, ":", read_count),
            umi_count = paste0( chain, ":", umi_count),
            cdr3s_region = paste0(chain, ":", cdr3_start,"-", cdr3_stop),
            CDS_region = paste0(chain, ":", start_codon_pos, "-", stop_codon_pos)) %>%
    select( barcode, sampleid,contig_id, chain,cdr3s_aa, cdr3s_nt, cdr3s_region, chainx,
            segments, CDS_region, read_count, reads, umi_count,umis ) %>%
    group_by( barcode ) %>%
    summarize( # merge the paired VDJ annotation for each chain into one line
      sampleid = unique(sampleid),
      cdr3s_aa = unique(cdr3s_aa),
      cdr3s_nt = unique(cdr3s_nt),
      cdr3s_region = paste(unique(cdr3s_region), collapse=";"),
      segments= paste(segments, collapse=";"),
      CDS_region = paste(unique(CDS_region), collapse=";"),
      vdj_read_count = paste(unique(read_count), collapse=";"),
      vdj_umi_count = paste(unique(umi_count), collapse=";"),
      umis4cell = sum(unique(umis)),
      reads4cell = sum(unique(reads)) ) %>% ungroup()

  #
  clonotype_count = integrated_profile %>% group_by(cdr3s_aa) %>% tally() %>% arrange(desc(n))
  clonotype_count$clonotype_id =  paste("clonotype",1:dim(clonotype_count)[1],sep="")
  integrated_profile = inner_join(integrated_profile, clonotype_count,by = "cdr3s_aa") %>%
    arrange( desc(n)) %>% mutate(is_paired = ifelse(grepl(";", cdr3s_aa), "TRUE", "FALSE" )) %>%
    distinct() %>% mutate( id4cell = 1)
  write.table( integrated_profile, file.path(output_dir, "merged_vdj_contig_annotation.csv"),
               sep=",", quote = F, col.names = T, row.names=F)


  additional_cell_meta = vector()
  sampleidx =  gsub("(_|-)[ATCG]{16,}.*", integrated_profile$barcode,perl=T) #the index order is the same as the row index of the assay metadata
  for ( colidx in colnames(assay_metadata) ){
    additional_cell_meta = cbind(additional_cell_meta,
                                 as.vector(assay_metadata[sampleidx, colidx]))
  }
  colnames(additional_cell_meta) = colnames(assay_metadata)
  rownames(additional_cell_meta) = integrated_profile$barcode
  additional_cell_meta = additional_cell_meta %>%
    as.data.frame() %>%
    tibble::rownames_to_column(var = "barcode")
  integrated_profile = inner_join(additional_cell_meta,
                                  integrated_profile,
                                  by = c("barcode" = "barcode", "sampleid" = "sampleid"), keep = F)

  if ( !is.null(opt$seurat) ){
    seurat_ob = AddMetaData(seurat_ob, metadata = integrated_profile)
    # saveRDSMC(seurat_ob, opt$seurat)
  }
  # count the umi, reads or cells for each group
  for ( methodx in unlist( strsplit(opt$quant.use,",") ) ){
    countby = switch(
      tolower(methodx),
      "umi" = "umis4cell",
      "reads" = "reads4cell",
      "cells" = "id4cell"
    )

    clonotype_table = integrated_profile %>%
      select_at( c("sampleid", "clonotype_id", countby)) %>%
      rename("counts" = {{countby}}) %>%
      group_by(sampleid,clonotype_id) %>%
      summarise(counts = sum(counts)) %>% ungroup() %>%
      tidyr::spread(sampleid, counts,fill = 0) %>%
      mutate(total = rowSums(.[,2:dim(.)[2]])) %>%
      arrange(desc(total)) %>% dplyr::select(-total)

    write.table(clonotype_table, file.path(output_dir, glue::glue("clonotype_count_by_{methodx}_for_each_sample.xls")),
                 sep="\t", quote = F, col.names = T, row.names=F)

    if ( opt$maketse ){
      # make the TreeSummarizedExperiment as a data container of the sample level
      # clonotype annotation for diversity ananlysis
      tse_counts  = clonotype_table %>%
        tibble::column_to_rownames(var = "clonotype_id") %>% as.matrix()
      clonotype_anno = integrated_profile %>%
        select( clonotype_id, cdr3s_aa) %>%
        unique() %>% as_tibble() %>%
        tibble::column_to_rownames(var = "clonotype_id")
      tse = TreeSummarizedExperiment::TreeSummarizedExperiment(
        assays = list( counts = tse_counts ),
        colData = assay_metadata[colnames(tse_counts),],
        rowData =  clonotype_anno[rownames(tse_counts),] )
      saveRDS(tse, file.path(output_dir, glue::glue("vdj.tse.by.{methodx}.rds")))
    }
  }

  # change the format clonotype table to the specified
  future.apply::future_lapply(names(json4samples), function(idx){
    if ( opt$vdjformat == "vdjtools" ){
      parsed_vdj = merged_profile %>%
        dplyr::filter( sampleid == idx ) %>%
        dplyr::mutate( frequency = umi_count/sum(umi_count)) %>%
        dplyr::separate(segments,
                 c("V", "V.start", "V.end", "D", "D.start", "D.end", "J", "J.start", "J.end"), sep= ":|,") %>%
        dplyr::select( umi_count,frequency,cdr3_nt,cdr3_aa,V,D,J, V.end, D.start, D.end, J.start, barcode,cdr3s_aa, cdr3s_nt) %>%
        dplyr::rename( count = umi_count, CDR3nt = cdr3_nt, CDR3aa = cdr3_aa,
                Vend = V.end, Dstart = D.start, Dend = D.end, Jstart = J.start,
                clonotype_nt = cdr3s_nt, clonotype_aa = cdr3s_aa ) %>%
        dplyr::arrange(dplyr::desc(count))
      parsed_vdj[is.na( parsed_vdj) ]= "."
    }else if ( opt$vdjformat == "immunarch" ){
      parsed_vdj = merged_profile %>%
        dplyr::filter( sampleid == idx ) %>%
        dplyr::mutate( frequency = umi_count/sum(umi_count)) %>%
        dplyr::separate(segments,
                 c("V", "V.start", "V.end", "D", "D.start", "D.end", "J", "J.start", "J.end"), sep= ":|,") %>%
        dplyr::select( umi_count,frequency,cdr3_nt,cdr3_aa,V,D,J, V.end, D.start, D.end, J.start, contig_id, barcode, cdr3s_nt,cdr3s_aa) %>%
        dplyr::rename( count = umi_count, CDR3nt = cdr3_nt, CDR3aa = cdr3_aa, Vend = V.end, Dstart = D.start, Dend = D.end, Jstart = J.start,clonotype_nt = cdr3s_nt, clonotype_aa = cdr3s_aa  ) %>%
        dplyr::arrange(desc(count))
      parsed_vdj[is.na( parsed_vdj) ]= "."
    }
    write.table( parsed_vdj, file.path(output_dir, paste0( idx, ".xls", collapse = "")),
                 sep="\t", col.names = T, row.names=F, quote = F)
  })

  file_name = paste( rownames(assay_metadata), ".xls", sep = "")
  new_names = c("#file_name", colnames(assay_metadata) )
  assay_metadata = cbind( file_name, assay_metadata )
  colnames(assay_metadata) = new_names
  assay_metadata = assay_metadata %>% rename( sample.id = sampleid)
  write.table( assay_metadata, file.path(output_dir, "vdj_metadata.xls"),
               sep="\t", col.names = T, row.names=F, quote = F)
}



# =============== Subcmd: rmdoublets, remove the doublets from the data matrix =========
if ( "rmdoublets" %in% args ){
  # read the specified assay and data slot in data object into memory
  data_ob = ReadX(input = opt$input,
                                informat = opt$informat,
                                assays = assays, # only RNA assay is valid
                                data.use = "counts", # counts slot is enough
                                verbose = F)

}
# =============== Subcmd: annotation, add annotation to a genelist file =========
if ( "annotation" %in% args ){
  if (is.null(opt$anno)) {
    stop("Please provide the species information with parameter \"-a\" !")
  }else{
    marker = read.delim(opt$genelist, sep = "\t", stringsAsFactors = F,check.names=F)
    anno = read.delim(opt$anno,stringsAsFactors = F, sep = '\t')
    if (colnames(marker[1]) == "gene") {
      res = dplyr::left_join(marker, anno, by = c("gene" = "id"))
    }
    else {
      res = dplyr::left_join(marker, anno, by = c("GeneID" = "id"))
    }
    res[is.na(res)] = "--"
    write.table(res, paste0(strsplit(opt$genelist, "\\.xls")[[1]][1], "_anno.xls", collapse = ""), sep = '\t', quote = F, row.names = F)
  }
}
#######

if ( "changecelltype" %in% args){
    data_ob = ReadX(input = opt$input, informat = opt$informat,
        assays = assays, data.use = dataslots)
  # subset cells on the expression matrix using logical exprssion on features
  if ( !is.null(opt$predicate) ){
      df = OESingleCell::colData(data_ob)
      desired_cells= subset(df, eval( parse(text=opt$predicate)))
      data_ob = data_ob[, rownames(desired_cells)]
  }
    if ( as.logical(opt$barcode) ) {
          #支持csv格式和云平台下载的xls格式
          if (grepl(".csv",opt$celltype) == TRUE) {
              tsv <- read.delim(opt$celltype,sep=",",header=T)
          } else if (grepl(".xls",opt$celltype) == TRUE) {
              tsv <- read.delim(opt$celltype,sep="\t",header=T)
          }
          
          #若输入的barcode不是rawbc 而是meta.data的行名，先转化为rawbc
          rownames(tsv)=tsv[[1]]
          if (any(tsv[[1]] %in% rownames(data_ob@meta.data))){
              tsv[intersect(tsv[[1]], rownames(data_ob@meta.data)),1]=data_ob@meta.data[intersect(tsv[[1]], rownames(data_ob@meta.data)),]$rawbc
          }
          id = colnames(tsv)[2]
          # print("导入文件的new_celltype")
          print(table(tsv[,id]))
          if (dim(data_ob)[2]!=dim(tsv)[1] ) {
              print(paste0("注意：导入文件的barcodes数量为",dim(tsv)[1],"，rds中barcodes数量为",dim(data_ob)[2],"，注意对比信息"))
              if (length(setdiff(tsv[,colnames(tsv)[1]],data_ob@meta.data$rawbc)) != 0 ) {
                  stop(paste0("注意：",length(setdiff(tsv[,colnames(tsv)[1]],data_ob@meta.data$rawbc)),"条barcodes与rds中不匹配！！！！！！！！"))
              }
          }

          ### 给所有细胞进行细胞类型修改
          for (i in unique(tsv[,id]) ){
              subset_ob= subset(tsv, tsv[,id] == i)
              data_ob@meta.data[which(data_ob@meta.data$rawbc %in% as.vector(subset_ob[,colnames(tsv)[1]])) ,id] = i
          }
          ### 导入细胞类型顺序
          if (paste0(id,"_order") %in% colnames(tsv)) {
          for (i in unique(tsv[,paste0(id,"_order")]) ){
              subset_ob= subset(tsv, tsv[,paste0(id,"_order")] == i)
              data_ob@meta.data[which(data_ob@meta.data$rawbc %in% as.vector(subset_ob[,colnames(tsv)[1]])) ,paste0(id,"_order")] = i

          }
              sorted_id <- data_ob@meta.data %>% dplyr::arrange(get(paste0(id,"_order")))
              order_id = unique(sorted_id[[id]])
          }else {
              order_id = names(rev(sort(table(data_ob@meta.data[,id]))))
          }
          ### 导入细胞类型颜色
          if (paste0(id,"_col") %in% colnames(tsv)) {
          for (i in unique(tsv[,paste0(id,"_col")]) ){
              subset_ob= subset(tsv, tsv[,paste0(id,"_col")]== i)
              data_ob@meta.data[which(data_ob@meta.data$rawbc %in% as.vector(subset_ob[,colnames(tsv)[1]])) ,paste0(id,"_col")] = i
          }
          }

          data_ob@meta.data[,id] = factor(data_ob@meta.data[,id] ,levels=order_id)  
          # print("写入后rds的new_celltype")
          print(table(data_ob@meta.data[,id]))
          temp_id = id
    } else {
        tsv=read.table(opt$celltype,header=T,sep="\t",stringsAsFactors=F,colClasses="character")
        id=names(tsv)[1]
        print("导入文件")
        print(tsv)
        tsv=tibble::column_to_rownames(tsv,id)
        a=list()
        b=c()
        for (i in rownames(tsv) ){
            a[[i]]=unlist(strsplit(tsv[i,],",",perl = T))
            for (cluster in a[[i]]){
              b=append(b,cluster)
              }
        }
        if ( "TRUE" %in% duplicated(b) ) {
              stop("There are duplicate clusters")
        } else if ( all(sort(b) %in% sort(levels(as.factor(data_ob@meta.data[,opt$cluster]))))) {
              to=c()
              for (name in names(a)){ for (cluster in a[[name]]) to[cluster]=name }
              data_ob@meta.data[,id] = plyr::mapvalues(x=data_ob@meta.data[,opt$cluster],
                from=levels(as.factor(data_ob@meta.data[,opt$cluster])),
                to=to[levels(as.factor(data_ob@meta.data[,opt$cluster]))])
              df = OESingleCell::colData(data_ob)
              desired_cells= subset(df, eval( parse(text = paste0(id," %in% c(names(a))"))))
              data_ob = data_ob[, rownames(desired_cells)]
              if (as.logical(opt$order)) {
                # 如果是 TRUE，按照 tsv 排序
                order_clusters <- rownames(tsv)
              } else {
                # 按照细胞数排序
                order_clusters <- names(rev(sort(table(data_ob@meta.data[, id]))))
              }
              data_ob@meta.data[,id] = factor(data_ob@meta.data[,id] ,levels=order_clusters)  
        } else {
              stop("clusters are out of range")
        }
        print(table(data_ob@meta.data[,id]))
        temp_id = id
    }
    if ( ! is.null(opt$extrabarcode) ) {
      extrabarcode = read.delim(opt$extrabarcode,sep=",",header=T)
      id2 = colnames(extrabarcode)[2]
      print("导入额外文件的new_celltype")
      print(table(extrabarcode[,id2]))
      if(is.factor(data_ob@meta.data[,id2])){
        data_ob@meta.data[,id2] <- as.character(data_ob@meta.data[,id2])
      }
      if (dim(data_ob)[2]!=dim(extrabarcode)[1] ) {
          print(paste0("注意：导入额外文件的barcodes数量为",dim(extrabarcode)[1],"，rds中barcodes数量为",dim(data_ob)[2],"，注意对比信息"))
          if (length(setdiff(extrabarcode[,colnames(extrabarcode)[1]],data_ob@meta.data$rawbc)) != 0 ) {
                stop(paste0("注意：",length(setdiff(extrabarcode[,colnames(extrabarcode)[1]],data_ob@meta.data$rawbc)),"条barcodes与rds中不匹配！！！！！！！！"))
          }
      }
      ### 给所有细胞进行细胞类型修改
      for (i in unique(extrabarcode[,id2]) ){
          subset_ob= subset(extrabarcode, extrabarcode[,id2] == i)
          data_ob@meta.data[which(data_ob@meta.data$rawbc %in% as.vector(subset_ob[,colnames(extrabarcode)[1]])) ,id2] = i
      }
      # print("写入后rds的new_celltype")
      print(table(data_ob@meta.data[,id2]))
      temp_id = c(id,id2)
    }
    if ( opt$reduct %in% names(data_ob@reductions) ){ ##判断二次降维方法是否输入错误
          reduct=opt$reduct
    } else {
          reduct=as.character(tail(names(data_ob@reductions),1))
          print(paste0(opt$reduct,"在RDS中不存在，使用",reduct,"作图"))
    }
    
    #get_colors
    source("/public/scRNA_works/pipeline/scRNA-seq_further_analysis/Get_colors.R")
    print("加载Get_colors.R")
    if ( !as.logical(opt$use_color_anno) ){
        print('忽略rds内注释')
        data_ob@meta.data = data_ob@meta.data[ ,!grepl(paste0("^",temp_id,"_col$" ), colnames(data_ob@meta.data))]
    }
    if ( !is.null(opt$color_file)){
      color_file = read.delim(opt$color_file, sep="\t", header = T)
      meta_anno = color_anno(data_ob@meta.data, color_file)
    } else {
        meta_anno = data_ob@meta.data
    }

    color_use = get_colors(meta_anno, temp_id, opt$palette)
    data_ob <- AddMetaData(object = data_ob,metadata = color_use$object_meta)
    user_color_pal = color_use[["new_celltype_pal"]]
    user_color_pal = na.omit(user_color_pal)
    color_use = user_color_pal
    for(draw_id in temp_id){
      pointsize=0.5
      gg = Seurat::DimPlot(object = data_ob, reduction = reduct,pt.size = pointsize,group.by=draw_id, order = names(color_use) )+
        ggplot2::theme( plot.title = ggplot2::element_text(hjust = 0.5)) +
        ggplot2::scale_colour_manual( values = color_use, breaks = names(color_use)) + theme(aspect.ratio = 1/1)
      OESingleCell::save_ggplots(file.path(output_dir,draw_id), gg, width = max(nchar( as.vector(unique(data_ob@meta.data[,draw_id]))))/15+7, dpi = 300,limitsize = F, bg="white")
      
      simplified_meta = data_ob@meta.data %>%
                                dplyr::rename( "Barcode" = "rawbc") %>%
                                      dplyr::select( Barcode, sampleid, opt$cluster, group,!!draw_id)
      write.table(simplified_meta, quote = F,sep =",",row.names = F,
                file.path(output_dir,paste0(draw_id,".metadata.csv",collapse = "")))
      if ( as.logical(opt$update) ){
        SeuratDisk::UpdateH5Seurat(file = opt$input, object = data_ob, verbose = FALSE )
      }else{
        OESingleCell::SaveX(data_ob, output = opt$output,update = FALSE,
                            outformat = opt$outformat, prefix = opt$prefix)
      }
    }
}
 # ====================================== Subcmd: monocle, monocle2 analysis ======================
  if ( "monocle" %in% args ){
  suppressPackageStartupMessages( library("monocle") )
  suppressPackageStartupMessages( library("tibble") )
  suppressPackageStartupMessages( library("dplyr") )
  suppressPackageStartupMessages( library("reshape2") )
  source("/public/scRNA_works/pipeline/scRNA-seq_further_analysis/Get_colors.R")
  if (is.null(opt$downsample)) {
    downsample <- 30000
  } else {
    downsample <- opt$downsample
  }


  if ( is.null(opt$output)){
      print("NO OUTPUT PATH SUPPLIED,current directory will be used!")
      output_dir = getwd()
  }else{
      output_dir = opt$output
      if ( !file.exists(output_dir) ){
          dir.create(output_dir)
      }
  }


  #check the components to use
  if ( is.null(opt$components) ){
      print("NO components number is available, the default will be used")
  }

  #check the value of perplexity
  if ( is.null(opt$perplexity) ){
      print("NO perplexity number is specified, the default will be used!")
  }

  if ( is.null( opt$design ) ){
      print("NO group design is provided! The clusters will be used!")
      design = "clusters"
  }else{
      design = opt$design
  }

  CustomCol2 <- function(n){
    my_palette=c(
      "#7fc97f","#beaed4","#fdc086","#386cb0","#f0027f","#a34e3b","#666666","#1b9e77","#d95f02","#7570b3",
      "#d01b2a","#43acde","#efbd25","#492d73","#cd4275","#2f8400","#d9d73b","#aed4ff","#ecb9e5","#813139",
      "#743fd2","#434b7e","#e6908e","#214a00","#ef6100","#7d9974","#e63c66","#cf48c7","#ffe40a","#a76e93",
      "#d9874a","#adc64a","#5466df","#d544a1","#54d665","#5e99c7","#006874","#d2ad2c","#b5d7a5","#9e8442",
      "#4e1737","#e482a7","#6f451d","#2ccfe4","#ae6174","#a666be","#a32b2b","#ffff99","#3fdacb","#bf5b17")
    return(my_palette[n])
  }


  gbm.PlotAbundances <- function (x = seurat, prop.by = "res.1", group.by = "sampleid", 
      split.by = NULL, method = "barplot", ncol = NULL, cols = CustomCol(1:length(unique(x[, 
          prop.by])))) 
  {
      md <- x@phenoData@data
      field4emeta = colnames(md)
      if (is.null(prop.by) | !prop.by %in% field4emeta) {
          stop("prop.by should be one of the clustering results name in meta.data.")
      }
      if (is.null(group.by) | !group.by %in% field4emeta) {
          stop("One of sampleid and clusters field name should be provided for groupping!")
      }
      cluster_ids <- md[, prop.by]
      sample_ids <- md[, group.by]
      counts <- table(cluster_ids, sample_ids)
      df <- melt(t(round(t(counts)/colSums(counts) * 100, 2)), 
          varnames = c(prop.by, group.by), value.name = "freq")
      df[, group.by] = factor(df[, group.by])
      df[, prop.by] = factor(df[, prop.by])
      if (!is.null(split.by)) {
          xm = unique(md[, c(group.by, split.by)])
          m <- match(df[, group.by], xm[, group.by])
          df[, split.by] = xm[m, setdiff(names(xm), names(df))]
          df[, split.by] = factor(df[, split.by])
      }
      p = switch(method, barplot = ggplot(df) + geom_bar(aes_string(y = "freq", 
          x = group.by, fill = prop.by), position = "stack", stat = "identity") + 
          scale_fill_manual(values = cols) + scale_y_continuous(expand = c(0, 
          0), labels = seq(0, 100, 25)) + labs(x = NULL, y = "Propotion [%]") + 
          theme_bw() + theme(panel.grid.minor = element_blank(), 
          panel.grid.major = element_blank(), strip.background = element_rect(fill = NA, 
              color = NA), panel.border = element_blank(), axis.ticks.x = element_blank(), 
          axis.text = element_text(color = "black"), axis.text.x = element_text(angle = 90, 
              hjust = 1, vjust = 0.5)), boxplot = ggplot(df) + 
          theme_bw() + geom_boxplot(aes_string(y = "freq", x = group.by, 
          color = group.by, fill = group.by), position = position_dodge(), 
          alpha = 0.25, outlier.color = NA) + scale_fill_manual(values = cols) + 
          geom_point(position = position_jitter(width = 0.25), 
              aes_string(x = group.by, y = "freq", color = group.by)) + 
          guides(fill = FALSE) + labs(x = NULL, y = "Proportion [%]") + 
          theme(strip.background = element_rect(fill = NA, color = NA), 
              panel.spacing = unit(0.2, "cm"), strip.text = element_text(face = "bold"), 
              panel.grid.minor = element_blank(), panel.grid.major = element_blank(), 
              axis.ticks.x = element_blank(), axis.text = element_text(color = "black"), 
              axis.text.x = element_text(angle = 90, hjust = 1, 
                  vjust = 0.5)), pie = ggplot(df, aes(x = 0, y = freq)) + 
          geom_bar(aes_string(fill = prop.by), width = 1, stat = "identity") + 
          theme_void() + scale_fill_manual(values = cols) + theme(axis.title.y = element_blank(), 
          axis.text.y = element_blank(), axis.ticks.y = element_blank()) + 
          coord_polar(theta = "y", start = 0) + facet_wrap(eval(expr(~!!ensym(group.by))), 
          ncol = ncol) + theme(strip.background = element_rect(fill = NA, 
          color = NA), strip.text = element_text(face = "bold")))
      if (!is.null(split.by)) {
          p = p + facet_grid(eval(expr(~!!ensym(split.by))), scales = "free_x", 
              space = "free")
      }
      return(p)
  }

#  2. Load and normalize data
#  https://www.bioconductor.org/packages/devel/bioc/vignettes/monocle/inst/doc/monocle-vignette.pdf
#
# ####################################################################
#whatever format the input file has, all the input expression matrix
#should be transformed to the seurat object finally.
  if ( !is.null(opt$input) ){
      # the input is a seurat object which may contain more than one sample
      if ( opt$informat == "seurat" || opt$informat == "h5seurat" ){
          if (opt$informat == "seurat"){
            seurat_ob = readRDS( opt$input )
          }else if (opt$informat == "h5seurat") {
            seurat_ob = ReadX(input = opt$input, informat = 'h5seurat', verbose = F)
          }
          if ( seurat_ob@version < 3 ){
              seurat_ob = UpdateSeuratObject(seurat_ob) #make sure the seurat object match with the latest seurat package
          }
          
          if ( !is.null( opt$assay) ){
              #DefaultAssay(seurat_ob) = opt$assay
              Seurat::DefaultAssay(seurat_ob) <- "RNA"
          }else{
              #DefaultAssay(seurat_ob) = "RNA"
              Seurat::DefaultAssay(seurat_ob) <- "RNA"
          }
  
          if ( is.null(seurat_ob@meta.data$clusters) ){
              seurat_ob = StashIdent(seurat_ob, save.name = "clusters")
          }else{
              seurat_ob = SetIdent( seurat_ob, value = "clusters")
          }

          if ( !is.null(opt$from) & !is.null(opt$to) ){
              from_ident = unlist( strsplit( opt$from, ",", perl =T ) )
              to_ident = unlist( strsplit(opt$to), ",", perl = T )
              seurat_ob@ident = plyr::mapvalues(x = seurat_ob@ident, from = from+ident, to = to_ident )
          }
          
          #subset the seurat object using the specified cells of clusters from the
          #command line if available
          if ( !is.null(opt$predicate)){
              desired_cells= subset(OESingleCell::colData(seurat_ob), eval( parse(text=opt$predicate)))
              seurat_ob = seurat_ob[,rownames(desired_cells)]
          }

          if ( is.null(opt$palette ) ){
			print("没有指定色板，将采用rds中注释的颜色或者默认色板.")
			palette = "customecol2"
		  }else{
                palette = opt$palette
          }
			colorby = unlist(strsplit(opt$colorby,",",perl=T))
			for ( ident2use in colorby ){
           if ( !as.logical(opt$use_color_anno)){
            print('忽略rds内注释')
            seurat_ob@meta.data = seurat_ob@meta.data[ ,!grepl(paste0("^",ident2use,"_col$" ), colnames(seurat_ob@meta.data))]
            }
        if ( !is.null(opt$color_file)){
                #拆分输入的color_file
                color_file_list = unlist(strsplit( opt$color_file,",",perl = T))
                #先给meta_anno一个初始值，为原始的meta
                meta_anno=seurat_ob@meta.data
                for (color_file in color_file_list){
                color_file = read.delim(color_file, sep="\t", header = T)
                    #判断输入的文件是否有barcode列来判断是否云平台导出的meta
                    if ("barcode" %in% colnames(color_file)) { 
                        #映射输入的颜色
                        col_name=colnames(color_file)[grepl("_col$",colnames(color_file))]
                        meta_anno[intersect(rownames(meta_anno),color_file$barcode),col_name]=as.character(color_file[which(rownames(meta_anno) %in% intersect(rownames(meta_anno),color_file$barcode)),col_name])
                        #判断是否文件中有顺序
                        if (any(grepl("_order$",colnames(color_file)))){
                        order_name=colnames(color_file)[grepl("_order$",colnames(color_file))]
                        #根据XXX_order列去排序
                        meta_sorted <- color_file[order(as.numeric(color_file[[order_name]])), ]
                        groupby=setdiff(colnames(color_file), c("barcode",col_name,order_name))
                        groupby_levels=unique(meta_sorted[[groupby]])
                        meta_anno[,groupby]=factor(meta_anno[,groupby],levels=groupby_levels)
                        }
                    }else{
                    meta_anno = color_anno(meta_anno, color_file)
                    }
                }
        } else {
            meta_anno = seurat_ob@meta.data
        }
        color_use = get_colors(meta_anno, ident2use, palette)
        seurat_ob = AddMetaData( seurat_ob, metadata = color_use[["object_meta"]])
        new_celltype_pal = color_use[["new_celltype_pal"]]
        new_celltype_pal = na.omit(new_celltype_pal)
        print("color.use :")
        print(new_celltype_pal)
        print(table(seurat_ob@meta.data[, paste0( ident2use,"_col" )]))
    }
          #check the components to use
          if ( is.null(opt$components) ){
              if ( is.null(Misc(seurat_ob, "optimal_pc")) ){
                  print( "NO previous components calculation is AVAILABLE, 20 will be used as default.")
                  components_num = 20
              }else{
                  components_num = Misc(seurat_ob, "optimal_pc")
              }
          }else{
              components_num  = opt$components
          }

          #check the value of perplexity
          if ( is.null(opt$perplexity) ){
              if ( is.null(Misc(seurat_ob, "perplexity")) ){
                  print( "NO previous perplexity is AVAILABLE, 30 will be used as default.")
                  perplexity = 30
              }else{
                  perplexity = Misc(seurat_ob, "perplexity")
              }
          }else{
              perplexity = opt$perplexity
          }
          if (ncol(seurat_ob) > 40000) {
              # library(sampling) need install
              ratio <- as.numeric(opt$downsample) / ncol(seurat_ob)
              metadata_temp <- as.data.frame(seurat_ob@meta.data)
              # strata(metadata_temp,stratanames="clusters",ratio,description=FALSE)
              cells_sample <- c()
              for (i in unique(seurat_ob$clusters)) {
                cells_temp <- rownames(metadata_temp)[which(metadata_temp$clusters == i)]
                #设置随机种子，确保结果可复原
                set.seed(2024)
                cells_temp_sample <- sample(cells_temp, ceiling(length(cells_temp) * ratio), replace = FALSE, prob = NULL)
                cells_sample <- append(cells_sample, cells_temp_sample)
              }
              seurat_ob <- subset(seurat_ob, cells = cells_sample)
            }
            print(dim(seurat_ob))
      }else{
          if ( opt$informat == "tenx" ){
              # Initialize the Seurat object with the raw (non-normalized data).
              # Keep all genes expressed in >= 3 cells (~0.1% of the data).
              #Directory containing the matrix.mtx, genes.tsv, and barcodes.tsv files provided by 10X.
              #A vector or named vector can be given in order to load several data directories of several samples.
              #If a named vector is given, the cell barcode names will be prefixed with the name.
              #the gene-barcode matrix result directory for all samples from 10X
              if ( !file.exists( opt$metadata) ){
                stop( "Warning:the metadata of this single cell assay is NOT AVAILABLE!")
              }else{
                assay_metadata = read.table(opt$metadata,sep="\t",header =T, row.names = F,check.names = )
              }
              outs_filtered_path = "outs/filtered_gene_bc_matrices"
              tenx_path = sub("\\/$","",opt$input,perl=T)
              tenx_path = normalizePath(tenx_path)
              matrix_path = apply( assay_metadata,1,
              function(samplex) file.path(tenx_path,samplex["sampleid"],outs_filtered_path,samplex["specie"]))
              countMatrixSparse <- Read10X(matrix_path)
          }
          #read data from the count matrix file, row as genes and columns as cells
          #the input matrix can be stored as sparse format or text format
          if ( opt$informat == "raw_dense" ){
              mycountmatrix = read.table(opt$input, header =T, row.name = 1)
              #notice that this may take to much memory
              #transform the density count matrix to the sparse form
              countMatrixSparse = Matrix(as.matrix(mycountmatrix), sparse=T)
              #remove the original matrix to reduce memory usage
              rm(mycountmatrix)
          }
          if ( opt$informat == "raw_sparse" ){
              countMatrixSparse = readMM(opt$input)
              rm(mycountmatrix)
          }

          #add in the metadata of all cells
          #preserve the sample group infomation into the seurat object,the order of the sample
          #is the same as the order in the metadata list
          cellnames = colnames(countMatrixSparse)
          if ( length(grep("\\d_[A-Z]*",cellnames,perl=T) ) < length(cellnames) ){
              #the barcodes of cells in first sample don't prefix with sample index number
              #so we add it for convenince
              firstsample = cellnames[grep("^[A-Z]",cellnames,perl=T)]
              cellnames[1:length(firstsample)] = gsub("^","1_",firstsample,perl=T)
              colnames(countMatrixSparse) = cellnames
          }
          sampleidx =  gsub("_.*","",cellnames,perl=T) #the index order is the same as the row index of the assay metadata
          #integrate the metadata from the assay design
          cell_meta = vector( )
          for ( colidx in colnames(assay_metadata) ){
              cell_meta= cbind(cell_meta, as.vector(assay_metadata[sampleidx, colidx]))
          }
          colnames(cell_meta) = colnames(assay_metadata)
          rownames(cell_meta) = cellnames
          cell_meta = as.data.frame(cell_meta)
          cell_meta$orig.ident = cell_meta$sampleid
          #the minimium cell number one gene is detected
          if ( is.null(opt$min.cell) ){
              min.cell_N = 0
          }else{
              min_cell4gene = opt$min.cell
              min.cell_N = round(min_cell4gene * ncol(countMatrixSparse))
          }
          #construct the seurat object using the meta data above
          seurat_ob <- CreateSeuratObject( raw.data = countMatrixSparse,min.cells=min.cell_N,
          names.field = 1, meta.data = cell_meta,
          names.delim = "_" )
          seurat_ob@meta.data$orig.ident = as.factor(cell_meta$orig.ident)
          rm(countMatrixSparse)
          seurat_ob <- NormalizeData(object = seurat_ob, normalization.method = "LogNormalize", scale.factor = 10000)

          #========1.4 find the highly variable genes
          seurat_ob = FindVariableGenes(object = seurat_ob, mean.function = ExpMean,
          dispersion.function = LogVMR,do.plot = F,
          x.low.cutoff = 0.0125, x.high.cutoff = 3, y.cutoff = 0.5)
          #  1.5 Seurat Clustering
          #=====1.5 Scaling the data and removing unwanted sources of variation=====
          mito.genes <- grep(pattern = "^(MT|mt)(-|_)", x = rownames(x = seurat_ob@data), value = T)
          percent.mito <- Matrix::colSums(seurat_ob@raw.data[mito.genes, ])/Matrix::colSums(seurat_ob@raw.data)

          # AddMetaData adds columns to object@meta.data, and is a great place to
          # stash QC stats
          seurat_ob <- AddMetaData(object = seurat_ob,
          metadata = percent.mito, col.name = "percent.mito")
          seurat_ob <- ScaleData(object = seurat_ob,vars.to.regress = c("nUMI", "percent.mito")) #takes some time

          #batch effect remove using Combat from sva package
          if ( opt$BATCH == T){
              suppressPackageStartupMessages(library(sva))
              m = as.matrix(seurat_ob@data)
              com = ComBat(dat=m, batch=seurat_ob@meta.data$batchid,
              prior.plots=FALSE, par.prior=TRUE)
              seurat_ob@data = Matrix(com)
              rm(m)
              rm(com)
          }

          seurat_ob <- RunPCA(object = seurat_ob,pc.genes = seurat_ob@var.genes,do.print = F)

          seurat_ob <- FindClusters(object = seurat_ob, reduction.type = "pca",
          dims.use = 1:components_num, resolution = resolution,
          print.output = 0, save.SNN = TRUE,force.recalc=T)
          pca_cluster_result_colname = paste("pca","2D","res",resolution,sep = ".")
          #as default the seurat will store the clustering results in the seurat_object@ident
          #to keep the clutering results using the specified resolution to seurat_object@metadata for reuse
          seurat_ob <- StashIdent(object = seurat_ob, save.name = pca_cluster_result_colname)
      }
  }

  if (is.null(opt$rds)){
      #transform the seurat object to the monocle CellDataSet
      # gbm_cds = importCDS( seurat_ob, import_all = F )
      gbm_cds = Seurat::as.CellDataSet( seurat_ob )
      #Estimate size factors and dispersions
      gbm_cds = estimateSizeFactors(gbm_cds)
      gbm_cds = estimateDispersions(gbm_cds)
      #Filtering low-quality cells
      gbm_cds = detectGenes(gbm_cds,min_expr = 1)
      #keep only the genes expressed in at least 10 cells of the data set.
      expressed_genes = row.names(subset(fData(gbm_cds),num_cells_expressed>10))
  
      pData(gbm_cds)$Total_mRNA = Matrix::colSums(exprs(gbm_cds))
      # gbm_cds = clusterCells(gbm_cds)
      #Find ordering genes
      clustering_DEGs = differentialGeneTest(gbm_cds,fullModelFormulaStr = paste0("~", design),cores = opt$ncores)
      featureData(gbm_cds)@data[rownames(clustering_DEGs),"pval"]=clustering_DEGs$pval
      featureData(gbm_cds)@data[rownames(clustering_DEGs),"qval"]=clustering_DEGs$qval
      ordering_genes <- row.names (subset(clustering_DEGs, qval < 0.01))
      if(!is.null(opt$topn)){
          topn=opt$topn
          data <- featureData(gbm_cds)@data
          if(opt$assay=="RNA"){
              ordering_genes <- subset(data, qval < 0.01) %>% tibble::rownames_to_column(var="gene" ) %>% dplyr::arrange(desc(vst.variance.standardized))  %>% dplyr::top_n(as.numeric(topn),vst.variance.standardized)
          }else if(opt$assay=="SCT"){
              ordering_genes <- subset(data, qval < 0.01) %>% tibble::rownames_to_column(var="gene" ) %>% dplyr::arrange(desc(sct.variance))  %>% dplyr::top_n(as.numeric(topn),sct.variance)  
          } 
          write.table(ordering_genes,file.path(output_dir,'ordering_genes.xls'),sep='\t',row.names=F,quote=F)   
          ordering_genes <- ordering_genes$gene    
          gbm_cds = setOrderingFilter(gbm_cds,ordering_genes = ordering_genes)
          # if(length(colnames(gbm_cds))<= 5000){            
          #   gbm_cds = reduceDimension(gbm_cds,max_components = 2,verbose = T,check_duplicates = F,auto_param_selection=F)
          # } else{
            gbm_cds = reduceDimension(gbm_cds,max_components = 2,verbose = T,check_duplicates = F)
          # }
      }   
      gbm_cds = setOrderingFilter(gbm_cds,ordering_genes = ordering_genes)
      gbm_cds = reduceDimension(gbm_cds,max_components = 2,verbose = T,check_duplicates = F)
      gbm_cds = orderCells(gbm_cds,reverse = F)

      #Remove the state with 0 cell
      for (i in which(table(gbm_cds$State)==0)){
      gbm_cds$State=as.numeric(gbm_cds$State)
      gbm_cds$State[gbm_cds$State>i]=gbm_cds$State[gbm_cds$State>i]-1
      gbm_cds$State=as.factor(gbm_cds$State)
      }
  
      saveRDS(gbm_cds, file = file.path(output_dir,"pseudotime_results.rds"))

      # Pseudotime on tsne plot
      seurat_ob@meta.data$Pseudotime = ""
      seurat_ob@meta.data[rownames(gbm_cds@phenoData),]$Pseudotime = gbm_cds$Pseudotime
      seurat_ob@meta.data$Pseudotime = as.numeric(seurat_ob@meta.data$Pseudotime)
      # p = FeaturePlot(seurat_ob, features= "Pseudotime", reduction = "tsne", pt.size= opt$pointsize) + scale_colour_viridis_c(option = "inferno")
      # ggsave(file.path(output_dir,paste0("Pseudotime_on_tsne_plot.pdf",collapse = "")), plot = p)
      # ggsave(file.path(output_dir,paste0("Pseudotime_on_tsne_plot.png",collapse = "")), plot = p, dpi=1000)
      Pseudotime_State= gbm_cds$State
      seurat_ob <- AddMetaData(object = seurat_ob,metadata = Pseudotime_State, col.name = "Pseudotime_State")
      if ( !is.null(opt$input) ){
          if ( !is.null(opt$predicate)){
              # saveRDS(seurat_ob,file.path(output_dir,paste0("subseted_",groupfactor,"_",paste0(cluster_list,collapse="-"),"_seurat_withpseudotime.rds")))    
              SeuratDisk::SaveH5Seurat(seurat_ob, filename = glue::glue("{output_dir}/subseted_seurat_withpseudotime.h5seurat") ,
                              overwrite = FALSE, verbose = FALSE)                                            
          } else{
              SeuratDisk::SaveH5Seurat(seurat_ob, filename = glue::glue("{output_dir}/seurat_withpseudotime.h5seurat") ,
                              overwrite = FALSE, verbose = FALSE)
          }
      }
  } else  {gbm_cds = readRDS(opt$rds)
           meta <- pData(gbm_cds)
         colorby = unlist(strsplit(opt$colorby,",",perl=T))
         if ( is.null(opt$palette ) ){
                     print("没有指定色板，将采用rds中注释的颜色或者默认色板.")
                     palette = "customecol2"
             }else{
                     palette = opt$palette
             }

         for ( ident2use in colorby ){
            if ( !is.null(opt$use_color_anno)){
                print('忽略rds内注释')
                meta = meta[ ,!grepl(paste0("^",ident2use,"_col$" ), colnames(meta))]
                }
            if ( !is.null(opt$color_file)){
                #拆分输入的color_file
                color_file_list = unlist(strsplit( opt$color_file,",",perl = T))
                #先给meta_anno一个初始值，为原始的meta
                meta_anno=meta
                #for循环针对每个color_file进行注释
                for (color_file in color_file_list){
                color_file = read.delim(color_file, sep="\t", header = T)
                    #判断输入的文件是否有barcode列来判断是否云平台导出的meta
                    if ("barcode" %in% colnames(color_file)) {
                    #映射输入的颜色
                    col_name=colnames(color_file)[grepl("_col$",colnames(color_file))]
                    meta_anno[intersect(rownames(meta_anno),color_file$barcode),col_name]=as.character(color_file[which(rownames(meta_anno) %in% intersect(rownames(meta_anno),color_file$barcode)),col_name])
                        #判断是否文件中有顺序
                        if (any(grepl("_order$",colnames(color_file)))){
                        order_name=colnames(color_file)[grepl("_order$",colnames(color_file))]
                        #根据XXX_order列去排序
                        meta_sorted <- color_file[order(as.numeric(color_file[[order_name]])), ]
                        groupby=setdiff(colnames(color_file), c("barcode",col_name,order_name))
                        groupby_levels=unique(meta_sorted[[groupby]])
                        meta_anno[,groupby]=factor(meta_anno[,groupby],levels=groupby_levels)
                        }  
                    }else{
                    meta_anno = color_anno(meta_anno, color_file)
                    }
                }
            } else {
                meta_anno = meta
            }
            color_use = get_colors(meta_anno, ident2use, palette)
            meta = color_use[["object_meta"]]
            new_celltype_pal = color_use[["new_celltype_pal"]]
            new_celltype_pal = na.omit(new_celltype_pal)
            print("color.use :")
            print(new_celltype_pal)
#            print(table(meta[, paste0( ident2use,"_col" )]))
        }

         pData(gbm_cds) <- meta
}

  # cell trajectory plot
  # p = plot_cell_trajectory(gbm_cds, color_by = "Pseudotime", cell_size = opt$pointsize, show_branch_points = F) + scale_colour_viridis_c(option = "inferno")
  # ggsave(file.path(output_dir,"cell_trajectory_color_by_Pseudotime.pdf"), plot = p )
  # ggsave(file.path(output_dir,"cell_trajectory_color_by_Pseudotime.png"), plot = p, dpi=1000)

  nlevel = length(unique(gbm_cds@phenoData@data[,"State"]))
  pp = plot_cell_trajectory(gbm_cds, color_by = "State", cell_size = opt$pointsize, show_branch_points = F) + scale_colour_manual( values = CustomCol2(1:nlevel)) + guides(colour = guide_legend(override.aes = list(size=2)))
  ggsave(file.path(output_dir,"cell_trajectory_color_by_State.pdf"), plot = pp, bg="white" )
  ggsave(file.path(output_dir,"cell_trajectory_color_by_State.png"), plot = pp, dpi=1000, bg="white")

  color_by = unlist(strsplit(opt$colorby,",",perl=T))

  for ( color_group in color_by ){
      # if(color_group =="clusters"){
          # nlevels = sort(unique(gbm_cds@phenoData@data[,"clusters"]))
          # user_color_pal = CustomCol2(nlevels)
          # nlevel = length(unique(gbm_cds@phenoData@data[,"clusters"]))
          # }else if(paste0(color_group,"_col") %in% colnames(gbm_cds@phenoData@data)){
              # groupby_col = paste0(color_group,"_col")
              # nlevel = length(unique(gbm_cds@phenoData@data[,color_group]))
              # nlevel_list = sort(as.character(unique(gbm_cds@phenoData@data[,color_group])))
              # tmp_df <- unique(gbm_cds@phenoData@data[c(color_group, groupby_col)])
              # new_celltype_pal <- as.vector(tmp_df[,groupby_col])
              # names(new_celltype_pal) <-  as.vector(tmp_df[,color_group])
              # new_celltype_pal = as.list(new_celltype_pal)
              # user_color_pal = new_celltype_pal[nlevel_list]
      # }else {
          # nlevel = length(unique(gbm_cds@phenoData@data[,color_group]))
          # user_color_pal = CustomCol2(1:nlevel)
      # }
            nlevel = length(unique(gbm_cds@phenoData@data[,color_group]))
             user_color_pal = get_colors(gbm_cds@phenoData@data, color_group, palette)
             user_color_pal = user_color_pal[["new_celltype_pal"]]
             user_color_pal = na.omit(user_color_pal)
			 
      # 获取总字符数
      total_char = sum(nchar(as.character(unique(gbm_cds@phenoData@data[,color_group]))))

      if (total_char < 40){
          p = plot_cell_trajectory(gbm_cds, color_by = color_group, cell_size = opt$pointsize, show_branch_points = F) + scale_colour_manual( values = user_color_pal) + guides(colour = guide_legend(override.aes = list(size=2),nrow=as.numeric((ifelse(nlevel >4,"2","1")))))
          ggsave(file.path(output_dir,paste0("cell_trajectory_color_by_",color_group,".pdf",collapse = "")), plot = p, bg="white")
          ggsave(file.path(output_dir,paste0("cell_trajectory_color_by_",color_group,".png",collapse = "")), plot = p, dpi=1000, bg="white")
          # facet_wrap
          p_facet = plot_cell_trajectory(gbm_cds, color_by = color_group, cell_size = opt$pointsize, show_branch_points = F ) +
                facet_wrap(eval(expr(~!!ensym(color_group))),scales = "free_x", ncol = as.numeric((ifelse(nlevel >20,"4","2")))) +scale_colour_manual( values = user_color_pal) + 
                guides(colour = guide_legend(override.aes = list(size=2),nrow=as.numeric((ifelse(nlevel >4,"2","1")))))
          ggsave(file.path(output_dir,paste0("cell_trajectory_group_by_",color_group,".pdf",collapse = "")), plot = p_facet,height= ceiling(nlevel/2)*4,bg="white")
          try(ggsave(file.path(output_dir,paste0("cell_trajectory_group_by_",color_group,".png",collapse = "")), plot = p_facet, dpi=1000,height= ceiling(nlevel/2)*4,bg="white"))
      } else {
          # 获取最大字符数
          nmax = max(nchar(as.character(unique(gbm_cds@phenoData@data[,color_group]))))
          # 计算nrow数
          nrows = ceiling(nlevel * nmax / 40)

          p = plot_cell_trajectory(gbm_cds, color_by = color_group, cell_size = opt$pointsize, show_branch_points = F) + scale_colour_manual( values = user_color_pal) + guides(colour = guide_legend(override.aes = list(size=2),nrow=nrows))
          ggsave(file.path(output_dir,paste0("cell_trajectory_color_by_",color_group,".pdf",collapse = "")), plot = p, bg="white")
          ggsave(file.path(output_dir,paste0("cell_trajectory_color_by_",color_group,".png",collapse = "")), plot = p, dpi=1000, bg="white")
          # facet_wrap
          p_facet = plot_cell_trajectory(gbm_cds, color_by = color_group, cell_size = opt$pointsize, show_branch_points = F ) +
                facet_wrap(eval(expr(~!!ensym(color_group))),scales = "free_x", ncol = as.numeric((ifelse(nlevel >20,"4","2")))) +scale_colour_manual( values = user_color_pal) + 
                guides(colour = guide_legend(override.aes = list(size=2),nrow=nrows))
          ggsave(file.path(output_dir,paste0("cell_trajectory_group_by_",color_group,".pdf",collapse = "")), plot = p_facet,height= ceiling(nlevel/2)*as.numeric((ifelse(nlevel >20,"2","4"))),width=as.numeric((ifelse(nlevel >20,"12","7"))),limitsize = FALSE, bg="white")
          try(ggsave(file.path(output_dir,paste0("cell_trajectory_group_by_",color_group,".png",collapse = "")), plot = p_facet, dpi=1000,height= ceiling(nlevel/2)*as.numeric((ifelse(nlevel >20,"2","4"))),width=as.numeric((ifelse(nlevel >20,"12","7"))),limitsize = FALSE,bg="white"))
      }
  }


  # count summary
  DATA <- as.data.frame( gbm_cds@phenoData@data[,c("sampleid", "group","State")] ) %>%
      group_by( .dots= c( "State","sampleid","group")) %>%
      dplyr::summarize(cell_number = n())
  write.table(as.data.frame(DATA),file.path(output_dir,"Pseudotime_State_count_info.xls"),sep="\t",col.names=T, row.names =F)

  # Pie plot
  color_use = get_colors(gbm_cds@phenoData@data, "group", palette)
new_celltype_pal = color_use[["new_celltype_pal"]]
new_celltype_pal = na.omit(new_celltype_pal)
pie_by_state = gbm.PlotAbundances(gbm_cds, prop.by = "group", group.by = "State", method = "pie", ncol = 4, cols = new_celltype_pal)

  ggsave(file.path(output_dir,"groupby_Pseudotime_State_pie_plot.pdf"), plot = pie_by_state, bg="white")
  ggsave(file.path(output_dir,"groupby_Pseudotime_State_pie_plot.png"), plot = pie_by_state, dpi=1000, bg="white")

  pie_by_group = gbm.PlotAbundances(gbm_cds, prop.by = "State", group.by = "group", method = "pie", ncol = 4, cols = CustomCol2(1:length(table(gbm_cds@phenoData@data[,"State"]))))
  ggsave(file.path(output_dir,"groupby_group_pie_plot.pdf"),plot = pie_by_group, bg="white")
  ggsave(file.path(output_dir,"groupby_group_pie_plot.png"),plot = pie_by_group, dpi=1000, bg="white")

  if(!file.exists(file.path(output_dir, "拟时序分析说明.docx"))){
    file.copy("/public/scRNA_works/Documents/拟时序分析说明.docx",
    file.path(output_dir, "拟时序分析说明.docx"))
  }
}

